{"meta":{"title":"Tyrival","subtitle":null,"description":null,"author":"Tyrival","url":"http://tyrival.github.io"},"pages":[{"title":"关于","date":"2018-10-23T07:56:04.745Z","updated":"2017-06-08T07:58:59.000Z","comments":true,"path":"about/index.html","permalink":"http://tyrival.github.io/about/index.html","excerpt":"","text":""},{"title":"分类","date":"2018-10-23T07:56:04.756Z","updated":"2017-06-08T07:58:25.000Z","comments":true,"path":"categories/index.html","permalink":"http://tyrival.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-10-23T07:56:04.774Z","updated":"2017-06-08T07:58:33.000Z","comments":true,"path":"tags/index.html","permalink":"http://tyrival.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker+Hadoop 01：环境部署","slug":"hadoop-docker-01","date":"2019-01-02T23:58:03.975Z","updated":"2019-01-03T00:38:30.610Z","comments":true,"path":"posts/hadoop-docker-01/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-docker-01/","excerpt":"本文介绍了基于docker部署hadoop环境的说明。","text":"本文介绍了基于docker部署hadoop环境的说明。 1. 概述 可以直接从docker hub下载，docker pull tyrival/hadoop https://hub.docker.com/r/tyrival/hadoop 也可以基于centos镜像手工构建 123centos镜像版本: 7.5.1804hadoop版本: hadoop-2.9.2.tar.gzjava版本: jdk-8u191-linux-x64.tar.gz hadoop和jdk下载完成后放在~/Documents/Workspace/Docker/hadoop文件夹中 ##2. 部署过程 1. 启动并进入centos容器123456# 将下载的hadoop和jdk放在~/Documents/Workspace/Docker/hadoop中# 启动镜像时，将此文件夹映射到容器中docker run -dit -v ~/Documents/Workspace/Docker/hadoop:/root/tmp --name centos centos# 进入容器docker exec -it centos /bin/bash 2. 安装软件12345678910111213141516171819202122232425# 安装必要软件yum install -y wget vim openssh-server openssh-clients net-tools# 进入hadoop和jdk所在文件夹cd /root/tmp# 创建java安装路径，并将jdk解压到此路径mkdir /usr/javatar zxf jdk-8u191-linux-x64.tar.gz -C /usr/java# 设置jdk环境变量echo 'export JAVA_HOME=/usr/java/jdk1.8.0_191' &gt;&gt; /etc/bashrcecho 'export PATH=$PATH:$JAVA_HOME/bin' &gt;&gt; /etc/bashrcecho 'export CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar' &gt;&gt; /etc/bashrcsource /etc/bashrc# 解压hadoop安装包tar zxf hadoop-2.9.2.tar.gz -C /usr/localmv /usr/local/hadoop-2.9.2 /usr/local/hadoop# 设置hadoop的环境变量echo 'export HADOOP_HOME=/usr/local/hadoop' &gt;&gt; /etc/bashrcecho 'export HADOOP_CONFIG_HOME=$HADOOP_HOME/etc/hadoop' &gt;&gt; /etc/bashrcecho 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' &gt;&gt; /etc/bashrcsource /etc/bashrc 3. hadoop准备1234567# 在hadoop目录下创建三个文件夹，cd $HADOOP_HOMEmkdir tmp namenode datanode# 根据模板创建配置文件cd $HADOOP_HOME/etc/hadoop/cp mapred-site.xml.template mapred-site.xml 4. hadoop设置vi core-site.xml1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi hdfs-site.xml1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/datanode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi mapred-site.xml123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; vi yarn-site.xml12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5. 配置slave节点12cd $HADOOP_HOMEvim etc/hadoop/slaves 内容如下： l12slave1slave2 6. ssh key生成ssh key，配置节点间的相互访问 12345678cd ~/ssh-keygen -q -t rsa -b 2048 -f /etc/ssh/ssh_host_rsa_key -N '' ssh-keygen -q -t ecdsa -f /etc/ssh/ssh_host_ecdsa_key -N ''ssh-keygen -t dsa -f /etc/ssh/ssh_host_ed25519_key -N ''ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsacd ~/.sshcat id_rsa.pub &gt;&gt; authorized_keys 7. 配置启动项新建启动脚本vi /root/run.sh，内容如下： 123#!/bin/bashecho '172.17.0.4 master' &gt;&gt; /etc/hosts/usr/sbin/sshd -D 设置脚本权限chmod +x /root/run.sh 退出容器exit 8. 保存镜像12# 5e为当前容器的id，hadoop为新建的镜像名称，v1为镜像版本docker commit 5e hadoop:v1 9. 启动节点123docker run -d -p 10012:22 --name slave1 hadoop:v1 /root/run.shdocker run -d -p 10022:22 --name slave2 hadoop:v1 /root/run.shdocker run -d -p 10002:22 -p 50070:50070 -p 8088:8088 --name master -h master -P --link slave1:slave1 --link slave2:slave2 hadoop:v1 /root/run.sh 10. 启动hadoop1234567891011# 进入master容器docker exec -it master /bin/bash# 格式化namenodehdfs namenode -format# 启动dfs和yarn，需要多次输入yesstart-dfs.sh# 启动yarnstart-yarn.sh 11. 验证访问 http://localhost:50070 ，进入datanode页面，可以看到有2个节点。","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"},{"name":"docker","slug":"docker","permalink":"http://tyrival.github.io/tags/docker/"}]},{"title":"SpringBoot05：Spring Boot与Tesseract集成","slug":"springboot-tesseract","date":"2018-07-08T06:26:12.000Z","updated":"2018-07-08T07:27:11.000Z","comments":true,"path":"posts/springboot-tesseract/","link":"","permalink":"http://tyrival.github.io/posts/springboot-tesseract/","excerpt":"本文介绍怎样基于Tesseract开发OCR的功能。","text":"本文介绍怎样基于Tesseract开发OCR的功能。 1. 源码地址：https://github.com/tyrival/SpringBoot-Dubbo-Sample 2. Tesseract2.1 准备 安装Tesseract，安装方法：https://github.com/tesseract-ocr/tesseract/wiki 下载官方的训练库，里面包含许多语言，这里只需要简体中文chi_sim.traineddata，下载地址：https://github.com/tesseract-ocr/tessdata 2.2 pom.xml最重要的是下面这个Tess4j， 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.tess4j&lt;/groupId&gt; &lt;artifactId&gt;tess4j&lt;/artifactId&gt; &lt;version&gt;4.0.2&lt;/version&gt; &lt;/dependency&gt;&lt;dependencies&gt; 2.3 Tessdata将第一步中下载的chi_sim.traineddata放在/src/main/resources/tessdata中，作为当前工程的训练库，基本可以识别大部分印刷体中文。如果有个性化的需求，例如艺术字、手写稿等，可以在网上搜索训练方法，非常简单，基本就是通过命令行加载并识别稿件，并对成果进行手工校准，校准完成之后就能形成个性化的训练库。 2.4 application.properties12# 设置训练库的路径，即在resources中的文件夹名tess.data=tessdata 2.4 OcrServiceImpl.java123456789101112131415161718192021222324252627282930313233343536import com.alibaba.dubbo.config.annotation.Service;import com.tyrival.common.ocr.OcrService;import com.tyrival.ocr.utils.ExcelUtil;import com.tyrival.ocr.utils.FileUtil;import com.tyrival.ocr.utils.OcrUtil;import com.tyrival.ocr.utils.WordUtil;import org.springframework.beans.factory.annotation.Value;import org.springframework.util.ClassUtils;@Service@org.springframework.stereotype.Servicepublic class OcrServiceImpl implements OcrService &#123; // application.properties中设置的tessData注入 @Value(\"$&#123;tess.data&#125;\") private String tessData; @Override public String doOCR(String filePath) throws Exception &#123; // word文件用poi读取 if (FileUtil.isWord(filePath)) &#123; return WordUtil.read(filePath); &#125; // excel文件用poi读取 if (FileUtil.isExcel(filePath)) &#123; return ExcelUtil.read(filePath); &#125; // 其他文件ocr，例如图片、pdf等 String result = OcrUtil.doOCR(filePath, this.getTessData()); return result; &#125; private String getTessData() &#123; return ClassUtils.getDefaultClassLoader().getResource(\"\").getPath() + tessData; &#125;&#125; 2.5 OrcUtil.java1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.tyrival.ocr.utils;import net.sourceforge.tess4j.ITesseract;import net.sourceforge.tess4j.Tesseract;import net.sourceforge.tess4j.TesseractException;import java.io.File;import java.io.FileNotFoundException;public class OcrUtil &#123; private final static String CHINESE = \"chi_sim\"; private final static String ENGLISH = \"eng\"; private static ITesseract instance; public static String doOCR(String filePath, String tessData) throws TesseractException, FileNotFoundException &#123; return doOCR(filePath, tessData, CHINESE); &#125; /* 过程非常简单 */ public static String doOCR(String filePath, String tessData, String language) throws TesseractException, FileNotFoundException &#123; ITesseract instance = getTesseract(); File file = new File(filePath); if (!file.isFile()) &#123; throw new FileNotFoundException(\"未找到 \" + filePath + \" 文件\"); &#125; // tessdata文件夹默认位置是工程根目录下/tessdata，即与/src目录同级 // 此处我们放在resources下，所以要进行手工设置datapath instance.setDatapath(tessData); instance.setLanguage(language); String result = instance.doOCR(file); return result; &#125; private static ITesseract getTesseract() &#123; if (instance == null) &#123; instance = new Tesseract(); &#125; return instance; &#125;&#125; 2.6 问题在MacOS下运行工程，如果通过controller模块中的/ocr/do接口运行，在识别过程中会崩溃，错误日志反应似乎是和dubbo有冲突，Windows和Linux还没测试，不知道是不是MacOS特有的。 解决办法：直接在ocr模块中建立controller，直接访问本模块的service，不通过dubbo进行远程调度，就不会出现这个问题。","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"SpringBoot04：基于Docker和Spring Boot部署开发Elastic","slug":"springboot-elastic","date":"2018-07-08T06:25:55.000Z","updated":"2018-07-08T07:27:01.000Z","comments":true,"path":"posts/springboot-elastic/","link":"","permalink":"http://tyrival.github.io/posts/springboot-elastic/","excerpt":"本文介绍基于Docker部署Elastic，并基于SpringBoot进行开发。","text":"本文介绍基于Docker部署Elastic，并基于SpringBoot进行开发。 1. 源码地址：https://github.com/tyrival/SpringBoot-Dubbo-Sample 2. Elasticsearch2.1 准备 创建目录~/Documents/Workspace/Docker/Elastic，其中创建config、data、plugins三个文件夹，分别用来储存配置文件、数据、插件 在config文件夹中创建配置文件elasticsearch.yml，只需要配置一个参数 1network.host: 0.0.0.0 elasticsearch.yml基本配置参数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475cluster.name: elasticsearch配置es的集群名称，默认是elasticsearch，es会自动发现在同一网段下的es，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。node.name: \"Franz Kafka\"节点名，默认随机指定一个name列表中名字，该列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。node.master: true指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。node.data: true指定该节点是否存储索引数据，默认为true。index.number_of_shards: 5设置默认索引分片个数，默认为5片。index.number_of_replicas: 1设置默认索引副本个数，默认为1个副本。path.conf: /path/to/conf设置配置文件的存储路径，默认是es根目录下的config文件夹。path.data: /path/to/data设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：path.data: /path/to/data1,/path/to/data2path.work: /path/to/work设置临时文件的存储路径，默认是es根目录下的work文件夹。path.logs: /path/to/logs设置日志文件的存储路径，默认是es根目录下的logs文件夹path.plugins: /path/to/plugins设置插件的存放路径，默认是es根目录下的plugins文件夹bootstrap.mlockall: true设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM和 ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit -l unlimited`命令。network.bind_host: 192.168.0.1设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。 network.publish_host: 192.168.0.1设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。network.host: 192.168.0.1这个参数是用来同时设置bind_host和publish_host上面两个参数。transport.tcp.port: 9300设置节点间交互的tcp端口，默认是9300。transport.tcp.compress: true设置是否压缩tcp传输时的数据，默认为false，不压缩。http.port: 9200设置对外服务的http端口，默认为9200。http.max_content_length: 100mb设置内容的最大容量，默认100mbhttp.enabled: false是否使用http协议对外提供服务，默认为true，开启。gateway.type: localgateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，Hadoop的HDFS，和amazon的s3服务器。gateway.recover_after_nodes: 1设置集群中N个节点启动时进行数据恢复，默认为1。gateway.recover_after_time: 5m设置初始化数据恢复进程的超时时间，默认是5分钟。gateway.expected_nodes: 2设置这个集群中节点的数量，默认为2，一旦这N个节点启动，就会立即进行数据恢复。cluster.routing.allocation.node_initial_primaries_recoveries: 4初始化数据恢复时，并发恢复线程的个数，默认为4。cluster.routing.allocation.node_concurrent_recoveries: 2添加删除节点或负载均衡时并发恢复线程的个数，默认为4。indices.recovery.max_size_per_sec: 0设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。indices.recovery.concurrent_streams: 5设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。discovery.zen.minimum_master_nodes: 1设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值（2-4）discovery.zen.ping.timeout: 3s设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。discovery.zen.ping.multicast.enabled: false设置是否打开多播发现节点，默认是true。discovery.zen.ping.unicast.hosts: [\"host1\", \"host2:port\", \"host3[portX-portY]\"]设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。下面是一些查询时的慢日志参数设置index.search.slowlog.level: TRACEindex.search.slowlog.threshold.query.warn: 10sindex.search.slowlog.threshold.query.info: 5sindex.search.slowlog.threshold.query.debug: 2sindex.search.slowlog.threshold.query.trace: 500msindex.search.slowlog.threshold.fetch.warn: 1sindex.search.slowlog.threshold.fetch.info: 800msindex.search.slowlog.threshold.fetch.debug:500msindex.search.slowlog.threshold.fetch.trace: 200ms 2.2 容器部署2.2.1 创建容器1234# -e \"cluster.name=elasticsearch\" 集群名称，相同名称的节点会进入同一集群# -e \"node.name=elas\" 节点名称，相同集群中节点名称保持唯一# -v 将配置文件、数据、插件挂载到容器中，使其保存在Docker外$ docker run -d -p 9200:9200 -p 9300:9300 --name elas -e \"cluster.name=elasticsearch\" -e \"node.name=elas\" -v ~/Documents/Workspace/Docker/Elastic/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml -v ~/Documents/Workspace/Docker/Elastic/data:/usr/share/elasticsearch/data -v ~/Documents/Workspace/Docker/Elastic/plugins:/usr/share/elasticsearch/plugins docker.elastic.co/elasticsearch/elasticsearch:6.3.0 2.2.2 安装插件12345678910111213### 进入容器$ docker exec -it elas /bin/bash### 安装分词插件# ./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.3.0/elasticsearch-analysis-ik-6.3.0.zip### 下面两个插件，如果不将本地plugins文件夹挂载到容器中，是会自动生成的，现在需手工安装# ./bin/elasticsearch-plugin install ingest-geoip# ./bin/elasticsearch-plugin install ingest-user-agent### 查看插件，三个插件安装完成# ls plugins/analysis-ik ingest-geoip ingest-user-agent 2.2.3 常用命令Elasticsearch是通过http请求进行操作的，常用指令如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990###### Elasticsearch6.x 对content-type验证采用了严格模式，不加--header会报错 ###### Content-Type header [application/x-www-form-urlencoded] is not supported# 创建index=accounts，其中包括一个type=person，# person包含三个字段，user，title，desc，都启用了ik分词插件$ curl --header \"content-type: application/JSON\" -X PUT 'localhost:9200/accounts' -d '&#123; \"mappings\": &#123; \"person\": &#123; \"properties\": &#123; \"user\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\" &#125;, \"title\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\" &#125;, \"desc\": &#123; \"type\": \"text\", \"analyzer\": \"ik_max_word\", \"search_analyzer\": \"ik_max_word\" &#125; &#125; &#125; &#125;&#125;'# 查看所有index$ curl -X GET 'http://localhost:9200/_cat/indices?v'# 删除index=accounts$ curl -X DELETE 'localhost:9200/accounts'# 在index=person创建id为1的一条记录，包括三个属性# 此时如果index=accounts不存在，会自动创建# PUT操作必须指定id，与post不同$ curl --header \"content-type: application/JSON\" -X PUT 'localhost:9200/accounts/person/1?pretty' -d '&#123; \"user\": \"张三\", \"title\": \"工程师\", \"desc\": \"数据库管理\"&#125;' # POST时可以不指定id，有系统自动生成$ curl -X POST 'localhost:9200/accounts/person' -d '&#123; \"user\": \"李四\", \"title\": \"工程师\", \"desc\": \"系统管理\"&#125;'# 查看type=person中id为1的记录$ curl 'localhost:9200/accounts/person/1?pretty'# 删除type=person中id=1的记录$ curl -X DELETE 'localhost:9200/accounts/person/1'# 查询所有记录$ curl 'localhost:9200/accounts/person/_search?pretty=true'# 查询满足desc包含‘管理’的记录$ curl --header \"content-type: application/JSON\" 'localhost:9200/accounts/person/_search?pretty' -d '&#123; \"query\" : &#123; \"match\" : &#123; \"desc\" : \"管理\" &#125;&#125;, \"from\": 1, \"size\": 1&#125;'# 多个关键词用空格分开，表示OR$ curl --header \"content-type: application/JSON\" 'localhost:9200/accounts/person/_search?pretty' -d '&#123; \"query\" : &#123; \"match\" : &#123; \"desc\" : \"数据库 系统\" &#125;&#125;&#125;'# 以下写法表示AND$ curl --header \"content-type: application/JSON\" 'localhost:9200/accounts/person/_search?pretty' -d '&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match\": &#123; \"desc\": \"数据库\" &#125; &#125;, &#123; \"match\": &#123; \"desc\": \"系统\" &#125; &#125; ] &#125; &#125;&#125;' 2.3 开发2.3.1 模块与solr类似，创建模块，创建相应的接口、配置文件等。 2.3.2 pom.xml参考solr模块的pom.xml，区别在于依赖如下 123456789101112131415161718192021222324252627282930313233&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.java.dev.jna&lt;/groupId&gt; &lt;artifactId&gt;jna&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt; &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.3.3 application.properties配置文件与solr类似，区别在于把solr的配置项换成elastic的 1234567## Elastic# 节点名字，默认elasticsearchspring.data.elasticsearch.cluster-name=elasticsearch# 节点地址，多个节点用逗号隔开spring.data.elasticsearch.cluster-nodes=127.0.0.1:9300# spring.data.elasticsearch.local=falsespring.data.elasticsearch.repositories.enable=true 2.3.4 ArticleRepository.javaArticleRepository相当于通常意义上的DAO层，用来与数据库直接进行交互 1234567import com.tyrival.entity.article.Article;import org.springframework.data.elasticsearch.repository.ElasticsearchRepository;import org.springframework.stereotype.Component;@Componentpublic interface ArticleRepository extends ElasticsearchRepository&lt;Article, Long&gt; &#123;&#125; 2.3.5 ArticleServiceImpl.javaService层直接调用articleRepository进行数据的操作，并将服务注册到Zookeeper 123456789101112131415161718192021222324252627282930313233343536373839import com.alibaba.dubbo.config.annotation.Service;import com.tyrival.common.article.ArticleService;import com.tyrival.elastic.repo.ArticleRepository;import com.tyrival.entity.article.Article;import org.elasticsearch.index.query.QueryStringQueryBuilder;import org.springframework.beans.factory.annotation.Autowired;import java.util.ArrayList;import java.util.Iterator;import java.util.List;@Service@org.springframework.stereotype.Servicepublic class ArticleServiceImpl implements ArticleService &#123; @Autowired private ArticleRepository articleRepository; @Override public void create(Article article) &#123; articleRepository.save(article); &#125; @Override public void delete(Article article) &#123; articleRepository.delete(article); &#125; @Override public List&lt;Article&gt; list(String keyword) &#123; QueryStringQueryBuilder builder = new QueryStringQueryBuilder(keyword); Iterable&lt;Article&gt; searchResult = articleRepository.search(builder); List&lt;Article&gt; list = new ArrayList&lt;&gt;(); for (Iterator iter = searchResult.iterator(); iter.hasNext();) &#123; list.add((Article) iter.next()); &#125; return list; &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"SpringBoot03：基于Docker和Spring Boot部署开发Solr","slug":"springboot-solr","date":"2018-07-08T06:25:50.000Z","updated":"2018-07-08T07:27:07.000Z","comments":true,"path":"posts/springboot-solr/","link":"","permalink":"http://tyrival.github.io/posts/springboot-solr/","excerpt":"本文介绍基于Docker部署Solr，并基于SpringBoot进行开发。","text":"本文介绍基于Docker部署Solr，并基于SpringBoot进行开发。 1. 源码地址：https://github.com/tyrival/SpringBoot-Dubbo-Sample 2. Solr2.1 准备 下载工程solr-7.4.0.zip（不带src的），解压缩。下载地址：http://lucene.apache.org/solr/ 创建目录~/Documents/Workspace/Docker/Solr，用来存储solr的所有cores 将工程solr-7.4.0/server/solr下所有文件，复制到刚创建的~/Documents/Workspace/Docker/Solr中 123456# 下载镜像solr:7.4.0，此版本需要和之前下载的工程版本保持一致$ docker pull solr# 已经下载过的镜像，可以通过以下代码查看版本# Config.ENV = [...SOLR_VERSION=7.4.0...]$ docker image inspect solr 2.2 容器部署1234# --name 命名容器名称# -v 将本地的文件夹挂载到容器内的文件夹，使solr的所有cores储存到本地目录# -p 将本地端口映射到容器端口$ docker run --privileged=true --name solr -v ~/Documents/Workspace/Docker/Solr:/opt/solr/server/solr -d -p 8983:8983 -t solr 2.3 创建core123456# 在name=solr的容器中，创建core=tyrival$ docker exec -it --user=solr solr bin/solr create_core -c tyrival# 此时在`~/Documents/Workspace/Docker/Solr`中可以看到多了tyrival文件夹，即新建的core# 在浏览器中访问http://localhost:8983/solr，会显示Solr Admin界面# 在左侧菜单的Core Selector中选择tyrival，可以看到core=tyrival的信息 2.4 配置 下载postgres的驱动，此处用postgresql-42.2.2.jar，复制到~/Documents/Workspace/Docker/Solr/lib中 将工程solr-7.4.0/example/example-DIH/solr/db/conf/db-data-config.xml，复制到~/Documents/Workspace/Docker/Solr/conf中，并编辑此文件 12345678910111213&lt;dataConfig&gt; &lt;!-- 数据库驱动，地址，用户名，密码 --&gt; &lt;dataSource type=\"JdbcDataSource\" driver=\"org.postgresql.Driver\" url=\"jdbc:postgresql://192.168.0.179:5432/postgres\" user=\"postgres\" password=\"123\"/&gt; &lt;document&gt; &lt;!-- 索引country表 --&gt; &lt;entity name=\"country\" query=\"select * from COUNTRY\" /&gt; &lt;/document&gt;&lt;/dataConfig&gt; 在数据库建表 12345678910111213141516171819create table country( id integer not null constraint country_pkey primary key, name varchar(50) not null, name_en varchar(100), continent varchar(50));comment on table countryis '国家表';create unique index country_id_uindex on country (id);insert into country (id, name, name_en, continent) values (1, '中华人民共和国', 'Republic of China', '亚洲')insert into country (id, name, name_en, continent) values (2, '大不列颠及北爱尔兰联合王国', 'United Kingdom of Great Britain and Northern Ireland', '欧洲')insert into country (id, name, name_en, continent) values (3, '德意志联邦共和国', 'Federal Republic of Germany', '欧洲')insert into country (id, name, name_en, continent) values (4, '朝鲜民主主义人民共和国', 'Democratic People''s Republic of Ko-rea', '亚洲')insert into country (id, name, name_en, continent) values (5, '法兰西共和国', 'French Republic', '欧洲') 编辑~/Documents/Workspace/Docker/Solr/conf/solrconfig.xml，设置DataImportHandler 1234567891011&lt;!-- 如果出现问题，就尝试把/dataimport写在/select之前 --&gt;&lt;requestHandler name=\"/dataimport\" class=\"solr.DataImportHandler\"&gt;&lt;lst name=\"defaults\"&gt; &lt;str name=\"config\"&gt;db-data-config.xml&lt;/str&gt;&lt;/lst&gt;&lt;/requestHandler&gt;&lt;requestHandler name=\"/select\" class=\"solr.SearchHandler\"&gt; &lt;lst name=\"defaults\"&gt; &lt;str name=\"echoParams\"&gt;explicit&lt;/str&gt; &lt;int name=\"rows\"&gt;10&lt;/int&gt; 重启Solr 12$ docker container stop [solr container id]$ docker container start [solr container id] 浏览器打开http://localhost:8983/solr，进入Solr Admin，左侧菜单Core Selector选择tyrival，然后选择Schema功能 点击右侧页面左上方的Add Field按钮，添加country表的name列 1234567name: name## 此处需要注意，如果选择text_general等类型，会导致后面查询结果时，name的值为数组，而不是字符串## 会造成查询结果解析时报BindingException异常field type: stringdefault: &apos;&apos;stored: 选中indexed: 选中 同样的方法添加name_en和continent列，然后可以在~/Documents/Workspace/Docker/Solr/conf/managed_schema中看到如下内容： 1234&lt;field name=\"continent\" type=\"string\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"id\" type=\"string\" multiValued=\"false\" indexed=\"true\" required=\"true\" stored=\"true\"/&gt;&lt;field name=\"name\" type=\"string\" indexed=\"true\" stored=\"true\"/&gt;&lt;field name=\"name_en\" type=\"string\" indexed=\"true\" stored=\"true\"/&gt; 此处如果主键名不是id，需要进行以下修改 12345&lt;!-- 将id修改为主键名 --&gt;&lt;uniqueKey&gt;id&lt;/uniqueKey&gt;&lt;!-- 改为required=\"false\" --&gt;&lt;field name=\"id\" type=\"string\" multiValued=\"false\" indexed=\"true\" required=\"true\" stored=\"true\"/&gt; 重启Solr 刷新Solr Admin页面，左侧选择core=tyrival，选DataImport菜单，进入数据导入页面 在数据导入页选全部导入Command=full-import，选择Entity=country，点击Execute，刷新页面，直到右侧出现绿色提示后，表示导入成功 123Indexing completed. Added/Updated: 5 documents. Deleted 0 documents.Requests: 1 , Fetched: 5 , Skipped: 0 , Processed: 5 Started: less than a minute ago 点击左侧菜单Query，进入查询页面，输入q=name_en:republic，点击Execute Query进行查询，可以查到相应的记录。 123456789101112131415161718192021222324252627282930313233&#123; \"responseHeader\":&#123; \"status\":0, \"QTime\":49, \"params\":&#123; \"q\":\"name:*共和国*\", \"_\":\"1530684926303\"&#125;&#125;, \"response\":&#123;\"numFound\":4,\"start\":0,\"docs\":[ &#123; \"continent\":\"亚洲\", \"name\":\"中华人民共和国\", \"id\":\"1\", \"name_en\":\"Republic of China\", \"_version_\":1605039455213715456&#125;, &#123; \"continent\":\"欧洲\", \"name\":\"德意志联邦共和国\", \"id\":\"3\", \"name_en\":\"Federal Republic of Germany\", \"_version_\":1605039455262998528&#125;, &#123; \"continent\":\"亚洲\", \"name\":\"朝鲜民主主义人民共和国\", \"id\":\"4\", \"name_en\":\"Democratic People's Republic of Ko-rea\", \"_version_\":1605039455264047104&#125;, &#123; \"continent\":\"欧洲\", \"name\":\"法兰西共和国\", \"id\":\"5\", \"name_en\":\"French Republic\", \"_version_\":1605039455265095680&#125;] &#125;&#125; 2.5 开发当solr部署完成后，可以进行二次开发，实现远程调用Solr应用，实现业务功能和solr引擎解耦，开发过程和user模块相似。 2.5.1 新建模块新建solr模块，并在根pom.xml中增加solr模块 1234&lt;modules&gt; ... &lt;module&gt;solr&lt;/module&gt;&lt;/modules&gt; 2.5.2 pom.xml参考user模块的pom.xml修改，继承根pom.xml，并引入spring-boot-starter-data-solr 1234567&lt;dependencies&gt; &lt;!-- solr --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-solr&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.5.3 application.properties配置文件中增加solr应用的访问地址，最后加上core名称tyrival，工程中实际配置在开发环境配置文件application-dev.properties中 12## solr 服务器spring.data.solr.host=http://127.0.0.1:8983/solr/tyrival 2.5.4 Country.java在common模块中创建实体时，必须加注解 类加@SolrDocument注解，solrCoreName的值为core名称，即tyrival 属性加@Field注解，如果表字段名与属性名不同，在@Field内标注表名 主键属性加@Id注解 123456789101112131415161718192021222324252627282930313233343536373839404142package com.tyrival.entity.country;import org.apache.solr.client.solrj.beans.Field;import org.springframework.data.annotation.Id;import org.springframework.data.solr.core.mapping.Indexed;import org.springframework.data.solr.core.mapping.SolrDocument;import java.io.Serializable;@SolrDocument(solrCoreName = \"tyrival\")public class Country implements Serializable &#123; /** * id */ @Id @Field(\"id\") private String id; /** * 名称 */ @Field(\"name\") @Indexed private String name; /** * 英文名 */ @Field(\"name_en\") @Indexed private String nameEn; /** * 所在州 */ @Field(\"continent\") @Indexed private String continent; /* getter &amp; setter */&#125; 2.5.5 CountryServiceImpl.java 记得类要加@com.alibaba.dubbo.config.annotation.Service和@org.springframework.stereotype.Service注解 SolrClient会被框架自动示例化注入 12345678910111213141516171819202122232425262728293031323334353637@Service@org.springframework.stereotype.Servicepublic class CountryServiceImpl implements CountryService &#123; @Autowired private SolrClient client; @Override public List&lt;Country&gt; listByPage(QueryParam queryParam) &#123; SolrQuery query = new SolrQuery(); int pageIndex = queryParam.getPage().getPageIndex(); int pageSize = queryParam.getPage().getPageSize(); // 这里设置的是从第几条数据开始，而不是从第几页开始 query.setStart((pageIndex - 1) * pageSize); query.setRows(pageSize); StringBuffer buffer = new StringBuffer(); Object name = queryParam.getConditions().get(\"name\"); if (name != null &amp;&amp; StringUtils.isNotBlank(name.toString())) &#123; // 此处需要在关键字两边加*号 buffer.append(\"name:\").append(\"*\").append(name.toString()).append(\"*\"); &#125; else &#123; buffer.append(\"*:*\"); &#125; query.set(\"q\", buffer.toString()); QueryResponse response = null; try &#123; response = client.query(query); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; // 如果之前在solr配置schema时，选择的type与Country类的属性类型不匹配的话 // 这里会报BindingException异常，因为查询出的属性值会是一个数组，而不是一个基本类型 List&lt;Country&gt; list = response.getBeans(Country.class); return list; &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"SpringBoot02：Spring Boot中的AOP","slug":"springboot-aop","date":"2018-07-08T06:25:37.000Z","updated":"2018-07-08T07:26:03.000Z","comments":true,"path":"posts/springboot-aop/","link":"","permalink":"http://tyrival.github.io/posts/springboot-aop/","excerpt":"本文介绍SpringBoot中AOP如何使用，包括拦截器和自定义注解。","text":"本文介绍SpringBoot中AOP如何使用，包括拦截器和自定义注解。 1. 源码地址：https://github.com/tyrival/SpringBoot-Dubbo-Sample 2. 拦截器Interceptor拦截器建立在controller模块中，此处以Token拦截器为例，讲解拦截器的配置方式，在调用接口时，拦截器比后面所说的AOP先发生作用。 2.1 依赖包拦截器依赖于spring-boot-starter-web，由于项目的根pom.xml已经引入，而controller的pom.xml继承自根pom.xml，所以无需重复引入 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- spring boot2.0的log4j依赖不全，排除，否则会报错 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 2.2 TokenInterceptor需要注意的是，此处拦截器所在的包为com.tyrival.controller.interceptor，而不是com.tyrival.interceptor，后者在模块启动时会扫描不到。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.tyrival.controller.interceptor;import com.tyrival.entity.user.User;import com.tyrival.enums.base.RequestAttrEnum;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class TokenInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception &#123; // 接受跨域访问 httpServletResponse.setHeader(\"Access-Control-Allow-Origin\", \"*\"); httpServletResponse.setHeader(\"Access-Control-Allow-Methods\", \"POST, GET, OPTIONS, DELETE\"); httpServletResponse.setHeader(\"Access-Control-Max-Age\", \"3600\"); httpServletResponse.setHeader(\"Access-Control-Allow-Headers\", \"x-requested-with, Authorization, Origin, Content-Type, Accept, token, apikey\"); String token = httpServletRequest.getParameter(\"token\"); User user = new User(); // TODO 解析TOKEN，验证有效性，将得到的用户信息赋予user，并注入请求 httpServletRequest.setAttribute(RequestAttrEnum.USER.getCode(), user); String newToken = \"\"; // TODO 生成新TOKEN httpServletResponse.setHeader(\"token\", newToken); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object o, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object o, Exception e) throws Exception &#123; &#125;&#125; 2.3 配置文件InterceptorConfig拦截器配置文件所处的包与拦截器相似，必须在controller之下建文件夹，否则也会扫描不到。 12345678910111213141516package com.tyrival.controller.config;import com.tyrival.controller.interceptor.TokenInterceptor;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class InterceptorConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 将拦截器加入序列，并增加URI匹配 registry.addInterceptor(new TokenInterceptor()).addPathPatterns(\"/**\"); &#125;&#125; 3. 自定义注解和AOP此处所有的注解都建立在controller模块中，与拦截器相同的是，此处的包都需要建立在com.tyrival.controller之下，否则SpringBoot也会扫描不到。 3.1 依赖包aop依赖于spring-boot-starter-aop，由于项目的根pom.xml已经引入，而controller的pom.xml继承自根pom.xml，所以无需重复引入 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 3.2 日志3.2.1 Log注解12345678910package com.tyrival.controller.annotation;import java.lang.annotation.*;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Log &#123; String value();&#125; 3.2.2 AOP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.tyrival.controller.aspect;import com.alibaba.dubbo.common.utils.StringUtils;import com.tyrival.controller.annotation.Log;import com.tyrival.entity.user.User;import com.tyrival.enums.base.RequestAttrEnum;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;import org.aspectj.lang.reflect.CodeSignature;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.stereotype.Component;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import java.lang.reflect.Method;@Aspect@Componentpublic class LogAspect &#123; // 设置切面为user包下所有类的所有方法 @Pointcut(\"execution(public * com.tyrival.controller.user.*.*(..))\") public void log() &#123; &#125; @Around(\"log()\") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; // 获取请求 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // 获取请求中由Token拦截器注入的用户信息 User user = (User) request.getAttribute(RequestAttrEnum.USER.getCode()); if (user == null || StringUtils.isBlank(user.getId())) &#123; // TODO 记录为游客 &#125; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); // 类名 String className = signature.getDeclaringTypeName(); // 方法名 Method method = signature.getMethod(); String methodName = method.getName(); // 参数 Object[] arguments = joinPoint.getArgs(); // 参数名称 String[] parameterNames = ((CodeSignature) joinPoint.getSignature()).getParameterNames(); Object result = joinPoint.proceed(); // 如存在Log注解，需要记录日志 if (method.isAnnotationPresent(Log.class)) &#123; Log annotation = method.getAnnotation(Log.class); // 获取Log注解内的参数 String type = annotation.value(); // TODO 记录日志 System.out.println(\"记录日志......\"); &#125; return result; &#125;&#125; 3.3 权限3.3.1 Permission注解12345678910package com.tyrival.controller.annotation;import java.lang.annotation.*;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Permission &#123; &#125; 3.3.2 AOP123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.tyrival.controller.aspect;import com.tyrival.controller.annotation.Permission;import com.tyrival.entity.user.User;import com.tyrival.enums.base.RequestAttrEnum;import com.tyrival.exception.CommonException;import com.tyrival.exception.ExceptionEnum;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.aspectj.lang.reflect.MethodSignature;import org.springframework.stereotype.Component;import org.springframework.web.context.request.RequestContextHolder;import org.springframework.web.context.request.ServletRequestAttributes;import javax.servlet.http.HttpServletRequest;import java.lang.reflect.Method;@Aspect@Componentpublic class PermissionAspect &#123; @Pointcut(\"execution(public * com.tyrival.controller.user.*.*(..))\") public void permission()&#123;&#125; @Around(\"permission()\") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; // 获取请求 ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); // 获取请求中由Token拦截器注入的用户信息 User user = (User) request.getAttribute(RequestAttrEnum.USER.getCode()); // 类名 MethodSignature signature = (MethodSignature) joinPoint.getSignature(); String className = signature.getDeclaringTypeName(); // 方法名 Method method = signature.getMethod(); String methodName = method.getName(); // 包含Permission注解时，进行权限验证 if (method.isAnnotationPresent(Permission.class) || !hasPermission(user, className, methodName)) &#123; throw new CommonException(ExceptionEnum.NO_PERMISSION); &#125; return joinPoint.proceed(); &#125; private boolean hasPermission(User user, String className, String methodName) &#123; // TODO 根据用户信息、类名、方法名，查询用户是否有该权限 return true; &#125;&#125; 3.4 示例123456789101112131415161718192021222324252627@RestControllerpublic class UserControllerImpl implements UserController &#123; // 记录为insert类日志，@Permission表示需要验证权限 @Override @Log(\"insert\") @Permission public Result create(HttpServletRequest request, HttpServletResponse response, User user) &#123; user = userService.create(user); return new Result(user); &#125; // 记录为query类日志，无@Permission注解表示无需验证权限 @Override @Log(\"query\") public Result list(HttpServletRequest request, HttpServletResponse response, QueryParam queryParam) &#123; List&lt;User&gt; list = userService.list(queryParam); return new Result(list); &#125; // 无需记录日志，无需验证权限 @Override public Result listByPage(HttpServletRequest httpReq, HttpServletResponse httpRsp, QueryParam queryParam) &#123; PageResult result = userService.listByPage(queryParam); return new Result(result); &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"SpringBoot01：基于Spring Boot、Dubbo、Redis、Mybtis搭建分布式开发项目","slug":"springboot-dubbo-mybatis-redis","date":"2018-06-19T00:49:02.000Z","updated":"2018-07-08T07:26:14.000Z","comments":true,"path":"posts/springboot-dubbo-mybatis-redis/","link":"","permalink":"http://tyrival.github.io/posts/springboot-dubbo-mybatis-redis/","excerpt":"本文从零开始，讲述基于Spring Boot、Dubbo搭建一个分布式开发项目，并集成Redis、Mybatis及其分页插件PageHelper的所有步骤。文中所用的IDE为Intellij IDEA，JDK版本为1.8。","text":"本文从零开始，讲述基于Spring Boot、Dubbo搭建一个分布式开发项目，并集成Redis、Mybatis及其分页插件PageHelper的所有步骤。文中所用的IDE为Intellij IDEA，JDK版本为1.8。 1. 概述完整源码：https://github.com/tyrival/SpringBoot-Dubbo-Sample 2. 步骤2.1 创建工程菜单-File-New-Project，选择Spring Initializr 12Project SDK: JDK1.8Initializr Service Url: 默认 https://start.spring.io 点Next，进入Project Metadata界面，填写信息 12345Group: com.tyrivalArfifact: springboot-dubbo-sampleType: Maven Project其余项目保持自动生成的值 点Next，进入Dependencies，由于工程本身不开发任何代码，只用于管理maven信息，从而提供给各模块进行继承，所以不选择任何依赖包，直接点Next，然后填写信息 123Project name: springboot-dubbo-sample // 与Project Metadata保持一致其余项目保持自动生成的值 点击Finish，工程创建成功，如果默认生成了src、.mvn、mvnw、mvnw.cmd等文件，将其全部删除。 2.2 创建模块菜单-File-New-Module，选择Spring Initializr 12Project SDK: JDK1.8Initializr Service Url: 默认 https://start.spring.io 点Next，进入Project Metadata界面，填写信息 12345Group: com.tyrivalArfifact: commonType: Maven Project其余项目保持自动生成的值 点Next，进入Dependencies，不选择任何依赖包，直接点Next，然后填写信息 123Module name: common // 与Project Metadata保持一致其余项目保持自动生成的值 点击Finish，模块创建完成，并用相同的方式创建controller、redis、user模块。 2.3 pom.xml2.3.1 项目的根pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;springboot-dubbo-sample&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 必须修改为pom --&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;springboot-dubbo-sample&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;!-- spring boot2.0的log4j依赖不全，排除，否则会报错 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!-- spring boot2.0的log4j依赖不全，排除，否则会报错 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring Boot Dubbo 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!-- 排除javassist-3.15.0-GA并升级，否则用lambda，会报invalid constant type: 18 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Javassist --&gt; &lt;dependency&gt; &lt;groupId&gt;org.javassist&lt;/groupId&gt; &lt;artifactId&gt;javassist&lt;/artifactId&gt; &lt;version&gt;3.18.2-GA&lt;/version&gt; &lt;/dependency&gt; &lt;!-- common --&gt; &lt;dependency&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- AOP --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- guava --&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;23.3-jre&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入各模块 --&gt; &lt;modules&gt; &lt;module&gt;user&lt;/module&gt; &lt;module&gt;redis&lt;/module&gt; &lt;module&gt;controller&lt;/module&gt; &lt;module&gt;common&lt;/module&gt; &lt;/modules&gt; &lt;!-- 管理Maven编译参数 --&gt; &lt;!-- 在编译时，通过增加参数\" -P 环境参数\"，会根据参数加载不同配置 --&gt; &lt;!-- 例如：\"-P dev\"表示调用开发环境配置 --&gt; &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;profileActive&gt;dev&lt;/profileActive&gt; &lt;/properties&gt; &lt;!-- 不加任何参数时，默认调用dev环境配置 --&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;prod&lt;/id&gt; &lt;properties&gt; &lt;profileActive&gt;prod&lt;/profileActive&gt; &lt;/properties&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- Maven编译配置 --&gt; &lt;build&gt; &lt;!-- 配置资源文件 --&gt; &lt;resources&gt; &lt;resource&gt; &lt;!-- 配置资源目录 --&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;!-- 排除所有资源文件 --&gt; &lt;excludes&gt; &lt;exclude&gt;application.properties&lt;/exclude&gt; &lt;exclude&gt;application-dev.properties&lt;/exclude&gt; &lt;exclude&gt;application-prod.properties&lt;/exclude&gt; &lt;/excludes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;!-- 标识构建时所需要的配置文件 --&gt; &lt;includes&gt; &lt;include&gt;application.properties&lt;/include&gt; &lt;!-- $&#123;profileActive&#125;这个值会在maven构建时传入 --&gt; &lt;include&gt;application-$&#123;profileActive&#125;.properties&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.codehaus.cargo&lt;/groupId&gt; &lt;artifactId&gt;cargo-maven2-plugin&lt;/artifactId&gt; &lt;version&gt;1.6.5&lt;/version&gt; &lt;configuration&gt; &lt;container&gt; &lt;!-- 指明使用的tomcat服务器版本 --&gt; &lt;containerId&gt;tomcat8x&lt;/containerId&gt; &lt;type&gt;remote&lt;/type&gt; &lt;/container&gt; &lt;configuration&gt; &lt;type&gt;runtime&lt;/type&gt; &lt;cargo.remote.username&gt;admin&lt;/cargo.remote.username&gt; &lt;cargo.remote.password&gt;password&lt;/cargo.remote.password&gt; &lt;/configuration&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;deploy&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;redeploy&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- 添加插件maven-resources-plugin，maven构建时替换参数 --&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.2&lt;/version&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;delimiter&gt;@&lt;/delimiter&gt; &lt;/delimiters&gt; &lt;useDefaultDelimiters&gt;false&lt;/useDefaultDelimiters&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.3.2 common模块的pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;common&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- common模块作为所有模块的依赖，编译为jar --&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;common&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.3.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3.3 controller模块的pom.xml1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;controller&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 修改为war --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;controller&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;springboot-dubbo-sample&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt;&lt;/project&gt; 2.3.4 user模块的pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;user&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 修改为war --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;user&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;springboot-dubbo-sample&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.3.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- PageHelper --&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Mysql --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- PostgreSQL --&gt; &lt;dependency&gt; &lt;groupId&gt;org.postgresql&lt;/groupId&gt; &lt;artifactId&gt;postgresql&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.3.5 redis模块的pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;redis&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;!-- 修改为war --&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;name&gt;redis&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;com.tyrival&lt;/groupId&gt; &lt;artifactId&gt;springboot-dubbo-sample&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring2.0 集成 redis 所需 common-pool2 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.5.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.40&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 2.4 子模块2.4.1 commoncommon作为其他所有模块的依赖，主要功能是声明各模块通用的Entity、Exception、Enumeration和Service接口。其中的SpringBootApplication和配置文件无需修改 2.4.2 useruser是一个以用户管理为示例开发的模块，主要负责向外提供UserService服务的实现，并与数据库进行用户信息的交换，下面列举部分主要源码。 com.tyrival.user.UserApplication 1234567891011121314151617import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;@SpringBootApplicationpublic class UserApplication extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; return builder.sources(UserApplication.class); &#125; public static void main(String[] args) &#123; SpringApplication.run(UserApplication.class, args); &#125;&#125; com.tyrival.user.service.UserServiceImpl 1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.alibaba.dubbo.config.annotation.Service;import com.github.pagehelper.PageHelper;import com.github.pagehelper.PageInfo;import com.tyrival.entity.base.PageResult;import com.tyrival.entity.param.QueryParam;import com.tyrival.entity.user.User;import com.tyrival.common.user.UserService;import com.tyrival.user.dao.UserDAO;import org.springframework.beans.factory.annotation.Autowired;import java.util.List;import java.util.UUID;// dubbo的服务注解，将此服务注册到dubbo注册中心，不可遗漏@Service// spring的服务注解，用于依赖注入@org.springframework.stereotype.Servicepublic class UserServiceImpl implements UserService &#123; @Autowired private UserDAO userDAO; @Override public User create(User user) &#123; user.setId(UUID.randomUUID().toString()); int i = userDAO.create(user); return i == 1 ? user : null; &#125; @Override public List&lt;User&gt; list(QueryParam queryParam) &#123; return userDAO.find(queryParam); &#125; @Override public PageResult listByPage(QueryParam queryParam) &#123; PageInfo pageInfo = PageHelper.startPage(1, 10) .doSelectPageInfo(() -&gt; userDAO.find(queryParam)); long totalCount = pageInfo.getTotal(); queryParam.getPage().setTotalCount(totalCount); PageResult result = new PageResult(pageInfo.getList(), queryParam.getPage()); return result; &#125;&#125; src/main/resources/application.properties 12345678## 通用配置文件，任何环境都要用到的配置在此处# 接收mavan构建时的-P参数，用于引入不同环境的配置文件spring.profiles.active=@profileActive@# mybatis配置文件引入mybatis.config-locations=classpath:mybatis/mybatis-config.xmlmybatis.mapper-locations=classpath:mybatis/mapper/*.xml src/main/resources/application-dev.properties 12345678910111213141516171819## dev开发环境下特有的配置记录在此# logging配置logging.level.root=infologging.file=tyrival-log/user-log.log# 数据源spring.datasource.driverClassName = org.postgresql.Driverspring.datasource.url = jdbc:postgresql://10.211.55.14:5432/postgres?useUnicode=true&amp;characterEncoding=utf-8spring.datasource.username = postgresspring.datasource.password = 123# Dubbo 服务注册中心spring.dubbo.application.name=user-providerspring.dubbo.registry.address=zookeeper://192.168.0.179:2181spring.dubbo.protocol.name=dubbospring.dubbo.protocol.port=20880# 扫描包内的所有dubbo的@Service注解，将其发布为RPC服务spring.dubbo.scan=com.tyrival.user.service 2.4.3 controllercontroller模块主要负责调用user模块发布的RPC服务，然后通过http协议对外提供服务。类似user模块，具体参考源码。 2.4.4 redisredis模块主要负责与redis服务器进行数据交互。类似user模块，具体参考源码。 3. 部署可以手工或利用Jenkins等自动化工具进行部署。在用Maven对各模块进行编译时，在命令行最后加上-P 参数，可在编译时引入不同的Spring Boot配置文件，从而对各类环境进行区分，参数包括开发环境dev和生产环境prod。","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"MacOS下配置Github多账号教程","slug":"git-multi-account","date":"2018-05-04T13:42:21.000Z","updated":"2018-05-05T02:27:45.000Z","comments":true,"path":"posts/git-multi-account/","link":"","permalink":"http://tyrival.github.io/posts/git-multi-account/","excerpt":"使用GIthub的过程中，有时会出现同时用到多个账号的情况，这次介绍下怎样在MacOS下配置多个账号。","text":"使用GIthub的过程中，有时会出现同时用到多个账号的情况，这次介绍下怎样在MacOS下配置多个账号。 生成ssh key 12345678$ cd ~/.ssh#用另一个github账号生成key$ ssh-keygen -t rsa -C \"second@gmail.com\"Generating public/private rsa key pair.#此处需要输入另一个私钥文件的名称，不能用默认的id_rsaEnter file in which to save the key (/Users/asir/.ssh/id_rsa): id_rsa_website 将新的ssh key添加到ssh agent中，使ssh能识别新的私钥 1$ ssh-add ~/.ssh/id_rsa_website 配置config文件 1234567891011121314$ vim config#以下为config内容#Default Github(tyrival@qq.com)Host github.com #第一域名HostName github.com #固定值，不修改User git #固定值，不修改IdentityFile ~/.ssh/id_rsa #第一个私钥文件路径#Website(tyrival@vip.qq.com)Host website.github.com #第二域名，自由定义，使用git时要用到HostName github.com #固定值，不修改User git #固定值，不修改IdentityFile ~/.ssh/id_rsa_website #第二个私钥文件路径 在Github中添加公钥，这个遇到Github改版有可能会变化，就不具体说了，可以在网上查询最新的方法 测试两个域名 123456#符号'@'后跟的域名就是config中配置的两个Host$ ssh -T git@github.com$ ssh -T git@website.github.com#出现下面的消息就说明成功了Hi tyrival! You've successfully authenticated, but GitHub does not provide shell access. 使用git方法 12#其中用到的域名替换为config中对应的host参数值$ git clone website.github.com:tyrival/sample.git 如果使用Hexo，提交时可能会出现下列错误 123456789Error: remote: Permission to tyrival/tyrival.github.io.git denied to tyrivalhome.fatal: unable to access 'https://github.com/tyrival/tyrival.github.io.git/': The requested URL returned error: 403#我修改了一下Hexo/_config.yml文件就正常了，不知道是不是问题所在deploy: type: git repository: git@github.com:tyrival/tyrival.github.io.git branch: master#repository原本是http的路径，改成git@xxx就好了","categories":[{"name":"工具","slug":"工具","permalink":"http://tyrival.github.io/categories/工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://tyrival.github.io/tags/git/"}]},{"title":"前端双向数据绑定的优势","slug":"two-way-data-binding","date":"2018-03-16T13:17:50.000Z","updated":"2018-03-16T14:52:53.000Z","comments":true,"path":"posts/two-way-data-binding/","link":"","permalink":"http://tyrival.github.io/posts/two-way-data-binding/","excerpt":"双向数据绑定是现在前端框架中很流行的一种技术，当前最流行的三大前端框架AngularJS、React、Vue均对其做了实现。通过 View &lt;-&gt; ViewModal &lt;=&gt; Modal的mvvm模型，使View的变化能触发Model的修改，Model的变化也能触发View的修改。本文不讨论双向数据绑定的功能实现，仅仅从最简单的层面分析其优势。","text":"双向数据绑定是现在前端框架中很流行的一种技术，当前最流行的三大前端框架AngularJS、React、Vue均对其做了实现。通过 View &lt;-&gt; ViewModal &lt;=&gt; Modal的mvvm模型，使View的变化能触发Model的修改，Model的变化也能触发View的修改。本文不讨论双向数据绑定的功能实现，仅仅从最简单的层面分析其优势。 业务逻辑假设有如下业务场景： 有3个INPUT，需要三者的值始终保持一致 事件驱动在未实现双向数据绑定时，我们的所有前端操作都属于事件驱动型，也就是为不同的DOM附加各种EventLIstener，当事件触发时，对页面和数据进行操作。 下面以jquery为例对上述逻辑进行实现 123456789101112131415161718&lt;input id=\"A\"/&gt;&lt;input id=\"B\"/&gt;&lt;input id=\"C\"/&gt;&lt;script&gt; $(\"#A\").on(\"keydown\", function() &#123; $(\"#B\").val($(this).val()) $(\"#C\").val($(this).val()) &#125;) $(\"#B\").on(\"keydown\", function() &#123; $(\"#A\").val($(this).val()) $(\"#C\").val($(this).val()) &#125;) $(\"#C\").on(\"keydown\", function() &#123; $(\"#A\").val($(this).val()) $(\"#B\").val($(this).val()) &#125;)&lt;/script&gt; 可见上述逻辑看起来非常简单，但实际业务场景复杂度远远超过这个，当一个DOM发生变化时，也许要操作多个DOM，所以，双向数据绑定诞生了。 数据驱动双向数据绑定后，所有的变化都是由数据的变化来驱动的，所以称为数据驱动型。同样来解决上面提到的业务需求，这里以vue为例来写代码，angular和react的代码逻辑类似。如下： 12345678910111213&lt;input id=\"A\" v-bind:value=\"inputVal\"/&gt;&lt;input id=\"B\" v-bind:value=\"inputVal\"/&gt;&lt;input id=\"C\" v-bind:value=\"inputVal\"/&gt;&lt;script&gt; export default &#123; data() &#123; return &#123; inputVal: '' &#125; &#125; &#125;&lt;/script&gt; 可以看到上面的代码非常简单，没有任何事件的监听，其中v-bind:value=&#39;inputVal&#39;里的v-bind:表示将input的属性value与下面数据集中的inputVal属性绑定，甚至可以更简单的写成:value=&quot;inputVal&quot;。与事件驱动型的代码比较起来，仅仅看代码的行数就少了50%。 更复杂的例子我们下面看一个更复杂的例子，来比较事件驱动和数据驱动的开发工作量。 例如：一个任务卡片有4个状态（未提交、运行、完成、错误），显示在任务卡的状态栏中，还有5个功能按钮（运行、删除、编辑、详情、日志），需要根据任务卡的状态来修改状态栏文本，以及判断5个功能按钮是否应该显示。 事件驱动 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;div class=\"card\"&gt; &lt;div id=\"status\"&gt;未提交&lt;/div&gt; &lt;button id=\"run\"&gt;运行&lt;/button&gt; &lt;button id=\"delete\"&gt;删除&lt;/button&gt; &lt;button id=\"edit\"&gt;编辑&lt;/button&gt; &lt;button id=\"reset\"&gt;重置&lt;/button&gt; &lt;button id=\"log\"&gt;日志&lt;/button&gt;&lt;/div&gt;&lt;script&gt; var changeWithStatus = function (status) &#123; $(\"#status\").html(status) switch(status) &#123; case \"未提交\": $(\"#run\").show(); $(\"#delete\").show(); $(\"#edit\").show(); $(\"#reset\").show(); $(\"#log\").hide(); break; case \"运行\": $(\"#run\").hide(); $(\"#delete\").hide(); $(\"#edit\").hide(); $(\"#reset\").hide(); $(\"#log\").hide(); break; case \"完成\": $(\"#run\").hide(); $(\"#delete\").hide(); $(\"#edit\").hide(); $(\"#reset\").show(); $(\"#log\").show(); break; case \"错误\": $(\"#run\").show(); $(\"#delete\").show(); $(\"#edit\").show(); $(\"#reset\").hide(); $(\"#log\").show(); break; &#125; &#125;&lt;/script&gt; 数据驱动 其中，v-show表示将元素是否显示，绑定到相应的属性或方法，根据属性值或方法的返回值来判断元素是否显示，在下面这种场景下，如果我要在另一个地方改变卡片的状态，例如this.status = &#39;错误&#39;这时所有设置了v-show绑定的button，都会根据status变化成的状态”错误”，来重新渲染其是否显示。 12345678910111213141516171819202122&lt;div class=\"card\"&gt; &lt;div&gt;&#123;&#123; status &#125;&#125;&lt;/div&gt; &lt;button v-show=\"canOperater\"&gt;运行&lt;/button&gt; &lt;button v-show=\"canOperater\"&gt;删除&lt;/button&gt; &lt;button v-show=\"canOperater\"&gt;编辑&lt;/button&gt; &lt;button v-show=\"status == '完成'\"&gt;重置&lt;/button&gt; &lt;button v-show=\"status == '完成' || status == '错误'\"&gt;日志&lt;/button&gt;&lt;/div&gt;&lt;script&gt; export default &#123; data() &#123; return &#123; status: '' &#125; &#125;, methods: &#123; canOperate: function() &#123; return this.status == '未提交' || status =='错误'\" &#125; &#125; &#125;&lt;/script&gt; 综合上面的例子来看，实现了双向数据绑定的框架，代码逻辑更加清晰，代码量少了一半左右，开发效率更高。","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"前端跨域及解决方案","slug":"cors-solutions","date":"2018-03-15T01:41:08.000Z","updated":"2018-03-16T06:07:18.000Z","comments":true,"path":"posts/cors-solutions/","link":"","permalink":"http://tyrival.github.io/posts/cors-solutions/","excerpt":"我们一般说的跨域，是在同源策略限制下，浏览器从一个域请求另一个域的资源。同源策略（SOP，Same origin policy）是浏览器的一种安全策略。也就是说，当浏览器打开A域后，在A域内如果需要访问B域的资源，如果B域不允许跨域访问，浏览器就会报禁止跨域的错误，而如果在A域中对B域的资源进行代理，浏览器 -&gt; A域 -&gt; 代理 -&gt; B域，就不会出现禁止跨域的错误。 同源指的是【协议+域名+端口】都相同，否则即使两个域名指向同一个IP，也不是同源。","text":"我们一般说的跨域，是在同源策略限制下，浏览器从一个域请求另一个域的资源。同源策略（SOP，Same origin policy）是浏览器的一种安全策略。也就是说，当浏览器打开A域后，在A域内如果需要访问B域的资源，如果B域不允许跨域访问，浏览器就会报禁止跨域的错误，而如果在A域中对B域的资源进行代理，浏览器 -&gt; A域 -&gt; 代理 -&gt; B域，就不会出现禁止跨域的错误。 同源指的是【协议+域名+端口】都相同，否则即使两个域名指向同一个IP，也不是同源。 同源策略主要限制了以下几种场景： Cookie、LocalStorage和IndexDB的无法读取 DOM和JS对象无法获得 AJAX请求不能发送 常见跨域场景123456789101112131415域名不同（即使是主域和子域也属于跨域）http://www.google.com/a.jshttp://map.google.com/b.js端口不同http://192.168.0.10:8080http://192.168.0.10:8090协议不同http://192.168.0.10:8080https://192.168.0.10:8080域名和对应IPhttp://www.tyival.comhttp://192.168.0.100 常见解决方案 JSONP document.domain + ifame location.hash + iframe window.name + iframe postMessage 跨域资源共享 nginx代理 nodejs中间件代理 WebSocket协议 1. JSONP我们在工程中经常会遇到引入在线的css、js等资源的情况，这种跨域引用是通过script标签进行实现的，这说明script标签是允许跨域的。我们可以动态创建script，再请求一个带参网址，从而实现跨域，如下： 12345678910111213&lt;script&gt; var script = document.createElement('script'); script.type = 'text/javascript'; // 传参并指定回调执行函数为onBack script.src = 'http://www.domain.com:8080/login?user=admin&amp;callback=onBack'; document.head.appendChild(script); // 回调执行函数 function onBack(res) &#123; // 此处可以获取到类似 &#123;\"status\": true, \"data\": \"\"&#125; 的结果 &#125;&lt;/script&gt; 从以上代码可以看到，JSONP有一个最大缺点——只能创建GET请求\u0010。 2. document.domain + iframe此方案只适用于主域相同，子域不同的场景。主要原理是两个页面都用js强制设置document.domain为主域，就实现了同源。 父窗口 123456&lt;!-- http://www.domain.com/a.html --&gt;&lt;iframe id=\"iframe\" src=\"http://child.domain.com/b.html\"&gt;&lt;/iframe&gt;&lt;script&gt; document.domain = 'domain.com'; var user = 'admin';&lt;/script&gt; 子窗口 123456&lt;!-- http://child.domain.com/b.html --&gt;&lt;script&gt; document.domain = 'domain.com'; // 获取父窗口中变量，值为admin console.log(window.parent.user);&lt;/script&gt; 3. location.hash + iframe实现原理： a欲与b跨域相互通信，通过中间页c来实现。不同域之间利用iframe的location.hash传值，相同域之间通过js访问来通信。 具体实现：A域：a.html -&gt; B域：b.html -&gt; A域：c.html，a与b不同域只能通过hash值单向通信，b与c也不同域也只能单向通信，但c与a同域，所以c可通过parent.parent访问a页面所有对象。 a.html 123456789101112131415&lt;!-- http://www.domain1.com/a.html --&gt;&lt;iframe id=\"iframe\" src=\"http://www.domain2.com/b.html\" style=\"display:none;\"&gt;&lt;/iframe&gt;&lt;script&gt; var iframe = document.getElementById('iframe'); // 向b.html传hash值 setTimeout(function() &#123; iframe.src = iframe.src + '#user=admin'; &#125;, 1000); // 开放给同域c.html的回调方法 function onCallback(res) &#123; alert('data from c.html ---&gt; ' + res); &#125;&lt;/script&gt; b.html 12345678910&lt;!-- http://www.domain2.com/b.html --&gt;&lt;iframe id=\"iframe\" src=\"http://www.domain1.com/c.html\" style=\"display:none;\"&gt;&lt;/iframe&gt;&lt;script&gt; var iframe = document.getElementById('iframe'); // 监听a.html传来的hash值，再传给c.html window.onhashchange = function () &#123; iframe.src = iframe.src + location.hash; &#125;;&lt;/script&gt; c.html 12345678&lt;!-- http://www.domain1.com/c.html --&gt;&lt;script&gt; // 监听b.html传来的hash值 window.onhashchange = function () &#123; // 再通过操作同域a.html的js回调，将结果传回 window.parent.parent.onCallback('hello: ' + location.hash.replace('#user=', '')); &#125;;&lt;/script&gt; 4. window.name + iframewindow.name属性的独特之处：name值在不同的页面（甚至不同域名）加载后依旧存在，并且可以支持非常长的 name 值（2MB）。 a.html 123456789101112131415161718192021222324252627282930313233343536&lt;!-- http://www.domain1.com/a.html --&gt;var proxy = function(url, callback) &#123; var state = 0; var iframe = document.createElement('iframe'); // 加载跨域页面 iframe.src = url; // onload事件会触发2次，第1次加载跨域页，并留存数据于window.name iframe.onload = function() &#123; if (state === 1) &#123; // 第2次onload(同域proxy页)成功后，读取同域window.name中数据 callback(iframe.contentWindow.name); destoryFrame(); &#125; else if (state === 0) &#123; // 第1次onload(跨域页)成功后，切换到同域代理页面 iframe.contentWindow.location = 'http://www.domain1.com/proxy.html'; state = 1; &#125; &#125;; document.body.appendChild(iframe); // 获取数据以后销毁这个iframe，释放内存；这也保证了安全（不被其他域frame js访问） function destoryFrame() &#123; iframe.contentWindow.document.write(''); iframe.contentWindow.close(); document.body.removeChild(iframe); &#125;&#125;;// 请求跨域b页面数据proxy('http://www.domain2.com/b.html', function(data)&#123; alert(data);&#125;); proxy.html 12&lt;!-- http://www.domain1.com/proxy.html --&gt;&lt;!-- 中间代理页，与a.html同域，内容为空即可。 --&gt; b.html 1234&lt;!-- http://www.domain2.com/b.html --&gt;&lt;script&gt; window.name = 'This is domain2 data!';&lt;/script&gt; 总结：通过iframe的src属性由外域转向本地域，跨域数据即由iframe的window.name从外域传递到本地域。这个就巧妙地绕过了浏览器的跨域访问限制，但同时它又是安全操作。 5. postMessagepostMessage是HTML5 XMLHttpRequest Level 2中的API，且是为数不多可以跨域操作的window属性之一，它可用于解决以下方面的问题： 页面和其打开的新窗口的数据传递 多窗口之间消息传递 页面与嵌套的iframe消息传递 上面三个场景的跨域数据传递 用法：postMessage(data,origin)方法接受两个参数data： html5规范支持任意基本类型或可复制的对象，但部分浏览器只支持字符串，所以传参时最好用JSON.stringify()序列化。origin： 协议+主机+端口号，也可以设置为”*”，表示可以传递给任意窗口，如果要指定和当前窗口同源的话设置为”/“。 a.html 1234567891011121314151617&lt;!-- http://www.domain1.com/a.html --&gt;&lt;iframe id=\"iframe\" src=\"http://www.domain2.com/b.html\" style=\"display:none;\"&gt;&lt;/iframe&gt;&lt;script&gt; var iframe = document.getElementById('iframe'); iframe.onload = function() &#123; var data = &#123; name: 'aym' &#125;; // 向domain2传送跨域数据 iframe.contentWindow.postMessage(JSON.stringify(data), 'http://www.domain2.com'); &#125;; // 接受domain2返回数据 window.addEventListener('message', function(e) &#123; alert('data from domain2 ---&gt; ' + e.data); &#125;, false);&lt;/script&gt; b.html 123456789101112131415&lt;!-- http://www.domain2.com/b.html --&gt;&lt;script&gt; // 接收domain1的数据 window.addEventListener('message', function(e) &#123; alert('data from domain1 ---&gt; ' + e.data); var data = JSON.parse(e.data); if (data) &#123; data.number = 16; // 处理后再发回domain1 window.parent.postMessage(JSON.stringify(data), 'http://www.domain1.com'); &#125; &#125;, false);&lt;/script&gt; 6. 跨域资源共享通常只需要在服务端设置Access-Control-Allow-Origin为*即可，例如可以在SpringMVC拦截器里加入如下代码： 123456789101112131415161718192021public class CorsInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o) throws Exception &#123; // 接受跨域访问 httpServletResponse.setHeader(\"Access-Control-Allow-Origin\", \"*\"); httpServletResponse.setHeader(\"Access-Control-Allow-Methods\", \"POST, GET, OPTIONS, DELETE\"); httpServletResponse.setHeader(\"Access-Control-Max-Age\", \"3600\"); httpServletResponse.setHeader(\"Access-Control-Allow-Headers\", \"x-requested-with, Authorization, Origin, Content-Type, Accept, token, apikey\"); return true; &#125; @Override public void postHandle(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, ModelAndView modelAndView) throws Exception &#123; &#125; @Override public void afterCompletion(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Object o, Exception e) throws Exception &#123; &#125;&#125; 但是，如果需要在跨域访问时，Request Header中带上Cookie信息，还需要进行如下设置： 前端 原生ajax 123456789101112131415// IE8/9需用window.XDomainRequest兼容var xhr = new XMLHttpRequest();// 前端设置是否带cookiexhr.withCredentials = true;xhr.open('post', 'http://www.domain2.com:8080/login', true);xhr.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');xhr.send('user=admin');xhr.onreadystatechange = function() &#123; if (xhr.readyState == 4 &amp;&amp; xhr.status == 200) &#123; alert(xhr.responseText); &#125;&#125;; jquery 12345678910$.ajax(&#123; ... // 前端设置是否带cookie xhrFields: &#123; withCredentials: true &#125;, // 会让请求头中包含跨域的额外信息，但不会含cookie crossDomain: true, ...&#125;); 后端 Java后台拦截器 1234// 本系统只允许来自 http://www.domain.com:port 域的请求跨域访问资源response.setHeader(\"Access-Control-Allow-Origin\", \"http://www.domain.com:port\"); // 允许ajax等跨域访问携带cookieresponse.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); Nodejs后台示例： 123456789101112131415161718192021222324252627282930313233var http = require('http');var server = http.createServer();var qs = require('querystring');server.on('request', function(req, res) &#123; var postData = ''; // 数据块接收中 req.addListener('data', function(chunk) &#123; postData += chunk; &#125;); // 数据接收完毕 req.addListener('end', function() &#123; postData = qs.parse(postData); // 跨域后台设置 res.writeHead(200, &#123; // 后端允许发送Cookie 'Access-Control-Allow-Credentials': 'true', // 允许访问的域（协议+域名+端口） 'Access-Control-Allow-Origin': 'http://www.domain1.com', // HttpOnly:脚本无法读取cookie 'Set-Cookie': 'l=a123456;Path=/;Domain=www.domain2.com;HttpOnly' &#125;); res.write(JSON.stringify(postData)); res.end(); &#125;);&#125;);server.listen('8080');console.log('Server is running at port 8080...'); 7. nginx代理1、 nginx配置解决iconfont跨域浏览器跨域访问js、css、img等常规静态资源被同源策略许可，但iconfont字体文件(eot|otf|ttf|woff|svg)例外，此时可在nginx的静态资源服务器中加入以下配置。 123location / &#123; add_header Access-Control-Allow-Origin *;&#125; 2、 nginx反向代理接口跨域跨域原理： 同源策略是浏览器的安全策略，不是HTTP协议的一部分。服务器端调用HTTP接口只是使用HTTP协议，不会执行JS脚本，不需要同源策略，也就不存在跨越问题。 实现思路：通过nginx配置一个代理服务器（域名与domain1相同，端口不同）做跳板机，反向代理访问domain2接口，并且可以顺便修改cookie中domain信息，方便当前域cookie写入，实现跨域登录。 nginx具体配置 123456789101112131415#proxy服务器server &#123; listen 81; server_name www.domain1.com; location / &#123; proxy_pass http://www.domain2.com:8080; #反向代理 proxy_cookie_domain www.domain2.com www.domain1.com; #修改cookie里域名 index index.html index.htm; # 当用webpack-dev-server等中间件代理接口访问nignx时，此时无浏览器参与，故没有同源限制，下面的跨域配置可不启用 add_header Access-Control-Allow-Origin http://www.domain1.com; #当前端只跨域不带cookie时，可为* add_header Access-Control-Allow-Credentials true; &#125;&#125; 前端代码 12345678var xhr = new XMLHttpRequest();// 前端开关：浏览器是否读写cookiexhr.withCredentials = true;// 访问nginx中的代理服务器xhr.open('get', 'http://www.domain1.com:81/?user=admin', true);xhr.send(); Nodejs后台 123456789101112131415161718var http = require('http');var server = http.createServer();var qs = require('querystring');server.on('request', function(req, res) &#123; var params = qs.parse(req.url.substring(2)); // 向前台写cookie res.writeHead(200, &#123; 'Set-Cookie': 'l=a123456;Path=/;Domain=www.domain2.com;HttpOnly' // HttpOnly:脚本无法读取 &#125;); res.write(JSON.stringify(params)); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...'); 8. Nodejs中间件代理跨域node中间件实现跨域代理，原理大致与nginx相同，都是通过启一个代理服务器，实现数据的转发，也可以通过设置cookieDomainRewrite参数修改响应头中cookie中域名，实现当前域的cookie写入，方便接口登录认证。 非vue框架的跨域（2次跨域）利用node + express + http-proxy-middleware搭建一个proxy服务器。 前端代码 12345678var xhr = new XMLHttpRequest();// 前端开关：浏览器是否读写cookiexhr.withCredentials = true;// 访问http-proxy-middleware代理服务器xhr.open('get', 'http://www.domain1.com:3000/login?user=admin', true);xhr.send(); 中间件服务器 123456789101112131415161718192021var express = require('express');var proxy = require('http-proxy-middleware');var app = express();app.use('/', proxy(&#123; // 代理跨域目标接口 target: 'http://www.domain2.com:8080', changeOrigin: true, // 修改响应头信息，实现跨域并允许带cookie onProxyRes: function(proxyRes, req, res) &#123; res.header('Access-Control-Allow-Origin', 'http://www.domain1.com'); res.header('Access-Control-Allow-Credentials', 'true'); &#125;, // 修改响应信息中的cookie域名 cookieDomainRewrite: 'www.domain1.com' // 可以为false，表示不修改&#125;));app.listen(3000);console.log('Proxy server is listen at port 3000...'); Nodejs后台同（6. nginx） 2、 vue框架的跨域（1次跨域）利用node + webpack + webpack-dev-server代理接口跨域。在开发环境下，由于vue渲染服务和接口代理服务都是webpack-dev-server同一个，所以页面与代理接口之间不再跨域，无须设置headers跨域信息了。 webpack.config.js部分配置： 12345678910111213141516module.exports = &#123; entry: &#123;&#125;, module: &#123;&#125;, ... devServer: &#123; historyApiFallback: true, proxy: [&#123; context: '/login', target: 'http://www.domain2.com:8080', // 代理跨域目标接口 changeOrigin: true, secure: false, // 当代理某些https服务报错时用 cookieDomainRewrite: 'www.domain1.com' // 可以为false，表示不修改 &#125;], noInfo: true &#125;&#125; 9. WebSocket协议跨域WebSocket protocol是HTML5一种新的协议。它实现了浏览器与服务器全双工通信，同时允许跨域通讯，是server push技术的一种很好的实现。原生WebSocket API使用起来不太方便，我们使用Socket.io，它很好地封装了webSocket接口，提供了更简单、灵活的接口，也对不支持webSocket的浏览器提供了向下兼容。 前端代码： 12345678910111213141516171819202122&lt;div&gt;user input：&lt;input type=\"text\"&gt;&lt;/div&gt;&lt;script src=\"./socket.io.js\"&gt;&lt;/script&gt;&lt;script&gt;var socket = io('http://www.domain2.com:8080');// 连接成功处理socket.on('connect', function() &#123; // 监听服务端消息 socket.on('message', function(msg) &#123; console.log('data from server: ---&gt; ' + msg); &#125;); // 监听服务端关闭 socket.on('disconnect', function() &#123; console.log('Server socket has closed.'); &#125;);&#125;);document.getElementsByTagName('input')[0].onblur = function() &#123; socket.send(this.value);&#125;;&lt;/script&gt; Nodejs socket后台： 1234567891011121314151617181920212223242526var http = require('http');var socket = require('socket.io');// 启http服务var server = http.createServer(function(req, res) &#123; res.writeHead(200, &#123; 'Content-type': 'text/html' &#125;); res.end();&#125;);server.listen('8080');console.log('Server is running at port 8080...');// 监听socket连接socket.listen(server).on('connection', function(client) &#123; // 接收信息 client.on('message', function(msg) &#123; client.send('hello：' + msg); console.log('data from client: ---&gt; ' + msg); &#125;); // 断开处理 client.on('disconnect', function() &#123; console.log('Client socket has closed.'); &#125;); 附：Java代理跨域请求123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245package cn.o.utils;import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONObject;import org.apache.commons.io.FileUtils;import org.apache.http.HttpEntity;import org.apache.http.client.config.RequestConfig;import org.apache.http.client.methods.CloseableHttpResponse;import org.apache.http.client.methods.HttpGet;import org.apache.http.client.methods.HttpPost;import org.apache.http.client.protocol.HttpClientContext;import org.apache.http.entity.ContentType;import org.apache.http.entity.StringEntity;import org.apache.http.entity.mime.MultipartEntityBuilder;import org.apache.http.entity.mime.content.FileBody;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.HttpClients;import org.apache.http.impl.client.RedirectLocations;import org.apache.http.protocol.BasicHttpContext;import org.apache.http.protocol.HttpContext;import org.apache.http.util.EntityUtils;import java.io.File;import java.io.IOException;import java.net.URI;public class HttpHelper &#123; public static JSONObject httpGet(String url)&#123; HttpGet httpGet = new HttpGet(url); CloseableHttpResponse response = null; CloseableHttpClient httpClient = HttpClients.createDefault(); RequestConfig requestConfig = RequestConfig.custom(). setSocketTimeout(2000).setConnectTimeout(2000).build(); httpGet.setConfig(requestConfig); try &#123; response = httpClient.execute(httpGet, new BasicHttpContext()); if (response.getStatusLine().getStatusCode() != 200) &#123; System.out.println(\"request url failed, http code=\" + response.getStatusLine().getStatusCode() + \", url=\" + url); return null; &#125; HttpEntity entity = response.getEntity(); if (entity != null) &#123; String resultStr = EntityUtils.toString(entity, \"utf-8\"); JSONObject result = JSON.parseObject(resultStr); if (result.getInteger(\"errcode\") == 0) &#123; return result; &#125; else &#123; System.out.println(\"request url=\" + url + \",return value=\"); System.out.println(resultStr); int errCode = result.getInteger(\"errcode\"); String errMsg = result.getString(\"errmsg\"); &#125; &#125; &#125; catch (IOException e) &#123; System.out.println(\"request url=\" + url + \", exception, msg=\" + e.getMessage()); e.printStackTrace(); &#125; finally &#123; if (response != null) try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125; public static JSONObject httpPost(String url, Object data) &#123; HttpPost httpPost = new HttpPost(url); CloseableHttpResponse response = null; CloseableHttpClient httpClient = HttpClients.createDefault(); RequestConfig requestConfig = RequestConfig.custom(). setSocketTimeout(2000).setConnectTimeout(2000).build(); httpPost.setConfig(requestConfig); httpPost.addHeader(\"Content-Type\", \"application/json\"); try &#123; StringEntity requestEntity = new StringEntity(JSON.toJSONString(data), \"utf-8\"); httpPost.setEntity(requestEntity); response = httpClient.execute(httpPost, new BasicHttpContext()); if (response.getStatusLine().getStatusCode() != 200) &#123; System.out.println(\"request url failed, http code=\" + response.getStatusLine().getStatusCode() + \", url=\" + url); return null; &#125; HttpEntity entity = response.getEntity(); if (entity != null) &#123; String resultStr = EntityUtils.toString(entity, \"utf-8\"); JSONObject result = JSON.parseObject(resultStr); if (result.getInteger(\"errcode\") == 0) &#123; result.remove(\"errcode\"); result.remove(\"errmsg\"); return result; &#125; else &#123; System.out.println(\"request url=\" + url + \",return value=\"); System.out.println(resultStr); int errCode = result.getInteger(\"errcode\"); String errMsg = result.getString(\"errmsg\"); &#125; &#125; &#125; catch (IOException e) &#123; System.out.println(\"request url=\" + url + \", exception, msg=\" + e.getMessage()); e.printStackTrace(); &#125; finally &#123; if (response != null) try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125; public static JSONObject uploadMedia(String url, File file)&#123; HttpPost httpPost = new HttpPost(url); CloseableHttpResponse response = null; CloseableHttpClient httpClient = HttpClients.createDefault(); RequestConfig requestConfig = RequestConfig.custom().setSocketTimeout(2000).setConnectTimeout(2000).build(); httpPost.setConfig(requestConfig); HttpEntity requestEntity = MultipartEntityBuilder.create().addPart(\"media\", new FileBody(file, ContentType.APPLICATION_OCTET_STREAM, file.getName())).build(); httpPost.setEntity(requestEntity); try &#123; response = httpClient.execute(httpPost, new BasicHttpContext()); if (response.getStatusLine().getStatusCode() != 200) &#123; System.out.println(\"request url failed, http code=\" + response.getStatusLine().getStatusCode() + \", url=\" + url); return null; &#125; HttpEntity entity = response.getEntity(); if (entity != null) &#123; String resultStr = EntityUtils.toString(entity, \"utf-8\"); JSONObject result = JSON.parseObject(resultStr); if (result.getInteger(\"errcode\") == 0) &#123; // 成功 result.remove(\"errcode\"); result.remove(\"errmsg\"); return result; &#125; else &#123; System.out.println(\"request url=\" + url + \",return value=\"); System.out.println(resultStr); int errCode = result.getInteger(\"errcode\"); String errMsg = result.getString(\"errmsg\"); &#125; &#125; &#125; catch (IOException e) &#123; System.out.println(\"request url=\" + url + \", exception, msg=\" + e.getMessage()); e.printStackTrace(); &#125; finally &#123; if (response != null) try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125; public static JSONObject downloadMedia(String url, String fileDir) &#123; HttpGet httpGet = new HttpGet(url); CloseableHttpResponse response = null; CloseableHttpClient httpClient = HttpClients.createDefault(); RequestConfig requestConfig = RequestConfig.custom().setSocketTimeout(2000).setConnectTimeout(2000).build(); httpGet.setConfig(requestConfig); try &#123; HttpContext localContext = new BasicHttpContext(); response = httpClient.execute(httpGet, localContext); RedirectLocations locations = (RedirectLocations) localContext.getAttribute(HttpClientContext.REDIRECT_LOCATIONS); if (locations != null) &#123; URI downloadUrl = locations.getAll().get(0); String filename = downloadUrl.toURL().getFile(); System.out.println(\"downloadUrl=\" + downloadUrl); File downloadFile = new File(fileDir + File.separator + filename); FileUtils.writeByteArrayToFile(downloadFile, EntityUtils.toByteArray(response.getEntity())); JSONObject obj = new JSONObject(); obj.put(\"downloadFilePath\", downloadFile.getAbsolutePath()); obj.put(\"httpcode\", response.getStatusLine().getStatusCode()); return obj; &#125; else &#123; if (response.getStatusLine().getStatusCode() != 200) &#123; System.out.println(\"request url failed, http code=\" + response.getStatusLine().getStatusCode() + \", url=\" + url); return null; &#125; HttpEntity entity = response.getEntity(); if (entity != null) &#123; String resultStr = EntityUtils.toString(entity, \"utf-8\"); JSONObject result = JSON.parseObject(resultStr); if (result.getInteger(\"errcode\") == 0) &#123; // 成功 result.remove(\"errcode\"); result.remove(\"errmsg\"); return result; &#125; else &#123; System.out.println(\"request url=\" + url + \",return value=\"); System.out.println(resultStr); int errCode = result.getInteger(\"errcode\"); String errMsg = result.getString(\"errmsg\"); &#125; &#125; &#125; &#125; catch (IOException e) &#123; System.out.println(\"request url=\" + url + \", exception, msg=\" + e.getMessage()); e.printStackTrace(); &#125; finally &#123; if (response != null) try &#123; response.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return null; &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"Java反射：通过方法名调用方法","slug":"java-reflect-invoke-method","date":"2018-03-08T01:57:44.000Z","updated":"2018-03-08T02:21:46.000Z","comments":true,"path":"posts/java-reflect-invoke-method/","link":"","permalink":"http://tyrival.github.io/posts/java-reflect-invoke-method/","excerpt":"在开发中，有时希望像Javascript一样，用 object[&#39;property&#39;] = xxx 的方式，对属性进行遍历和赋值，这就需要用到Java中的反射。","text":"在开发中，有时希望像Javascript一样，用 object[&#39;property&#39;] = xxx 的方式，对属性进行遍历和赋值，这就需要用到Java中的反射。 封装一个辅助类，将对象包装起来，对外暴露的是类似invokeMethod(String methodName)这样，通过方法名调用对象方法的API。下面是辅助类代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128import java.lang.reflect.Field;import java.lang.reflect.Method;import java.util.Hashtable;import java.util.regex.Pattern;public class ReflectObject &#123; // 存放需要包装的对象 private Object object; // 对象的类 private Class cls; // 对象的属性 private String[] props; // 存放getter方法 private Hashtable&lt;String, Method&gt; getMethods = null; // 存放setter方法 private Hashtable&lt;String, Method&gt; setMethods = null; // 存放其他方法 private Hashtable&lt;String, Method&gt; methods = null; /** * 定义构造方法 * @param o 需要包装对象 */ public ReflectObject(Object o) &#123; object = o; initMethods(); &#125; /** * 初始化 */ public void initMethods() &#123; getMethods = new Hashtable&lt;String, Method&gt;(); setMethods = new Hashtable&lt;String, Method&gt;(); methods = new Hashtable&lt;String, Method&gt;(); cls = object.getClass(); Field[] fields = cls.getDeclaredFields(); props = new String[fields.length]; for(int i = 0; i &lt; fields.length; i++) &#123; props[i] = fields[i].getName(); &#125; Method[] allMethods = cls.getMethods(); // 定义正则表达式，从方法中过滤出getter / setter 函数. String gs = &quot;get(\\\\w+)&quot;; Pattern getM = Pattern.compile(gs); String ss = &quot;set(\\\\w+)&quot;; Pattern setM = Pattern.compile(ss); // 把方法中的&quot;set&quot; 或者 &quot;get&quot; 去掉 String rapl = &quot;$1&quot;; String param; for (int i = 0; i &lt; allMethods.length; ++i) &#123; Method m = allMethods[i]; String methodName = m.getName(); if (Pattern.matches(gs, methodName)) &#123; param = getM.matcher(methodName).replaceAll(rapl).toLowerCase(); getMethods.put(param, m); &#125; else if (Pattern.matches(ss, methodName)) &#123; param = setM.matcher(methodName).replaceAll(rapl).toLowerCase(); setMethods.put(param, m); &#125; this.methods.put(methodName, m); &#125; &#125; /** * 调用object的属性property的setter方法 * @property: 属性名 * @value: 给属性赋的值 */ public boolean setMethodValue(String property, Object value) throws Exception &#123; Method m = setMethods.get(property.toLowerCase()); if (m != null) &#123; try &#123; // 调用目标类的setter函数 m.invoke(object, value); return true; &#125; catch (Exception ex) &#123; throw new Exception(&quot;对象的[&quot; + property + &quot;]属性的setter方法执行时报错。&quot;); &#125; &#125; throw new Exception(&quot;未查询到对象的[&quot; + property + &quot;]属性的setter方法。&quot;); &#125; /** * 调用object的属性property的getter方法 * @property: 属性名 */ public Object getMethodValue(String property) throws Exception &#123; Method m = getMethods.get(property.toLowerCase()); if (m != null) &#123; try &#123; // 调用目标类的getter函数 Object o = m.invoke(object); return o; &#125; catch (Exception ex) &#123; throw new Exception(&quot;对象的[&quot; + property + &quot;]属性的getter方法执行时报错。&quot;); &#125; &#125; throw new Exception(&quot;未查询到对象的[&quot; + property + &quot;]属性的getter方法。&quot;); &#125; /** * 调用object的methodName方法 * @methodName: 方法名 * @params: methodName接受的参数数组 */ public Object invokeMethod(String methodName, Object[] params) throws Exception &#123; Method m = methods.get(methodName); if (m == null) &#123; throw new Exception(&quot;未找到对象的[&quot; + methodName + &quot;]方法。&quot;); &#125; return m.invoke(this.object, params); &#125; /** * object的getter，可以获取ReflectObject的实例包装的对象object */ public Object getObject() &#123; return object; &#125; /** * props的getter，可以获取ReflectObject的实例包装的对象object的所有属性 */ public String[] getProps() &#123; return props; &#125;&#125; 调用方式： 12345678910111213141516171819202122public static void main(String[] args) &#123; User user = new User(); ReflectObject reflectObject = new ReflectObject(user); reflectObject.setMethodValue(&quot;name&quot;, &quot;张三&quot;); reflectObject.setMethodValue(&quot;age&quot;, 16); reflectObject.invokeMethod(&quot;say&quot;, [&quot;李四&quot;, &quot;你好。&quot;]); // 输出：张三对李四说：你好。&#125;public Class User &#123; private String name; private Integer age; public void say(String targetUser, String content) &#123; console.log(this.name + &quot;对&quot; + targetUser + &quot;说：&quot; + content + &quot;&quot;); &#125; public String getName() &#123; return this.name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return this.age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"Java动态编译","slug":"java-dynamic-compile","date":"2018-03-08T00:44:12.000Z","updated":"2018-03-08T02:00:24.000Z","comments":true,"path":"posts/java-dynamic-compile/","link":"","permalink":"http://tyrival.github.io/posts/java-dynamic-compile/","excerpt":"JDK1.6加入了编译API，开发者可以在代码中调用API，从而动态编译Java源代码，下面举个例子来讲解具体用法。","text":"JDK1.6加入了编译API，开发者可以在代码中调用API，从而动态编译Java源代码，下面举个例子来讲解具体用法。 直接上源码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140package cn.o.test;import javax.tools.*;import java.io.*;import java.util.*;import java.util.regex.Matcher;import java.util.regex.Pattern;import javax.tools.JavaCompiler.CompilationTask;public class DynamicCompiler &#123; /** * 匹配包名的正则 */ private static final String REG_EX = \"(?&lt;=package\\\\s).*(?=;)\"; /** * 缓存已编译的脚本的名称和Hash值，Map&lt;类名, Hash值&gt; */ private static Map&lt;String, String&gt; classCache = new HashMap&lt;&gt;(); /** * 编译源码，返回Class * @srcFilePath: 源文件绝对路径 */ public static Class compile(String srcFilePath) throws Exception &#123; // 实例化编译器 JavaCompiler compiler = ToolProvider.getSystemJavaCompiler(); // 实例化源文件管理器 StandardJavaFileManager fileManager = compiler.getStandardFileManager(null, null, null); // 实例化日志管理器 DiagnosticCollector&lt;JavaFileObject&gt; diagnostics = new DiagnosticCollector&lt;JavaFileObject&gt;(); // 通过文件名获取类名 File srcFile = new File(srcFilePath); String className = srcFile.getName(); // 解析包名，获得类全名 String packageName = getPackageName(srcFilePath); String fullClassName = packageName + \".\" + className; // 获取源码的hash String hash = String.valueOf(readFile(srcFilePath).hashCode()); // 通过比较类名对应的Hash，判断类是否已编译过，且是否更改 String originalHash = classCache.get(fullClassName); // 如果源码未做改动，则直接返回已编译过的类 if (originalHash != null &amp;&amp; hash.equals(originalHash)) &#123; return Class.forName(fullClassName); &#125; // 获取要编译的编译单元 List&lt;File&gt; srcFileList = new ArrayList&lt;File&gt;(); srcFileList.add(srcFile); Iterable&lt;? extends JavaFileObject&gt; compilationUnits = fileManager.getJavaFileObjectsFromFiles(srcFileList); /* * 编译参数， * -encoding：编码方式为utf-8 * -classpath：依赖包和依赖的classpath绝对路径，用半角冒号:隔开 * -d：编译的目标绝对路径 */ String dependencies = \"/lib/ABC.jar:/lib/DEF.jar:/lib/GHI.jar\"; String targetPath = \"/compile/source/to/this/path\"; Iterable&lt;String&gt; options = Arrays.asList( \"-encoding\", \"utf-8\", \"-classpath\", dependencies, \"-d\", targetPath); // 获取编译任务 CompilationTask compilationTask = compiler.getTask( null, fileManager, diagnostics, options, null, compilationUnits); // 运行编译任务 Boolean result = compilationTask.call(); if (!result) &#123; // 此处可以DEBUG查看或打印diagnostics对象的内容，从而查看编译失败原因 throw new Exception(fullClassName + \"编译失败。\"); &#125; // 销毁文件管理器 fileManager.close(); // 储存编译的类的hash classCache.put(fullClassName, hash); return Class.forName(fullClassName); &#125; /** * 从源文件中获得包名 * @param srcPath */ private static String getPackageName(String srcPath) throws Exception &#123; String result = null; BufferedReader br; Pattern packagePattern = Pattern.compile(REG_EX); try &#123; br = new BufferedReader(new FileReader(srcPath)); String data = br.readLine(); while (data != null) &#123; if (data.indexOf(\"package\") != -1) &#123; Matcher m = packagePattern.matcher(data); if (m.find()) &#123; result = m.group(); &#125; break; &#125; data = br.readLine(); &#125; br.close(); &#125; catch (IOException e) &#123; throw new Exception(\"获取包名失败\"); &#125; return result; &#125; /** * 读取源码内容 * @srcFilePath: 源文件绝对路径 */ private static String readFile(String srcFilePath) &#123; BufferedReader br = null; String line = null; StringBuffer buf = new StringBuffer(); try &#123; br = new BufferedReader(new InputStreamReader(new FileInputStream(srcFilePath), \"UTF-8\")); while ((line = br.readLine()) != null) &#123; buf.append(line).append(\"\\n\"); &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; // 关闭流 if (br != null) &#123; try &#123; br.close(); &#125; catch (IOException e) &#123; br = null; &#125; &#125; &#125; return buf.toString(); &#125;&#125; 调用方式 12345public static void main(String[] args) &#123; Class klass = DynamicCompiler.compile(&quot;/absolute/path/of/java/source/file.java&quot;); Object object = klass.newInstance(); // do something&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"java","slug":"java","permalink":"http://tyrival.github.io/tags/java/"}]},{"title":"Python01：MacOS升级Python2到Python3，以及误删系统自带Python的解决方法","slug":"python-01","date":"2018-03-03T11:57:14.000Z","updated":"2018-03-03T12:38:08.000Z","comments":true,"path":"posts/python-01/","link":"","permalink":"http://tyrival.github.io/posts/python-01/","excerpt":"刚开始学Python，想装个Python3.6，一看MacOS自带Python2.7，就在网上搜升级方法，结果第一条搜索是个坑！也不知道在哪搞了个半截的教程贴上来的，误人子弟！系统自带的Python2.7是很多系统级应用的依赖，比如xcode什么的。所以，千万、千万、千万不要删除系统自带的Python2.7！！！ 如果已经看了那个教程掉坑了，可以按照下面的方法解决。","text":"刚开始学Python，想装个Python3.6，一看MacOS自带Python2.7，就在网上搜升级方法，结果第一条搜索是个坑！也不知道在哪搞了个半截的教程贴上来的，误人子弟！系统自带的Python2.7是很多系统级应用的依赖，比如xcode什么的。所以，千万、千万、千万不要删除系统自带的Python2.7！！！ 如果已经看了那个教程掉坑了，可以按照下面的方法解决。 从以下两个渠道获取相应的文件，替换误删或误改的文件 TimeMachine的备份 从另一台系统版本相同的Mac 文件清单如下： /System/Library/Frameworks/Python.framework/Versions/2.7 /System/Library/Frameworks/Python.framework/Versions/Current /usr/bin/pydoc /usr/bin/python /usr/bin/pythonw /usr/bin/python-config 修改python2.7的权限 1$ sudo chown -R root:wheel /System/Library/Frameworks/Python.framework/Versions/2.7 将~/.bash_profile中增加的Python 3.6的PATH变量去掉 删掉/System/Library/Frameworks/Python.framework/Versions/3.x文件夹 用homebrew安装python3（homebrew安装方式自行搜索） 1$ brew install python3","categories":[{"name":"后端","slug":"后端","permalink":"http://tyrival.github.io/categories/后端/"}],"tags":[{"name":"python","slug":"python","permalink":"http://tyrival.github.io/tags/python/"}]},{"title":"算法03：回归算法","slug":"algorithm-03","date":"2018-02-25T09:58:52.000Z","updated":"2018-02-26T03:22:21.000Z","comments":true,"path":"posts/algorithm-03/","link":"","permalink":"http://tyrival.github.io/posts/algorithm-03/","excerpt":"回归算法（Regression）是研究自变量和因变量之间关系的一种预测模型技术。回归算法与分类算法类似，是基于已有的数据样本，对未来的样本进行预测。回归算法与分类算法也有不同，主要区别在于输出变量的类型。回归是定量的输出\u0010\u0010，即连续变量的预测；分类是定性的输出，即离散变量的预测。例如：预测明天的温度，是回归任务；预测明天是晴天还是雨天，是分类任务。回归算法可以通过三种方法分类：自变量的个数、因变量的类型和回归线的形状，主要包括线性回归、逻辑回归、多项式回归、逐步回归等多种算法。","text":"回归算法（Regression）是研究自变量和因变量之间关系的一种预测模型技术。回归算法与分类算法类似，是基于已有的数据样本，对未来的样本进行预测。回归算法与分类算法也有不同，主要区别在于输出变量的类型。回归是定量的输出\u0010\u0010，即连续变量的预测；分类是定性的输出，即离散变量的预测。例如：预测明天的温度，是回归任务；预测明天是晴天还是雨天，是分类任务。回归算法可以通过三种方法分类：自变量的个数、因变量的类型和回归线的形状，主要包括线性回归、逻辑回归、多项式回归、逐步回归等多种算法。 均值（mean）：又称平均数或平均值 $$x=\\cfrac{\\sum_{i=1}^n x_i}{n}$$ 中位数（median）：将数据中各数值按照大小顺序排列，位于中间位置的变量 众数（mode）：数据中出现次数最多的数 方差（variance）：描述离散程度的衡量方式，此处的$x$为平均数 $$s^2=\\cfrac{\\sum_{i=1}^n (x_i-x)^2}{n}$$ 标准差（standard deviation）：将方差开方就得到标准差 线性回归（Linear Regression）对于一组分布在二维坐标系上的样本，线性回归的目标是找到一条描述样本变化规律的线，使所有样本尽可能接近这条线。 例如：找到房屋的面积、房间数对价格的影响，现有以下数据： 面积 房间数 价格 210 3 40.0 160 3 33.1 240 3 36.9 141 2 23.2 300 4 54.0 假设有一个公式，能够根据面积和房间数算出价格，这个公式不仅满足现在的样本数据，在新的数据上也要尽量准确，假定这个公式是线性函数： $$h(x)=\\theta_0+\\theta_1 x_1+\\theta_2 x_2$$ 其中，$x_1$和$x_2$分别表示面积和房间数，$\\theta$表示权重，$h(x)$是房屋的价格。 首先把他看作一条$y=wx+b$的直线，其中$w$就是权重$\\theta$，$x$为样本数据，$b$为截距，为了公式推导的方便，我们设$x_0=1$，上面的公式简化如下： $$h(x)=\\theta_0 x_0+\\theta_1 x_1+\\theta_2 x_2=\\sum_{i=0}^n \\theta_i x_i=\\theta^Tx$$ 现在只需得到$\\theta$，即可得到最终的模型。想要模型能够准确描述当前数据，最理想的情况是这条线能通过所有样本数据，但实际上这几乎不可能，所以只能使$\\theta$能够在当前数据集上尽可能准确。反过来想，当找到这条直线后，每个样本距离这条直线都存在一定的误差，即截距，当总截距最小时，这条直线就是我们需要的模型，所以我们只要找到截距与模型间的关系，就可以获得模型，这个关系被称为损失函数。 $$J(\\theta)=\\cfrac{1}{2m}\\sum_{i=1}^m (h(x^{(i)})-y^{(i)})^2$$ 其中，$m$为样本数量，按照这个公式，求解出使损失函数最小的$\\theta$。 逻辑回归（Logistic Regression）逻辑回归就是将上面线性回归预测的值，转化为离散的结果进行输出。逻辑回归虽然名字里带回归，实际上是分类，只是过程中用到了回归算法。逻辑回归的具体算法此处暂不详述。","categories":[{"name":"算法","slug":"算法","permalink":"http://tyrival.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://tyrival.github.io/tags/algorithm/"}]},{"title":"算法02：分类算法","slug":"algorithm-02","date":"2018-02-25T00:26:06.000Z","updated":"2018-02-25T09:58:29.000Z","comments":true,"path":"posts/algorithm-02/","link":"","permalink":"http://tyrival.github.io/posts/algorithm-02/","excerpt":"分类算法，是从数据集中提取描述数据类的一个函数或模型（也叫分类器），并将数据集中每个样本归结到某个已知的类中。分类算法的目标是对已有数据进行分类，并预测未来数据的归类，分类算法常用语医疗诊断、图像识别模式等领域。常见分类算法包括贝叶斯（Bayes）、决策树（Decision Tree）、支持向量机（SVM）、K近邻（KNN）、逻辑回归（Logistic Regression）、神经网络、深度学习等。\u0010\u0010","text":"分类算法，是从数据集中提取描述数据类的一个函数或模型（也叫分类器），并将数据集中每个样本归结到某个已知的类中。分类算法的目标是对已有数据进行分类，并预测未来数据的归类，分类算法常用语医疗诊断、图像识别模式等领域。常见分类算法包括贝叶斯（Bayes）、决策树（Decision Tree）、支持向量机（SVM）、K近邻（KNN）、逻辑回归（Logistic Regression）、神经网络、深度学习等。\u0010\u0010 朴素贝叶斯（Naive Bayes）贝叶斯分类法是基于贝叶斯定理的一种十分简单的分类算法，核心思想是，对于待分类的对象，求该对象在各类别出现的概率，哪个概率最大，就将此对象归入哪个类别。朴素贝叶斯有一个前提，每个特征值相对于其他特征值必须独立——类条件独立性。 贝叶斯定理： $$P(A|B)=\\cfrac{P(B|A)P(A)}{P(B)}$$ P(A|B)是在B发生的情况下，A的发生概率，即A的后验概率； P(A)是发生A的概率，即A的先验概率； P(B|A)是在A发生的情况下，B的发生概率，即B的后验概率； P(B)是发生B的概率，即B的先验概率。 公式假设某样本有n项特征（Feature），分别为$F_1$、$F_2$、…、$F_n$。现有m个类别（Category），分别为$C_1$、$C_2$、…、$C_m$。贝叶斯分类器就是计算出概率最大的那个分类，也就是求下面这个算式的最大值： $$P(C|F_1F_2…F_n)=\\cfrac{P(F_1F_2…F_n|C)P(C)}{P(F_1F_2…F_n)}$$ 由于 P(F1F2…Fn) 对于所有的类别都是相同的，可以省略，问题就变成了求下式的最大值： $$P(F_1F_2…F_n|C)P(C)$$ 朴素贝叶斯分类器则是更进一步，假设所有特征都彼此独立，因此 $$P(F_1F_2…F_n|C)P(C)=P(F_1|C)P(F_2|C) … P(F_n|C)P(C)$$ 上式等号右边的每一项，都可以从样本资料中计算得到，由此就可以计算出每个类别对应的概率，从而找出最大概率的那个类。 案例有一组样本数据，记录了各门诊病人的职业、症状和确诊疾病，如下： 职业 症状 疾病 护士 打喷嚏 感冒 农夫 打喷嚏 过敏 工人 头痛 脑震荡 工人 头痛 感冒 教师 打喷嚏 感冒 教师 头痛 脑震荡 现在来了一个打喷嚏的工人，请问他最有可能是什么疾病？ 设疾病为Category={&quot;感冒&quot;, &quot;过敏&quot;, &quot;脑震荡&quot;}，职业和症状为Feature={&quot;工人&quot;, &quot;打喷嚏&quot;} 首先计算此人得感冒的概率，根据贝叶斯定理，可 $$P(感冒|打喷嚏×工人)=\\cfrac{P(打喷嚏×工人|感冒)×P(感冒)}{P(打喷嚏×工人)}$$ 由于朴素贝叶斯中各特征值独立，即“症状”（打喷嚏）和“职业”（工人）相互独立，上面的等式变为 $$P(感冒|打喷嚏×工人)=\\cfrac{P(打喷嚏|感冒)×P(工人|感冒)×P(感冒)}{P(打喷嚏×工人)}$$ 等号右边的所有概率P都可以根据样本数据计算得到 $$P(感冒|打喷嚏×工人)=\\cfrac{0.66×0.33×0.5}{0.5×0.33}=0.66$$ 所以他得感冒的概率为66% 同理计算此人患过敏或脑震荡的概率，比较后就能知道他最可能的疾病 优点 过程简单速度快； 在属性独立假设成立的前提下，效果极佳，所需样本量也少。 缺点 属性间相互独立的假设经常不成立； 通过先验和数据来决定后验的概率从而决定分类，先验概率很多时候取决于假设，存在一定的错误率。 应用 需要不同维度之间相关性较小的样本，例如：垃圾邮件识别、微博上的褒贬情绪判断等。 决策树（Decision Tree）决策树是一个树结构（二叉树或非二叉树），使用时从根节点开始，在每个非叶节点测试样本中相应的属性值，按照属性值进行分支输出，直至到达叶节点，每个叶节点代表一个类别，将最终到达的叶节点作为决策结果。 构造决策树的关键是分裂属性，在非叶节点按照某个属性值的不同，划分构造不同的分支，目标是让各分裂子集尽可能单纯，即让分裂后的子集中的待分类样本属于同意类别。分裂属性包含以下三种情况： 属性是离散值（名称型Nornimal）且不要求生成二叉决策树时，属性的每个值作为一个分支。 属性是离散值（名称型Nornimal），且要求生成二叉决策树时，使用属性划分的一个子集进行测试，按照“属于此子集”和“不属于此子集”分成两个分支。 属性是连续值（数字型Numeric）。此时确定一个值作为分裂点split_point，按照&gt;split_point和&lt;=split_point生成两个分支。 例如有以下对话： 女儿：多大年纪了？ 母亲：26。 女儿：长的帅不帅？ 母亲：挺帅的。 女儿：收入高不？ 母亲：不算很高，中等情况。 女儿：是公务员不？ 母亲：是，在税务局上班呢。 女儿：那好，我去见见。 这就是典型的决策树，通过年龄、长相、收入和是否是公务员的判断，得到最终的两个类别：见和不见。 年龄属性是连续值，此时假设女儿选择30作为分裂点，按照&lt;=30和&gt;30生成两个分支； 长相是连续值，且要求生成二叉树，属性划分为“丑”和“不丑”子集，生成两个分支； 收入是离散值，包括高、中、低三个值，此处不要求生成二叉树，每个值作为一个分支。 在构造决策树的过程中，决策点的选取和决策顺序非常重要，良好的决策顺序和分支设定可以减少性能消耗，提高效率，因此需要一个量化的方法，选取决策划分点和划分顺序。常见决策树算法包括ID3和C4.5。 ID3算法ID3算法建立在“奥卡姆剃刀”的基础上：越是小型的决策树优于大的决策树。 ID3算法的重要衡量标准为熵和信息增益。 熵（entropy）是整个系统的平均消息量，一个系统越是有序，熵就越低；反之，熵就越高，所以，熵也可以说是系统有序化程度的一个度量。反映到决策树上，熵越大，在决策树上要达到叶节点（即输出最终结果），所需要判断的属性就越多，效率就越低。 信息熵，代表随机变量的复杂度。 条件熵，代表在某一个条件下，随机变量的复杂度。 信息增益，表示得知某个属性之后，使得样本集合不确定度减少的程度。 $$信息增益=信息熵-条件熵$$ 过程 计算信息熵 样本集合D中有$k$类样本，其中第$i$类所占比例为$P_i$，D的信息熵计算公式如下： $$Entropy(D)=-\\sum_{i=1}^k P_i\\log_2 P_i$$ 计算信息增益 $a$表示某个属性，$V(a)$表示属性a的值的数量，$D$是样本集合，$D^v$是$D$中在$a$属性上，值等于$v$的样本集合\u0010\u0010，信息增益计算公式如下： $$Gain(D,a)=Entropy(D)-\\sum_{v\\in V(a)}\\cfrac{|D^v|}{|D|}Entropy(D^v)$$ 案例假设样本集合D某个属性a有3个分支x、y、z，通过对样本数据的统计，发现10个样本中，有6个走向了x分支、3个走向y分支，1个走向z分支\u0010。 计算熵 $$Ent(D_x)=\\cfrac{6}{10}\\log_2\\cfrac{6}{10}$$ $$Ent(D_y)=\\cfrac{3}{10}\\log_2\\cfrac{3}{10}$$ $$Ent(D_z)=\\cfrac{1}{10}\\log_2\\cfrac{1}{10}$$ $$Ent(D)=-P_x-P_y-P_z$$ 计算信息增益 $$Gain(D, a)=Ent(D)-(\\cfrac{6}{10}\\times Ent(D_x)+\\cfrac{3}{10}\\times Ent(D_y)+\\cfrac{1}{10}\\times Ent(D_z))$$ 计算其他属性的信息增益，进行对比，选择信息增益最高的属性作为当前节点，假设属性$a$的信息增益最高，则$a$作为当前节点的测试属性，x、y、z作为三个分支，将集合D分为三部分$D_x$、$D_y$、$D_z$ 针对上一步得到的各分支，重复前三步，向下递归构成决策树 决策树构建时，某条路径终止的条件有两种： 这条路径包括了所有的属性。 某个分支输出的样本集合，剩余的属性值全部相同，则终止并得到一个叶节点。 优点 构建决策树的速度比较快，算法实现简单，生成的规则容易理解。 缺点 在属性选择时，倾向于选择那些拥有多个属性值的属性作为分裂属性，例如：当一个属性为ID时，这个属性会被作为根节点，而实际上这并没有意义。 应用 可以训练缺少属性值的实例。 C4.5算法C4.5算法是对ID3算发的改进，C4.5算法不使用信息增益来选取特征值，而是使用了信息增益率。 $$信息增益率=\\cfrac{信息增益}{属性固有值}$$ 公式如下： $$GainRadio(D,a)=\\cfrac{Gain(D,a)}{IV(a)}$$ $$IV(a)=-\\sum_{v\\in V(a)}\\cfrac{|D^v|\u0010}{|D|}\\log_2\\cfrac{|D^v|\u0010}{|D|}$$ 属性固有值$IV(a)$随着$a$的值域数量增大而增大，此时优先选择GainRadio较大的属性作为当前节点，然后向下递归。 优点 既保证了信息增益高于平均水平，又避免出现选择ID作为特征这种极端的情况。 缺点 在构造树的过程中，需要对数据集进行多次顺序扫描和排序，导致算法低效。","categories":[{"name":"算法","slug":"算法","permalink":"http://tyrival.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://tyrival.github.io/tags/algorithm/"}]},{"title":"算法01：聚类算法","slug":"algorithm-01","date":"2018-02-24T05:31:51.000Z","updated":"2018-02-25T08:43:50.000Z","comments":true,"path":"posts/algorithm-01/","link":"","permalink":"http://tyrival.github.io/posts/algorithm-01/","excerpt":"聚类算法，是把一组样本中，把类似的样本聚在一起，不同的样本分开，最终形成几个簇。主要是基于已有数据进行分析，得出结论的过程。常见业务场景包括：基于用户位置信息的商业选址、中文地址标准化处理、用户画像、非人恶意流量识别、广告精准投放、图像分割等众多领域。","text":"聚类算法，是把一组样本中，把类似的样本聚在一起，不同的样本分开，最终形成几个簇。主要是基于已有数据进行分析，得出结论的过程。常见业务场景包括：基于用户位置信息的商业选址、中文地址标准化处理、用户画像、非人恶意流量识别、广告精准投放、图像分割等众多领域。 距离：在多维空间里，假设两个样本为a(x1, x2, x3 ,x4, … xn)，b(y1, y2, y3, y4, … yn)。那么他们之间的欧式距离（Euclidean distance）的计算公式是 $$d=\\sqrt{\\sum_{k=1}^n (x_k-y_k)^2}$$ 除了欧式距离、还有Mahattan disatnce、Mahalanobis distance等。 K-MeansK-Means是最常用的经典聚类算法。 过程 在样本中随机选择K个点CM={M0, M1, … Mk}，作为每个类别的初始中心点。K由用户自定义，表示拥护想将样本分为K个簇； 分别计算所有样本离这K个初始中心点的距离，并分别进行比较，样本离哪个中心点最近，就将其归入那个中心点簇中，从而将所有样本分为K个簇； 在划分好的K个簇中，分别计算出新的中心点CN={N0, N1, … Nk}，使中心点到该簇中所有样本的距离之和最小； 判断新获得的中心点CN是否与旧中心点CM一致，如不一致，则将CN赋值给CM，然后回到第2步，重新计算CN并再次比较；如一致则结束，即收敛。 案例设置K=3，并随机选择3个点，进行第一次聚类 第二次聚类 收敛时 K的选择K的选择通常有4种方法 按需选择 根据需求或经验进行选择，例如把客户分为高级VIP、普通VIP、普通用户三类。 观察法 将样本在坐标系中绘制，并用眼睛观察大致分为几类，这种方式有时会很模糊，而且只能用于低维度数据（1、2、3维），对于高维度数据，需要利用PCA算法降维，然后进行观察。 手肘法 手肘法是一种间接的观察法，当K-Means算法完成后，我们将得到K个聚类的中心点。计算样本点到它所在的簇的中心点的距离，并求和作为模型的度量，记为D。 $$D_k=\\sum_{i=1}^K\\sum_{X\\in C_i}||X-M_i||$$ 对于不同的K，最后我们会得到不同的中心点和聚类，所有会有不同的度量。 我们把上面的例子用不同的K去计算，会得到不同的结果。把K作为横坐标，D作为纵坐标，我们可以得到下面的折线。 很显然K越大，距离和越小。但是我们注意到K=3是一个拐点，就像是我们的肘部一样，K=1到3下降很快，K=3之后趋于平稳。手肘法认为这个拐点就是最佳的K。 Gap Statistics方法 计算Gap Statisitc，Gap statistic取得最大值所对应的K就是最佳的K，详细内容可以Google。 优点： 逻辑简单，便于实现。 缺点： 较为低效，因为要计算所有的样本到中心的距离； K由用户定义，所以需要对数据由比较深刻的了解； “距离”的选择影响结果。欧式距离计算中，所有属性的权重是相同的，而实际应用时，各属性的权重实际上是有差别的，而不同的权重系数，会导致聚类结果出现较大差异。 应用：由于K-Means简单易实现，所以经常被用来做pre-clustering，在使用更高级的算法前，先进行初步聚类。 层次聚类层次聚类算法（Hierarchical clustering）通过分层来实现样本的聚类，包括Agglomerative和Divisive两种策略。Agglomerative初始假设每个样本属于独立的簇，自下而上，通过合并每层中相邻的簇进行汇聚，最终达到所有簇的最高层。Divisive初始假设所有样本属于一个簇，从上到下，通过分离每个簇中比较不相似的样本，直到每个样本都属于不同的簇。 Cluster dissimilarity：为了决定簇的合并（Agglomerative）或分解（Divisive）方式，需要一个指标来衡量两个簇所包含的样本的差异程度。一般来说，这个指标有两个组成部分，一个是Metric，用于衡量两个样本之间的距离，另一个是Linkage，用于衡量两个簇间的差异程度。Metric跟Linkage的选取直接影响最终结果。Metric包括Euclidean distance、Squared Euclidean distance、Mahattan distance、Mahalanobis distance等，Linkage包括Single linkage、Complate linkage、Average linkage等。 过程 Agglomerative是每次将Linkage最小的两个簇合并，直到只剩一个最大的簇为止； Divisive是每次把一个簇分成两个，使这两个簇的Linkage最大，直到每个簇只剩一个样本为止； 由于用户需要的结果不会是Agglomerative或Divisive的最终结果，所以用户在过程中何时停下，决定了最终的结果。 案例如下图是Agglomerative算法的示意图，每次对差异度最小的簇进行合并，直到最终成为一个大簇，用户在Y轴上取一个值，作为终止计算的位置，则此时簇的数量为4。 Divisive算法示意图与Agglomerative类似。 优点 不像K-Means需要用户定义簇的数量。 缺点 没有目标函数，会一直计算直到极端情况出现； 最终的结果取决于用户的主观想法，即何时停止； Cluster dissimilarity中的Metric和Linkage的选择没有统一标准。 应用查询结果聚类、信息检索 DBSCAN当样本分布不均匀，形状不规则时，K-Means和层次聚类算法都有可能失效，此时可以采用基于密度的聚类算法DBSCAN。例如下图样本： 过程 设定扫描半径 Eps, 并规定扫描半径内的密度值。若当前点的半径范围内密度大于等于设定密度值，则设置当前点为核心点；若某点刚好在某核心点的半径边缘上，则设定此点为边界点；若某点既不是核心点又不是边界点，则此点为噪声点。 删除噪声点。 将距离在扫描半径内的所有核心点赋予边进行连通。 每组连通的核心点标记为一个簇。 将所有边界点指定到与之对应的核心点的簇总 案例假设扫描半径 Eps 为 1.5，密度阈值 threshold 为 3，可得下图： 通过计算各个点之间的欧式距离及其所在扫描半径内的密度值来判断这些点属于核心点，边界点或是噪声点。因为我们设定了扫描半径为 1.5，密度阈值为 3，所以： P0 点为边界点，因为在以其为中心的扫描半径内只有两个点 P0 和 P1； P1 点为核心点，因为在以其为中心的扫描半径内有四个点 P0, P1, P2, P4 ； P8 为噪声点，因为其既非核心点，也非边界点； 其他点依次类推。 优点 可以对任意形状的稠密数据集进行聚类；（K-Means之类的聚类算法一般只适用于凸数据集） 可以在聚类的同时发现异常点，对数据集中的异常点不敏感; 聚类结果没有偏倚。（K-Means之类的聚类算法初始值对聚类结果有很大影响） 缺点 全局参数难以设定； 难以识别空间簇相互邻接（颈问题）情况下的空间聚类操作。 其他除了以上三种聚类算法，还有BIRTH、CURE、SOM、FCM等多种聚类算法。","categories":[{"name":"算法","slug":"算法","permalink":"http://tyrival.github.io/categories/算法/"}],"tags":[{"name":"algorithm","slug":"algorithm","permalink":"http://tyrival.github.io/tags/algorithm/"}]},{"title":"Swift3 - 01：基础语法","slug":"swift-01-base","date":"2017-07-03T03:51:04.000Z","updated":"2018-02-24T03:57:19.000Z","comments":true,"path":"posts/swift-01-base/","link":"","permalink":"http://tyrival.github.io/posts/swift-01-base/","excerpt":"入门学习Swift3的一些基本语法tips。","text":"入门学习Swift3的一些基本语法tips。 getter、setter、计算属性、只读属性 123456789101112131415161718192021222324252627282930313233import UIKitclass Person: NSObject &#123; // 使用一个属性记录 name 的值 var _name: String // Swift中通常不会重写 getter 和 setter 方法 var name: String &#123; get &#123; return _name &#125; set &#123; _name = newValue &#125; &#125; // 只定义了 getter，所以 title 为只读属性，同时 title 又是计算型属性， // 每次调用 person.title 时，都进行一次计算，随 name 值变化 // var title: String &#123; get &#123; return \"Mr. \" + (name ?? \"\") &#125; &#125; // 可以简写为如下格式 var title2: String &#123; return \"Mr. \" + (name ?? \"\") &#125; // 闭包，只计算一次，之后不随 name 值变化 var title3: String = &#123; return \"Mr. \" + (name ?? \"\") &#125;()&#125; willSet和didSet 12345678910111213141516171819202122232425import UIKitclass Person: NSObject &#123; var nickName: String var age: Int = 0 &#123; //age属性变化前做点什么 willSet &#123; println(\"Will set an new value \\(newValue) to age\") &#125; //age属性发生变化后，更新一下nickName这个属性 didSet &#123; println(\"age filed changed form \\(oldValue) to \\(age)\") if age &lt; 10 &#123; nickName = \"Little\" &#125;else &#123; nickName = \"Big\" &#125; &#125; &#125;&#125; 访问控制修饰词 Swift 3 相较于之前的版本，新加了两个关于访问控制修饰符，open和fileprivate。全部访问控制修饰词的限制如下： 1open &gt; public &gt; internal(默认) &gt; fileprivate &gt; private open 和 public 二者都是可以跨 Module 访问的，但open 比 public 更加开放。 open 修饰的类可以继承，open类中，用 open 修饰的方法可以重写，而 public 不可以。 public final 在任何地方均不可重写， public可在本 Module 内重写。 internal internal 是默认的访问控制级别。internal 对自身 Module 开放所有源文件，而对外界源代码屏蔽。 fileprivate &amp; private fileprivate 是文件内可访问，private 是代码块内可访问，例如： 12345678910111213141516class Animal: NSObject &#123; func eat() &#123; chew() // 在同一文件，fileprivate可访问 bite() // 不在同一代码块，private禁止访问 &#125;&#125;extension Animal &#123; fileprivate func chew() &#123; bite() // 在同一代码块，private可访问 &#125; private func bite() &#123; // do something &#125;&#125;","categories":[{"name":"iOS","slug":"iOS","permalink":"http://tyrival.github.io/categories/iOS/"}],"tags":[{"name":"swift","slug":"swift","permalink":"http://tyrival.github.io/tags/swift/"}]},{"title":"Less入门 & Webstorm实时编译","slug":"less-and-webstorm","date":"2017-06-20T12:26:12.000Z","updated":"2017-06-20T13:42:17.000Z","comments":true,"path":"posts/less-and-webstorm/","link":"","permalink":"http://tyrival.github.io/posts/less-and-webstorm/","excerpt":"Less只要半小时就入门了，顺便介绍下怎样用Webstorm实时编译和调试。","text":"Less只要半小时就入门了，顺便介绍下怎样用Webstorm实时编译和调试。 基本语法 创建一个最简单的工程，基本结构如下： 1234|- css // 编译生成css的文件夹|- src // 源码 |- style // less文件夹|- index.html // 首页 变量 变量主要用于声明一个可复用的样式，供多次调用，可将全局常用变量声明在一个文件中，例如创建文件/src/style/variables.less，用于保存全局变量；/src/style/main.less，用于编写样式。这里需要说明，分号（;）在less中非常重要，尽量不要省略。 1234567891011121314151617## variables.less@color_default: #ffffff; // 用@声明变量，末尾需要加分号;## main.less@import \"./variables.less\"; // 引入全局变量.btn-default &#123; background-color: @color_default; // 引用变量，声明样式&#125;.nav &#123; @nav_height: 55px; // 声明局部变量，作用域为所在的大括号内 height: @nav_height; li &#123; line-height: @nav_height; &#125;&#125; 混合（mixin） 混合可以声明一组固定的样式，被其他元素所引用 12345678910111213141516171819202122232425262728/* 普通 */.panel &#123; border: solid 1px #999999; background-color: #ffffff; font-size: 12px;&#125;.btn &#123; .panel; // 加分号&#125;/* 带参数，类似带参函数，常用于部分样式不确定 */.border(@border_width) &#123; border: solid black @border_width;&#125;.panel &#123; .border(5px);&#125;/* 带默认值的参数 */.border(@border_width:10px) &#123; border: solid black @border_width;&#125;.panel &#123; .border(); // 参数为空则取默认值&#125; 匹配模式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 三角向上.triangle(top,@width:5px,@color:red) &#123; width: 0; height: 0; overflow: hidden; nprder-style: solid dashed dashed dashed; // 匹配旧版IE，如果只写solid，会导致背景为黑色 border-width: @width; border-color: @color transparent transparent transparent;&#125;// 三角向下.triangle(bottom,@width:5px,@color:red) &#123; width: 0; height: 0; overflow: hidden; nprder-style: dashed dashed solid dashed; border-width: @width; border-color: transparent transparent transparent;&#125;.triangle-down &#123; .triangle(bottom); // 向下的三角&#125;/* 以上代码可将共有的部分提取出来，利用通配符@_匹配，类似函数的重载 */.triangle(top,@width:5px,@color:red) &#123; nprder-style: solid dashed dashed dashed; border-width: @width; border-color: @color transparent transparent transparent;&#125;.triangle(bottom,@width:5px,@color:red) &#123; nprder-style: dashed dashed solid dashed; border-color: transparent transparent transparent;&#125;// 表示不管第一个参数传入什么值，都需要带上这组样式.triangle(@_,@width:5px,@color:red) &#123; width: 0; height: 0; overflow: hidden; border-width: @width;&#125;.triangle-down &#123; .triangle(bottom);&#125; 运算 1234567@height: 100px;@color: #aaaaaa;.panel &#123; width: (@height + 20 - 5) * 6 / 3; color: @color - 10; // 颜色运算使用较少&#125; 嵌套 1234567891011121314151617181920212223/* 潜逃中常用&amp;代替上级选择器 */ul &#123; // 等同 ul li li &#123; // 等同 ul li a a &#123; // 等同 ul li a .icon，不是 a.icon .icon &#123; &#125; // &amp;代替的是上级选择器，即a，等同 ul li a.active &amp;.active &#123; &#125; // 等同 ul li a:hover &amp;:hover &#123; &#125; &#125; &#125;&#125; @arguments 12345678/* 代替全部参数 */.border(@w:5px, @c:black, solid) &#123; border: @arguments; // 代入所有的参数&#125;.btn &#123; .border();&#125; 注释 123/* 这类注释会被原样编译到css中 */// 这类注释不会被编译到css中 Webstorm实时编译 Webstorm可以将less实时编译为css，并且发布到浏览器，此功能还需要用到Chrome和npm（安装NodeJS）； Chrome安装JetBrains IDE Support扩展； npm安装less编译器 1$ sudo npm install -g less // 全局安装，如果未翻墙，改为执行 sudo cnpm install -g less Webstorm打开Preference &gt; Build,Execution,Deployment &gt; Debugger &gt; Live Edit，勾选Update中的Auto in (ms)，后面填写更新频率，比如200。 选择Preference &gt; Tools &gt; File Watchers，在右侧点+，选择Less，修改Output paths to refresh为项目的css文件夹的相对路径：../../css/$FileNameWithoutExtension$.css，此处需注意Program应当指向之前安装的less编译器，比如/usr/local/bin/lessc，如果为空，说明less编译器未安装成功，需要重新安装后再试。 右键点击需要调试的页面，选择Debug “页面.html”，注意不能选Run … Chrome会自动加载此页面，顶部如果出现”JetBrains IDE Support正在调试此浏览器”的字样，则说明配置成功。注意：这个提示不可关闭，关闭则失效 编辑less文件，可以将修改后的样式在Chrome中实时显示出来 这个功能还可以用于实时编译Babel、Sass、SCSS、CoffeeScript等。","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"css","slug":"css","permalink":"http://tyrival.github.io/tags/css/"},{"name":"less","slug":"less","permalink":"http://tyrival.github.io/tags/less/"}]},{"title":"Vue 02：单页面开发基础","slug":"vue-02-base","date":"2017-06-19T07:33:56.000Z","updated":"2017-06-19T10:00:03.000Z","comments":true,"path":"posts/vue-02-base/","link":"","permalink":"http://tyrival.github.io/posts/vue-02-base/","excerpt":"本文粗略讲述了Vue单页面应用开发，包括组件：状态管理模块Vuex、路由管理模块VueRouter、AJAX模块VueResource等，新建一个页面并实现跳转。","text":"本文粗略讲述了Vue单页面应用开发，包括组件：状态管理模块Vuex、路由管理模块VueRouter、AJAX模块VueResource等，新建一个页面并实现跳转。 VueResource工程中默认使用的ajax模块是axios，需要额外下载VueResource 1$ npm install vue-resource VueRouterVueRouter用于管理单页面应用的页面跳转，可以实现局部页面的切换，路由配置文件为/src/router.js 1234567891011121314// 配置的解析方式为：查找到路径后就停止向后解析const routers = [&#123; path: '/', meta: &#123; title: '' &#125;, component: (resolve) =&gt; require(['./views/index.vue'], resolve)&#125;, &#123;path: '/index', component: require('./views/index.vue')&#125;, // 与/一致，方便跳转到首页 &#123;path: '/hello', component: require('./views/main/hello.vue')&#125;, // 跳转到hello页面 &#123;path: '*', component: require('./views/index.vue')&#125;, // 找不到路径时，默认跳转到首页]export default routers Main.js/src/main.js为项目总配置文件，在其中引入各模块，并实例化前端应用根节点，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// 全局引入模块文件和样式import Vue from 'vue' // 引入Vueimport iView from 'iview' // 引入iViewimport VueRouter from 'vue-router' // 引入VueRouterimport Routers from './router' // 引入VueRouter配置文件import Vuex from 'vuex' // 引入Vueximport VueResource from 'vue-resource' // 引入VueResource(新增)import Util from './libs/util' // 引入util包import App from './app.vue' // 引入项目入口模板import 'iview/dist/styles/iview.css' // 引入iView样式// Vue引用模块Vue.use(VueRouter) // 路由模块Vue.use(Vuex) // 状态管理Vue.use(VueResource) // Ajax模块(新增)Vue.use(iView) // iView组件// VueRouter路由模块配置和实例化const RouterConfig = &#123; mode: 'history', routes: Routers&#125;const router = new VueRouter(RouterConfig)router.beforeEach((to, from, next) =&gt; &#123; iView.LoadingBar.start() Util.title(to.meta.title) next()&#125;)router.afterEach(() =&gt; &#123; iView.LoadingBar.finish() window.scrollTo(0, 0)&#125;)// Vuex状态管理实例化const store = new Vuex.Store(&#123; state: &#123;&#125;, getters: &#123;&#125;, mutations: &#123;&#125;, actions: &#123;&#125;&#125;)// 实例化前端根节点，声明变量vm，作为全局应用，方便后续调用var vm = new Vue(&#123; el: '#app', //入口元素 router: router, // 路由 store: store, // 状态 render: h =&gt; h(App) // 渲染&#125;) Hello World 新建页面/src/views/main/hello.vue 12345678910&lt;template&gt; &lt;div id=\"hello\"&gt; Hello World! &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; name: 'hello', // name属性用于Vue框架报错时，显示错误模块名 &#125;&lt;/script&gt; 新建样式文件/src/styles/main.less和/src/styles/variables.less，前者用于全局样式，后者用于定义全局less变量 12345678910// variables.less@global-color: #ffffff;// main.less@import '../styles/variables.less';html, body &#123; height: 100%; background-color: @global-color&#125; 修改index.vue 123456789101112131415161718192021222324252627282930&lt;style lang=\"less\" scoped&gt; @import '../styles/main.less';&lt;/style&gt;&lt;template&gt; &lt;div&gt; &lt;!-- 绑定goHello方法 --&gt; &lt;button @click=\"goHello\"&gt;Go to Hello&lt;/button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; export default &#123; methods: &#123; // 绑定按钮的点击事件 goHello: function () &#123; // 跳转到/hello，在/src/router.js中指向/views/main/hello.vue this.$router.push(&#123; path: '/hello' &#125;)， this.$http.get('/dist/data/ajax.json').then((response) =&gt; &#123; // 响应成功回调 console.log(\"Success message: \" + response.body.message) &#125;, (response) =&gt; &#123; // 响应错误回调 console.log(\"Failure message: \" + response.body.message) &#125;); &#125; &#125; &#125;&lt;/script&gt; VueResource VueResource负责与后端进行Ajax请求交互，基本用法如下 123456789101112131415161718192021222324export default &#123; methods: &#123; ajaxReq: function () &#123; // 基本结构为this.$http.get(url).then(success, failure) // success和failure使用Lambda表达式，好处是不会改变函数内部的上下文 var me = this; this.$http.get('/dist/data/ajax.json').then((response) =&gt; &#123; // 由于使用Lambda表达式，上下文未变化 console.log(this === me) // 响应成功回调 console.log(\"Success message: \" + response.body.message) &#125;, (response) =&gt; &#123; // 响应错误回调 console.log(\"Failure message: \" + response.body.message) &#125;); &#125; &#125;&#125; 调用方法有两种 12Vue.$http.get() // 全局this.$http.get() // 局部 除了get，还有下列REST方法 1234567get(url, [options])head(url, [options])delete(url, [options])jsonp(url, [options])post(url, [body], [options])put(url, [body], [options])patch(url, [body], [options]) options包含以下属性 1234567891011url string 请求的URLmethod string 请求的HTTP方法，例如：&apos;GET&apos;, &apos;POST&apos;或其他HTTP方法body Object,FormData string request bodyparams Object 请求的URL参数对象headers Object request headertimeout number 单位为毫秒的请求超时时间 (0 表示无超时时间)before function(request) 请求发送前的处理函数，类似于jQuery的beforeSend函数progress function(event) ProgressEvent回调处理函数credentials boolean 表示跨域请求时是否需要使用凭证emulateHTTP boolean 发送PUT, PATCH, DELETE请求时以HTTP POST的方式发送，并设置请求头的X-HTTP-Method-OverrideemulateJSON boolean 将request body以application/x-www-form-urlencoded content type发送 response包含以下属性和方法 123456789方法 类型 描述text() string 以string形式返回response bodyjson() Object 以JSON对象形式返回response bodyblob() Blob 以二进制形式返回response body属性 类型 描述ok boolean 响应的HTTP状态码在200~299之间时，该属性为truestatus number 响应的HTTP状态码statusText string 响应的状态文本headers Object 响应头","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"},{"name":"vue","slug":"vue","permalink":"http://tyrival.github.io/tags/vue/"}]},{"title":"Vue 01：初始化项目","slug":"vue-01-initial","date":"2017-06-19T06:12:05.000Z","updated":"2017-06-19T09:57:01.000Z","comments":true,"path":"posts/vue-01-initial/","link":"","permalink":"http://tyrival.github.io/posts/vue-01-initial/","excerpt":"最近开始学习Vue框架，使用基于Vue开发的iView组件库，开发单页面应用。iView组件库设计的较为全面，特别欣赏它的复杂表格组件和项目构建工具。IDE使用Webstorm，前段工具为Webpack。","text":"最近开始学习Vue框架，使用基于Vue开发的iView组件库，开发单页面应用。iView组件库设计的较为全面，特别欣赏它的复杂表格组件和项目构建工具。IDE使用Webstorm，前段工具为Webpack。 新建工程 进入 iView Cli下载页面 下载构建工具，全平台支持，安装完成后打开。 新建工程，配置如下： CSS预处理：less Ajax：勾选 状态管理：vuex 图表：echarts cookie（js-cookie）：勾选 复制（clipboard）：勾选 HTML转图片（html2canvas）：勾选 显示更多配置：填写项目名称 创建工程 用Webstorm打开刚才创建的工程 打开Terminal，进入工程目录（或者用WebStorm内的Terminal），安装依赖包，可能需要等待较长时间，安装完成后，工程目录中出现node_modules目录 1$ npm install // 如果未翻墙，使用 cnpm install 启动服务，启动完成后，打开 http://127.0.0.1:8080 可访问工程默认界面 1$ npm run dev 编译打包， 1$ npm run build Webpack将所有资源文件编译到dist目录下，根目录下有index.html和index_prod.html，前者用于开发环境，后者用于生产环境。 项目结构 主要文件结构和说明如下，有些文件夹需要手工创建 1234567891011121314151617181920212223242526272829303132333435363738394041|— dist 生产环境资源|— node_modules 依赖包|— src 源码 |— components 自定义组件文件夹 |— config 配置文件夹 |— libs 工具库文件夹 |— styles 自定义样式文件夹 |— template 模板文件夹 |— index.ejs 编译index.html的模板 |— views 视图文件夹 |— index.vue app.vue内的内容组件 |— app.vue 项目根组件，根路由入口 |— main.js 项目入口js |— route.js VueRouter配置文件 |— vendors.js 项目入口js|— index.html 首页（开发环境）|— index_prod.html 首页（生产环境）|— package.json Webpack配置文件|— webpack.base.config.js Webpack配置文件|— webpack.dev.config.js Webpack配置文件|— webpack.prod.config.js Webpack配置文件","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"},{"name":"vue","slug":"vue","permalink":"http://tyrival.github.io/tags/vue/"}]},{"title":"树莓派 02：搭建迅雷远程下载服务器","slug":"pi-02-thunder-remote","date":"2017-06-07T21:57:06.000Z","updated":"2017-06-08T01:41:28.000Z","comments":true,"path":"posts/pi-02-thunder-remote/","link":"","permalink":"http://tyrival.github.io/posts/pi-02-thunder-remote/","excerpt":"本文介绍怎样用小霸王学习机树莓派3B搭建一个远程控制的迅雷服务器，主要内容包括外界存储的挂载，迅雷服务器的搭建等。","text":"本文介绍怎样用小霸王学习机树莓派3B搭建一个远程控制的迅雷服务器，主要内容包括外界存储的挂载，迅雷服务器的搭建等。 USB外接存储 如果外接存储是NTFS文件系统，需要安装软件包，并重启 12$ sudo apt-get install ntfs-3g$ sudo reboot 将存储设备连接到树莓派后，外接存储会自动挂载到 /media/pi/[存储名称]，如果没有自动挂载，则进行手工挂载 12$ sudo mkdir /media/pi/NAS #NAS为自定义名称$ sudo chmod 770 /media/pi/NAS #权限分配 查询user id和group id，分别是第三列和第四列 12$ grep pi /etc/passwdpi:x:1000:1000:,,,:/home/pi:/bin/bash #uid和gid通常都是1000 手动挂载 1$ sudo mount -t ntfs-3g -o uid=1000,gid=1000,umask=007 /dev/sda1 /media/pi/NAS 查看到外界存储名称为/dev/sda1，根据名称查看存储的UUID为FE18BF9718BF4D81 12345678910$ sudo fdisk -l #查看外接存储的名称为/dev/sda1...Device Boot Start End Sectors Size Id Type/dev/sda1 2 1953525167 1953525166 931.5G 7 HPFS/NTFS/exFAT$ ls -l /dev/disk/by-uuid/total 0lrwxrwxrwx 1 root root 15 Jun 7 09:50 95E0-9AC4 -&gt; ../../mmcblk0p1lrwxrwxrwx 1 root root 15 Jun 7 09:50 b105f9a8-f450-4976-8ac8-69053f57bab4 -&gt; ../../mmcblk0p2lrwxrwxrwx 1 root root 10 Jun 7 13:14 FE18BF9718BF4D81 -&gt; ../../sda1 设置开机自动挂载 12$ vim /etc/fstab #加入下列内容，UUID为上一步查找到的值UUID=FE18BF9718BF4D81 /media/pi/NAS ntfs-3g uid=1000,gid=1000,umask=007 0 0 迅雷远程服务 下载迅雷 12345$ mkdir ~/Software/xunlei$ cd ~/Software/xunlei$ wget http://www.openwrtdl.com/wordpress/wp-content/uploads/2016/03/Xware1.0.31_armel_v5te_glibc.zip$ upzip Xware1.0.31_armel_v5te_glibc.zip$ rm Xware1.0.31_armel_v5te_glibc.zip 运行迅雷，会得到一个设备码，即下面的ABCXYZ 123$ ./portal...THE ACTIVE CODE IS: ABCXYZ 到 迅雷远程 ，用迅雷账号登录后，点击左侧的添加按钮，在弹出界面输入上一步得到的设备码，进行绑定，然后就可以在网页端远程操作迅雷进行下载了，通常，迅雷会自动在外界存储的挂载点建立一个TDDOWNLOAD文件夹，作为下载的默认路径。","categories":[{"name":"硬件","slug":"硬件","permalink":"http://tyrival.github.io/categories/硬件/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"raspberry","slug":"raspberry","permalink":"http://tyrival.github.io/tags/raspberry/"}]},{"title":"树莓派 01：系统安装和配置","slug":"pi-01-initial","date":"2017-06-07T21:54:51.000Z","updated":"2017-06-08T01:42:18.000Z","comments":true,"path":"posts/pi-01-initial/","link":"","permalink":"http://tyrival.github.io/posts/pi-01-initial/","excerpt":"本文介绍怎样在Mac OS初始化树莓派3B，包括安装、配置系统等。","text":"本文介绍怎样在Mac OS初始化树莓派3B，包括安装、配置系统等。 安装系统 戳这里 下载 Raspbian Jessie with Pixel，就是左边那个，右边的是简化版，下完后解压，得到一个img文件 打开磁盘工具，格式化MicroSD卡 打开终端，查看挂载的磁盘，找到MicroSD卡，记下挂载路径 123$ df.../dev/disk2s1 ... 卸载MicroSD卡 1$ diskutil unmount /dev/disk2s1 查看内存卡名称 12345$ diskutil list/dev/disk2 (internal, physical): #: TYPE NAME SIZE IDENTIFIER 0: FDisk_partition_scheme *31.6 GB disk2 ... 进入下载镜像文件的位置烧录镜像到MicroSD卡，if=后面为镜像名称，of=后面为内存卡名称disk2前面加个r，可以使烧录速度快一些。输入系统密码，然后就感觉卡住了，坐等几分钟后，出现提示就代表成功了 12$ cd ~/Downloads$ sudo dd bs=4m if=2017-04-10-raspbian-jessie.img of=/dev/rdisk2 这时候不要着急拔卡，还要配置SSH SSH和VNC 在 Raspbian Jessie with Pixel 的最新版系统中已经内置了这个功能，但默认是关闭的，所以需要创建一个名为 ssh 的文件（空白文件，且无任何后缀），并放入树莓派的根目录，然后开机 在终端ssh连接树莓派，默认用户名pi，密码raspberry，如果这种方式不可行，则用网线连接树莓派和路由器，然后到路由器管理界面找到树莓派的IP，使用IP地址进行ssh连接 12$ ssh pi@raspberrypi.local$ ssh pi@192.168.0.150 SSH连接成功后，输入 sudo raspi-config，进入设置界面 移动光标，选择第5项 Interfacing Options （旧版系统可能选第7项 Advanced Options），选择VNC，回车，YES，启用VNC 使用VNC客户端连接树莓派，我在Mac上用的是VNC Viewer，连接地址、用户名、密码都和SSH相同 在图形界面配置wifi，使用静态IP连接，并将SSH和VNC客户端中的IP地址进行修改 拔除树莓派的网线，完成","categories":[{"name":"硬件","slug":"硬件","permalink":"http://tyrival.github.io/categories/硬件/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"raspberry","slug":"raspberry","permalink":"http://tyrival.github.io/tags/raspberry/"}]},{"title":"Solr 01：用Intellij IDEA搭建服务","slug":"solr-01","date":"2017-05-27T05:53:05.000Z","updated":"2017-08-21T06:17:53.000Z","comments":true,"path":"posts/solr-01/","link":"","permalink":"http://tyrival.github.io/posts/solr-01/","excerpt":"solr可以使用自带的jetty启动，但为了后续开发和调试的方便，还是采用IDEA+tomcat的方式搭建环境。文中主要讲述怎样用Intellij IDEA搭建搜索引擎服务。","text":"solr可以使用自带的jetty启动，但为了后续开发和调试的方便，还是采用IDEA+tomcat的方式搭建环境。文中主要讲述怎样用Intellij IDEA搭建搜索引擎服务。 软件准备 Intellij IDEA 2017.1.3 tomcat-8.0.22 solr-6.5.1 mysql-connector-java-5.1.42-bin.jar - mysql驱动 ikanalyzer-solr - 分词匹配，适用于solr-6.5 pinyin4j-2.5.0.jar - 拼音检索 pinyinAnalyzer4.3.1.jar - 拼音检索 创建工程新建一个文件夹 solr，路径为 /Users/tyrival/Documents/Workspace/solr，进行如下操作： 1234567* solr-6.5.1\\server\\solr-webapp\\webapp 下所有内容复制到 solr 中* solr-6.5.1\\server\\lib 中所有jar复制到 solr\\WEB-INF\\lib 中* solr-6.5.1\\server\\lib\\ext 中所有jar复制到 solr\\WEB-INF\\lib 中* 新建 solr\\src\\main\\java 文件夹* solr-6.5.1\\server\\resources\\log4j.properties 复制到 solr\\src\\main\\java 中* 新建 solr\\solrhome 文件夹* solr-6.5.1\\server\\solr 中所有文件复制到 solr\\solrhome 中 Solrhome修改 solr\\WEB-INF\\web.xml 中的 env-entry-value 值，修改为项目中solrhome的绝对路径 12345&lt;env-entry&gt; &lt;env-entry-name&gt;solr/home&lt;/env-entry-name&gt; &lt;env-entry-value&gt;/Users/tyrival/Documents/Workspace/solr/solrhome&lt;/env-entry-value&gt; &lt;env-entry-type&gt;java.lang.String&lt;/env-entry-type&gt;&lt;/env-entry&gt; 配置IDEA打开Project Structure（Command + ;） 1234567891011121314151617Project* SDK -&gt; java 1.8Modules* 选中目录树上的solr* Sources标签，设置src\\main\\java为Sources类型* Paths标签，设置Output path：/Users/tyrival/Documents/Workspace/solr/WEB-INF/classes，勾选Exclude output paths* 选中目录树上的Web，如果没有，可以点上面的加号新建一个Web，然后点右下角出现的Fix按钮* 勾选右下方的Source RootsLibraries* 点顶部的+号，选择 solr\\WEB-INF\\lib 文件夹Artifacts* 点+号，选择Web Application:Exploded =&gt; From ModulesOK 打开Run/Debug Configurations，配置tomcat 1234567891011* 点左上角+号，选择Tomcat Server =&gt; Local* 输入NameServer* Open browser中，勾选After launch，输入默认打开路径为 http://localhost:8080/solr/index.htmlDeployment* 点面板中部的+号，选择Artifact =&gt; 第3步创建的solr:Web exploded* Application context改为 /solrOK 启动点运行，浏览器打开http://localhost:8080/solr/index.html，服务搭建成功。 配置core 新建 solr\\solrhome\\my_solr 文件夹 solr-6.5.1\\example\\example-DIH\\solr\\solr 中所有文件复制到刚创建的 my_solr 中 将mysql驱动 mysql-connector-java-5.1.42-bin.jar 复制到 solr/WEB-INF/lib 中， 修改 my_solr\\conf\\solr-data-config.xml 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;dataConfig&gt; &lt;!-- 数据库连接 --&gt; &lt;dataSource type=&quot;JdbcDataSource&quot; driver=&quot;com.mysql.jdbc.Driver&quot; url=&quot;jdbc:mysql://10.211.55.82:3306/test&quot; user=&quot;root&quot; password=&quot;root&quot;/&gt; &lt;!-- 数据表映射 --&gt; &lt;document name=&quot;solr_mysql_test&quot;&gt; &lt;entity name=&quot;solrTest&quot; pk=&quot;id&quot; query=&quot;select * from solrTest&quot; deltaImportQuery=&quot;select * from solrTest where id = &apos;$&#123;dih.delta.id&#125;&apos;&quot; deltaQuery=&quot;select id from solrTest where updateTime &gt; &apos;$&#123;dataimporter.last_index_time&#125;&apos;&quot;/&gt; &lt;field column=&quot;id&quot; name=&quot;id&quot;/&gt; &lt;field column=&quot;context&quot; name=&quot;context&quot;/&gt; &lt;field column=&quot;updateTime&quot; name=&quot;updateTime&quot;/&gt; &lt;field column=&quot;sort&quot; name=&quot;sort&quot;/&gt; &lt;/document&gt;&lt;/dataConfig&gt; 修改 my_solr\\conf\\managed-schema，在schema标签下添加 1234&lt;!-- 这里没有添加field = id，因为managed-schema中默认已经存在了 --&gt;&lt;field name=&quot;context&quot; type=&quot;string&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt; &lt;field name=&quot;updateTime&quot; type=&quot;date&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt; &lt;field name=&quot;sort&quot; type=&quot;int&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt; 这里可以将managed-schema复制为schema.xml，然后修改内容，这样对IDEA来说更清晰。 MySql1234567CREATE TABLE `solrTest` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;id&apos;, `context` varchar(255) DEFAULT NULL COMMENT &apos;context&apos;, `updateTime` datetime DEFAULT NULL COMMENT &apos;updateTime&apos;, `sort` int(11) DEFAULT &apos;1&apos; COMMENT &apos;排序&apos;, PRIMARY KEY (`id`) ) DEFAULT CHARSET=utf8; 插入几条测试数据。 导入插件 solr-6.5.1\\dist 下的 solr-dataimporthandler-6.0.0.jar 和 solr-dataimporthandler-extras-6.0.0.jar 复制到 solr\\WEB-INF\\lib 中 数据导入 打开http://localhost:8080/solr/index.html，左侧Core Selector选择my_solr 选择Dataimport，点击右侧Execute，刷新后出现如下信息 123Indexing completed. Added/Updated: 3 documents. Deleted 0 documents. (Duration: 01s)Requests: 1 1/s, Fetched: 3 3/s, Skipped: 0 , Processed: 3 3/sStarted: about 8 hours ago 展开Raw Status-Output 1234567891011121314151617181920212223242526&#123; &quot;responseHeader&quot;: &#123; &quot;status&quot;: 0, &quot;QTime&quot;: 0 &#125;, &quot;initArgs&quot;: [ &quot;defaults&quot;, [ &quot;config&quot;, &quot;solr-data-config.xml&quot; ] ], &quot;command&quot;: &quot;status&quot;, &quot;status&quot;: &quot;idle&quot;, &quot;importResponse&quot;: &quot;&quot;, &quot;statusMessages&quot;: &#123; &quot;Total Requests made to DataSource&quot;: &quot;1&quot;, &quot;Total Rows Fetched&quot;: &quot;3&quot;, &quot;Total Documents Processed&quot;: &quot;3&quot;, &quot;Total Documents Skipped&quot;: &quot;0&quot;, &quot;Full Dump Started&quot;: &quot;2017-05-27 14:47:32&quot;, &quot;&quot;: &quot;Indexing completed. Added/Updated: 3 documents. Deleted 0 documents.&quot;, &quot;Committed&quot;: &quot;2017-05-27 14:47:33&quot;, &quot;Time taken&quot;: &quot;0:0:0.602&quot; &#125;&#125; 如果导入失败，可以打开Logging查看错误日志 打开Query，点击Execute Query可以查看到导入的数据 分词、停止词、扩展词123* 复制 IKAnalyze-solr 中的 ik-analyzer-solr5-5.x.jar 和 solr-analyzer-ik-5.1.0.jar 到 solr\\WEB-INF\\lib 中* 复制 IKAnalyze-solr 中的 ext.dic、stopword.dic、IKAnalyzer.cfg.xml 到 solr\\src\\main\\java 中* 修改 IKAnalyzer.cfg.xml 123456789&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic;&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;stopword.dic;&lt;/entry&gt;&lt;/properties&gt; 修改 solr\\solrhome\\my_solr\\conf\\managed-schema，注册分词插件 12345678&lt;fieldType name=&quot;text_ik&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;org.apache.lucene.analysis.ik.IKTokenizerFactory&quot; useSmart=&quot;true&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;org.apache.lucene.analysis.ik.IKTokenizerFactory&quot; useSmart=&quot;true&quot;/&gt; &lt;/analyzer&gt;&lt;/fieldType&gt; 修改 solr\\solrhome\\my_solr\\conf\\managed-schema 中的 field=context，启用分词查询 1&lt;field name=&quot;context&quot; type=&quot;text_ik&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt; 在浏览器左侧进入my_solr =&gt; Query， 修改 q 为 context:关键词，就可以按照关键字进行分词匹配，查出结果。 停止词表示在查询中需要忽略的词，比如语气词“啊”、“呀”或者“的”、“得”等，可在stopword.dic中配置 扩展词表示部分非常用词汇、专业词汇、新造词，例如：“炉石传说”、“吉安娜”等，可在ext.dic重配置 拼音检索 复制 pinyin4j-2.5.0.jar、pinyinAnalyzer.jar 到 solr/WEB-INF/lib 中 在 solr\\solrhome\\my_solr\\conf\\managed-schema 的 schema 标签中增加： 123456789101112&lt;fieldType name=&quot;text_pinyin&quot; class=&quot;solr.TextField&quot; positionIncrementGap=&quot;0&quot;&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;org.apache.lucene.analysis.ik.IKTokenizerFactory&quot;/&gt; &lt;filter class=&quot;com.shentong.search.analyzers.PinyinTransformTokenFilterFactory&quot; minTermLenght=&quot;2&quot; /&gt; &lt;filter class=&quot;com.shentong.search.analyzers.PinyinNGramTokenFilterFactory&quot; minGram=&quot;1&quot; maxGram=&quot;20&quot; /&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;org.apache.lucene.analysis.ik.IKTokenizerFactory&quot;/&gt; &lt;filter class=&quot;com.shentong.search.analyzers.PinyinTransformTokenFilterFactory&quot; minTermLenght=&quot;2&quot; /&gt; &lt;filter class=&quot;com.shentong.search.analyzers.PinyinNGramTokenFilterFactory&quot; minGram=&quot;1&quot; maxGram=&quot;20&quot; /&gt; &lt;/analyzer&gt;&lt;/fieldType&gt; 在web端，Analysis中校验拼音检索 同义词 在 solr\\solrhome\\my_solr\\conf\\managed-schema 的 schema 标签中增加： 1234567891011&lt;fieldType name=&quot;text_syn&quot; class=&quot;solr.TextField&quot;&gt; &lt;analyzer type=&quot;query&quot;&gt; &lt;tokenizer class=&quot;solr.WhitespaceTokenizerFactory&quot;/&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt; &lt;analyzer type=&quot;index&quot;&gt; &lt;tokenizer class=&quot;solr.WhitespaceTokenizerFactory&quot;/&gt; &lt;filter class=&quot;solr.SynonymFilterFactory&quot; synonyms=&quot;synonyms.txt&quot; ignoreCase=&quot;true&quot; expand=&quot;false&quot;/&gt; &lt;filter class=&quot;solr.LowerCaseFilterFactory&quot;/&gt; &lt;/analyzer&gt;&lt;/fieldType&gt; 修改 solr\\solrhome\\my_solr\\conf\\managed-schema 中的 field=context，启用同义词查询 1&lt;field name=&quot;context&quot; type=&quot;text_syn&quot; indexed=&quot;true&quot; stored=&quot;true&quot; multiValued=&quot;false&quot;/&gt; 在 solr\\solrhome\\my_solr\\conf\\synonyms.txt 中增加同义词映射： 12345# 格式1，箭头表示映射测试 =&gt; test# 格式2，用英文逗号隔开同义词组测试,test,tst 在web端，Analysis中校验同义词检索","categories":[{"name":"系统","slug":"系统","permalink":"http://tyrival.github.io/categories/系统/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"linux","slug":"linux","permalink":"http://tyrival.github.io/tags/linux/"},{"name":"database","slug":"database","permalink":"http://tyrival.github.io/tags/database/"}]},{"title":"CentOS 7 安装JDK、MySql","slug":"server-jdk-mysql","date":"2017-05-27T05:52:20.000Z","updated":"2017-05-27T09:33:57.000Z","comments":true,"path":"posts/server-jdk-mysql/","link":"","permalink":"http://tyrival.github.io/posts/server-jdk-mysql/","excerpt":"怎样部署CentOS 7服务器环境。","text":"怎样部署CentOS 7服务器环境。 关闭防火墙（通常只用于开发环境）1234# service iptables stop // 暂时关闭# chkconfig iptables off // 永久关闭# systemctl stop firewalld.service // 关闭firewall# systemctl disable firewalld.service // 禁止firewall开机启动# vim /etc/sysconfig/selinux // 设置SELINUX=disabled 安装JDK 1.8123456789101112// 下载jdk-8u131-linux-x64.rpm# yum localinstall jdk-8u131-linux-x64.rpm# vi /etc/profile// 添加以下内容export JAVA_HOME=/usr/java/jdk1.8.0_131export PATH=$JAVA_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar# source /etc/profile# exit$ source /etc/profile 安装MySql1234567891011121314151617181920212223242526272829303132333435363738394041# yum install mysql# yum install mysql-devel# yum install mariadb-server mariadb// 启动# systemctl start mariadb// 无密码，按回车登录# mysql -u root -p MariaDB [(none)]&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || test |+--------------------+4 rows in set (0.00 sec)MariaDB [(none)]&gt; use mysql;MariaDB [mysql]&gt; select host,user from user;+-----------+------+| host | user |+-----------+------+| 127.0.0.1 | root || ::1 | root || centos | || centos | root || localhost | || localhost | root |+-----------+------+6 rows in set (0.00 sec)// 修改root为任意位置可登录MariaDB [mysql]&gt; update user set host=&apos;%&apos; where user=&apos;root&apos; and host=&apos;centos&apos;;// 登录授权，密码设置为rootMariaDB [mysql]&gt; GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;root&apos; WITH GRANT OPTION;MariaDB [mysql]&gt; flush privileges;","categories":[{"name":"系统","slug":"系统","permalink":"http://tyrival.github.io/categories/系统/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"linux","slug":"linux","permalink":"http://tyrival.github.io/tags/linux/"},{"name":"database","slug":"database","permalink":"http://tyrival.github.io/tags/database/"}]},{"title":"CSS文字竖排垂直居中","slug":"css-text-vertical-align-center","date":"2017-04-27T00:54:20.000Z","updated":"2017-04-27T01:18:34.000Z","comments":true,"path":"posts/css-text-vertical-align-center/","link":"","permalink":"http://tyrival.github.io/posts/css-text-vertical-align-center/","excerpt":"文字竖排","text":"文字竖排 1letter-spacing: 5px; 垂直居中 1234567891011.wrapper&#123; text-align: center; width: 100%; height: 100%; display: table;&#125;.subwrap&#123; display: table-cell; vertical-align: middle;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"css","slug":"css","permalink":"http://tyrival.github.io/tags/css/"}]},{"title":"Hadoop 07：Hadoop编程","slug":"hadoop-07-hadoop-programming","date":"2017-04-27T00:51:20.000Z","updated":"2017-04-30T00:01:37.000Z","comments":true,"path":"posts/hadoop-07-hadoop-programming/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-07-hadoop-programming/","excerpt":"介绍用Intellij IDEA编写Hadoop程序。","text":"介绍用Intellij IDEA编写Hadoop程序。 用IDEA创建一个maven项目，pom.xml如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.o&lt;/groupId&gt; &lt;artifactId&gt;hadoop&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-mapreduce-client-jobclient&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-cli&lt;/groupId&gt; &lt;artifactId&gt;commons-cli&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;cn.o.WordCount&lt;/mainClass&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;classesDirectory&gt; &lt;/classesDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; WordCount.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package cn.o;import java.io.IOException;import java.util.StringTokenizer;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.util.GenericOptionsParser;public class WordCount &#123; public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123; private final static IntWritable one = new IntWritable(1); private Text word = new Text(); public void map(Object key, Text value, Context context ) throws IOException, InterruptedException &#123; StringTokenizer itr = new StringTokenizer(value.toString()); while (itr.hasMoreTokens()) &#123; word.set(itr.nextToken()); context.write(word, one); &#125; &#125; &#125; public static class IntSumReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; &#123; private IntWritable result = new IntWritable(); public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context ) throws IOException, InterruptedException &#123; int sum = 0; for (IntWritable val : values) &#123; sum += val.get(); &#125; result.set(sum); context.write(key, result); &#125; &#125; public static void main(String[] args) throws Exception &#123; Configuration conf = new Configuration(); String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs(); if (otherArgs.length &lt; 2) &#123; System.err.println(&quot;Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;); System.exit(2); &#125; Job job = Job.getInstance(conf, &quot;word count&quot;); job.setJarByClass(WordCount.class); job.setMapperClass(TokenizerMapper.class); job.setCombinerClass(IntSumReducer.class); job.setReducerClass(IntSumReducer.class); job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); for (int i = 0; i &lt; otherArgs.length - 1; ++i) &#123; FileInputFormat.addInputPath(job, new Path(otherArgs[i])); &#125; FileOutputFormat.setOutputPath(job, new Path(otherArgs[otherArgs.length - 1])); System.exit(job.waitForCompletion(true) ? 0 : 1); &#125;&#125; Project Structure -&gt; Artifacts -&gt; + -&gt; JAR -&gt; From modules with dependencies Manifest File：/Users/tyrival/Documents/Workspace/hadoop/src/ Main Class：cn.o.WordCount Output directory：/Users/tyrival/Desktop 菜单 -&gt; Build -&gt; Build Artifacts -&gt; hadoop:jar -&gt; Build 将输出的hadoop.jar包放到CentOS的/home/hadoop/Desktop/ 在hdfs中建立/test/input/wc.input文件 进入hadoop目录，并执行上传的WordCount.jar12# cd /opt/modules/hadoop-2.8.0# bin/yarn jar /home/hadoop/Desktop/hadoop.jar /test/input/wc.input /test/output 此处与执行hadoop example中的wordcount不同，不需要指明package和class，hadoop example中自带wordcount的执行代码如下：bin/yarn jar hadoop-mapreduce-examples.jar wordcount /test/input/wc.input /test/output","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Hadoop 06：Ambari集群部署","slug":"hadoop-06-ambari-cluster-install","date":"2017-04-27T00:50:57.000Z","updated":"2017-04-27T01:27:10.000Z","comments":true,"path":"posts/hadoop-06-ambari-cluster-install/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-06-ambari-cluster-install/","excerpt":"介绍Ambari搭建本地仓库并部署集群。","text":"介绍Ambari搭建本地仓库并部署集群。 操作系统：CentOS-7-x86_64-DVD-1611硬件要求：master要6G内存，slave要4G内存，客户端要2G内存 环境准备，所有机器上都需要执行以下内容： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/* 开机启动网卡 */# vim /etc/sysconfig/network-scripts/ifcfg-eth0ONBOOT=yes# service network restart // 重启网卡# ifconfig // 查看IP/* 修改hostname */# hostname master.o.cn # vim /etc/sysconfig/network // 永久修改hostnameHOSTNAME=master.o.cn // slave机器命名为slave.o.cn/* 关闭iptables、防火墙、SELinux、PackageKit */# service iptables stop // 暂时关闭# chkconfig iptables off // 永久关闭# systemctl stop firewalld.service // 关闭firewall# systemctl disable firewalld.service // 禁止firewall开机启动# vim /etc/selinux/configSELINUX=disabled# vim /etc/yum/pluginconf.d/refresh-packagekit.confenabled=0/* 同步时钟 */# yum install ntpd // 安装同步时钟# service ntpd start // 启动# chkconfig ntpd on // 设置开机启动/* 重启生效 */# reboot# hostname# service iptables status# service ntpd status# sestatus -v/* 添加域名映射 */# vim /etc/hosts192.168.0.100 master.o.cn192.168.0.101 slave01.o.cn.../* SSH免密码登录 *//* master */# ssh-keygen -t rsa // 按三次回车# cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys# scp /root/.ssh/id_rsa.pub root@slave01.o.cn:~//* slave */# ssh-keygen -t rsa# cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys# cat id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys# scp /root/.ssh/id_rsa.pub root@master.o.cn:~//* master */# cat id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys# ssh slave01.o.cn // 测试是否成功 本地仓库搭建在hortonworks.com下载Ambari、HDP、HDP-UTILS三个压缩包，将Ambari上传至仓库服务器的/var/www/html目录，HDP和HDP-UTILS上传至/var/www/html/hdp目录 123456789101112/* 安装httpd */# yum install httpd // 安装# service httpd start // 启动# chkconfig httpd on // 开机启动/* 解压缩 */# tar -zxvf /var/www/html/Ambari.tar.gz# tar -zxvf /var/www/html/hdp/HDP.tar.gz# tar -zxvf /var/www/html/hdp/HDP-UTILS.tar.gz# rm -rf /var/www/html/Ambari.tar.gz# rm -rf /var/www/html/hdp/HDP.tar.gz# rm -rf /var/www/html/hdp/HDP-UTILS.tar.gz 在浏览器中输入以下路径可以访问资源目录： Repo URL Ambari http://[仓库服务器IP]/ambari/centos7 HDP http://[仓库服务器IP]/hdp/HDP/centos7 HDP-UTILS http://[仓库服务器IP]/hdp 安装 1234567891011121314151617181920212223/* 编辑ambari.repo */# cp /var/www/html/ambari/centos7/ambari.repo ./# vim ambari.repobaseurl=http://master.o.cn/ambari.centos7# cp ambari.repo /etc/yum.repos.d//* 安装ambari */# yum install ambari-serverInstalling : postgresql-libs-9.2.18-1.el7.x86_64 Installing : postgresql-9.2.18-1.el7.x86_64 Installing : postgresql-server-9.2.18-1.el7.x86_64 Installing : ambari-server-2.5.0.3-1050.x86_64 Verifying : ambari-server-2.5.0.3-1050.x86_64 Verifying : postgresql-9.2.18-1.el7.x86_64 Verifying : postgresql-server-9.2.18-1.el7.x86_64 Verifying : postgresql-libs-9.2.18-1.el7.x86_64Installed:ambari-server.x86_64 0:2.5.0.3-1050Dependency Installed:postgresql.x86_64 0:9.2.18-1.el7 postgresql-libs.x86_64 0:9.2.18-1.el7 postgresql-server.x86_64 0:9.2.18-1.el7 Complete! 配置 123456789101112131415// 如需使用自定义数据库，需要在配置ambari前将数据库准备完成// 不支持MSSQL Server和SQL Anywhere数据库# ambari-server setup1. 如果SELinux未禁用，会跳出提示，选择y；2. 用当前root用户运行ambari，选择n；3. 如果iptables未禁用，会跳出提示，选择y；4. 下载安装JDK1.8，选择1，；5. 同意JDK协议，选择y；6. 使用默认的PostgreSQL数据库配置（数据库ambari，用户名ambari，密码bigdata），选择n； // 如果使用自定义数据库，选择y，并且按照下列步骤： // Oracle：输入2； // MySQL/MariaDB：输入3； // PostgreSQL：输入4； // 输入数据库服务器IP、数据库名、用户名、密码； // 确定，选择y； 启动 123456789# ambari-server start // 停止服务 ambari-server stop...Ambari Server &apos;start&apos; completed successfully.# ambari-server statusUsing python /usr/bin/pythonAmbari-server statusAmbari Server runningFound Ambari Server PID: 11066 at: /var/run/ambari-server/ambari-server.pid 登录Apache Ambarihttp://[安装Ambari的系统IP]:8080默认：账号admin，默认admin如果无法登录，尝试以下操作 123456# service iptables stop // 暂时关闭# chkconfig iptables off // 永久关闭# systemctl stop firewalld.service // 关闭firewall# systemctl disable firewalld.service // 禁止firewall开机启动# service iptables status // 查看防火墙状态# vim /etc/sysconfig/selinux // 设置SELINUX=disabled 启动Ambari Cluster安装向导，选择Launch Install Wizard 输入集群名：Tyrival； 选择HDP版本和软件安装仓库，centos7：HDP：http://master.o.cn/hdp/HDP/centos7HDP-UTILS：http://master.o.cn/hdp 在Target Hosts输入Hosts名称，可以输入多台服务器地址，SSH Private Key中上传输入master机器的id_rsa内容； 下一步直到结束。 部署成功。","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Hadoop 05：HDP Sandbox","slug":"hadoop-05-hdp-sandbox-sample","date":"2017-04-27T00:50:29.000Z","updated":"2017-04-27T01:26:27.000Z","comments":true,"path":"posts/hadoop-05-hdp-sandbox-sample/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-05-hdp-sandbox-sample/","excerpt":"初步介绍HDP的使用。","text":"初步介绍HDP的使用。 环境：VMware + HDP Sandbox for VMware SSH登录 123ssh root@172.16.147.128 -p 2222// 由于HDP使用Docker，必须要加上2222端口号// 登录时需要修改root密码 运行WordCount 123456789101112131415161718192021# cd /usr/hdp/2.5.0.0-1245/hadoop-mapreduce/# cp hadoop-mapreduce-examples-2.7.3.2.5.0.0-1245.jar ~# cd ~# vi word.txti like hadoophadoop is bestlucky hadoop# hdfs dfs -mkdir /user/tyrival# hdfs dfs -put word.txt /user/tyrival# yarn jar hadoop-mapreduce-examples-2.7.3.2.5.0.0-1245.jar wordcount /user/tyrival/word.txt /user/tyrival/word.txt.out# hdfs dfs -text /user/tyrival/word.txt.out/*|cat17/04/08 03:08:12 INFO lzo.GPLNativeCodeLoader: Loaded native gpl library17/04/08 03:08:12 INFO lzo.LzoCodec: Successfully loaded &amp; initialized native-lzo library [hadoop-lzo rev 7a4b57bedce694048432dd5bf5b90a6c8ccdba80]best 1hadoop 3i 1is 1like 1lucky 1 登录管理界面http://sandbox.hortonworks.com:8080/sandbox.hortonworks.com通过配置host指向VMware虚拟机的IP账号密码：raj_ops / raj_ops","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Hadoop 04：WordCount","slug":"hadoop-04-wordcount-sample","date":"2017-04-27T00:49:31.000Z","updated":"2017-04-27T01:26:01.000Z","comments":true,"path":"posts/hadoop-04-wordcount-sample/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-04-wordcount-sample/","excerpt":"WordCount案例。","text":"WordCount案例。 创建文件目录 1# bin/hdfs dfs -mkdir /test/input/ 创建并编写input文件 123# touch wc.input# vim wc.input写若干个单词，用回车或空格分开 将input文件放入input目录 1# bin/hdfs dfs -put ./wc.input /test/input/ 查看文件内容 1# bin/hdfs dfs -text /test/input/wc.input 运行WordCount案例 1# bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar wordcount /test/input/wc.input /test/output 查看结果 123456789101112# bin/hdfs dfs -ls /test/outputound 2 items-rw-r--r-- 1 root supergroup 0 2017-04-07 06:17 /test/output/_SUCCESS-rw-r--r-- 1 root supergroup 50 2017-04-07 06:17 /test/output/part-r-00000# bin/hdfs dfs -text /test/output/part-r-00000hadoop 4hdfs 2hello 1mapreduce 1wor1 1yarn 2","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Hadoop 03：启动YARN","slug":"hadoop-03-start-yarn","date":"2017-04-27T00:49:21.000Z","updated":"2017-04-27T01:25:48.000Z","comments":true,"path":"posts/hadoop-03-start-yarn/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-03-start-yarn/","excerpt":"介绍YARN的启动。","text":"介绍YARN的启动。 启动ResourceManager 1# sbin/yarn-daemon.sh start resourcemanager 启动NodeManager 1# sbin/yarn-daemon.sh start nodemanager 访问http://hadoop.o.cn:8088/cluster，可查看YARN状态 访问http://hadoop.o.cn:8088/logs，可查看YARN日志 运行案例 1# bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.0.jar pi 5 20 // Map=5 样本=20 访问http://hadoop.o.cn:8088/cluster，-&gt; Applications 可以看到运行统计 Job Id分配原则：job_年月日时分_job序列号，序列号从0开始，上限为1000 Task Id分配原则： job_年月日时分_job序列号_task序列号_m ，m代表map task slot job_年月日时分_job序列号_task序列号_r，r代表reduce task slot task序列号从0开始，上限为1000 启动历史服务器1# sbin/mr-jobhistory-daemon.sh start historyserver 访问http://hadoop.o.cn:8088/cluster，点击任务后的history，跳转http://hadoop.o.cn:19888/jobhistory/job/job_1491481769386_0001， 可查看运行历史。","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Hadoop 02：常用命令和配置","slug":"hadoop-02-commond","date":"2017-04-27T00:49:01.000Z","updated":"2017-04-27T01:25:30.000Z","comments":true,"path":"posts/hadoop-02-commond/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-02-commond/","excerpt":"介绍hadoop常用命令和配置。","text":"介绍hadoop常用命令和配置。 文件操作 查看File system 1# bin/hdfs dfs -ls / // 查看根目录 将文件放入File system 123# bin/hdfs dfs -put test.txt /data01# bin/hdfs dfs -ls /data01 // 读data01中的文件列表# bin/hdfs dfs -cat /data01/test.txt // 读文件text.txt 删除文件 1# bin/hdfs dfs -rm /data01/test.txt 删除目录 1# bin/hdfs dfs -rmdir /data01 HDFS用户权限 操作File system目录时，会根据校验是否是当前用户拥有的File system，如果不是，会禁止操作并报错。解决方案是配置文件hdfs-site.xml，添加以下内容：1234&lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt;&lt;/property&gt; 重启服务1234567# cd /opt/modules/hadoop-2.8.0# sbin/hadoop-daemon.sh stop namenode // 关闭namenode# sbin/hadoop-daemon.sh stop datanode // 关闭datanode# sbin/hadoop-daemon.sh start namenode // 启动namenode# sbin/hadoop-daemon.sh start datanode // 启动datanode# bin/hdfs dfsadmin -safemode get // 查看安全模式Safe mode is OFF 修改文件所有者1# bin/hdfs dfs -chown -R hadoop /test // 修改hadoop为test拥有者","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Hadoop 01：伪分布式安装","slug":"hadoop-01-install","date":"2017-04-27T00:48:03.000Z","updated":"2017-12-08T09:22:24.000Z","comments":true,"path":"posts/hadoop-01-install/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-01-install/","excerpt":"介绍伪分布式安装Hadoop步骤。","text":"介绍伪分布式安装Hadoop步骤。 操作系统：CentOS-7-x86_64-Everything-1611 切换到root用户 12$ suPassword: 开启SSH远程登录 关闭防火墙和禁用SELinux 123456# service iptables stop // 暂时关闭# chkconfig iptables off // 永久关闭# systemctl stop firewalld.service // 关闭firewall# systemctl disable firewalld.service // 禁止firewall开机启动# service iptables status // 查看防火墙状态# vim /etc/sysconfig/selinux // 设置SELINUX=disabled 设置静态IP地址 123456# vim /etc/sysconfig/network-scripts/ifcfg-eth0ONBOOT=yesIPADDR=10.211.55.11GATEWAY=10.211.55.1# service network restart 修改HostName 1234# hostname hadoop.o.cn // 当前生效# vim /etc/sysconfig/network // 下次启动生效NETWORKING=yesHOSTNAME=hadoop.o.cn IP与HostName绑定 12# vim /etc/hosts10.211.55.11 hadoop.o.cn hadoop // 用tab分隔，不用空格 安装JDK 12345678安装目录 /opt/modules/jdk1.8.0_121# sudo vim ~/.bashrc // 文件末尾添加以下内容export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_121export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATH # source ~/.bashrc 设置系统默认jdk版本 12345678# update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_121/bin/java 300 # update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_121/bin/javac 300 # update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/jdk1.8.0_121/bin/jar 300 # update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/jdk1.8.0_121/bin/javah 300 # update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/jdk1.8.0_121/bin/javap 300 # update-alternatives --config java# java -versionjava version &quot;1.8.0_121&quot; hadoop安装目录：/opt/modules/ 解压TAR包 1# tar -zxvf hadoop-2.8.0.tar.gz -C /opt/modules/ 进入hadoop文件夹 1# cd /opt/modules/hadoop-2.8.0 修改配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# cd /opt/modules/hadoop-2.8.0/etc/hadoop# vim hadoop-env.sh // 如下修改JAVA_HOMEexport JAVA_HOME=/opt/modules/jdk1.8.0_121# vim yarn-env.sh // 添加以下内容export JAVA_HOME=/opt/modules/jdk1.8.0_121# vim mapred-env.sh // 添加以下内容export JAVA_HOME=/opt/modules/jdk1.8.0_121# vim core-site.xml // 配置NameNode和缓存文件夹&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://hadoop.o.cn:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.8.0/data/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;# vim hdfs-site.xml // 设置hdfs副本数为1&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;# vim yarn-site.xml // 配置yarn&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;# cp mapred-site.xml.template mapred-site.xml // 复制模板# vim mapred-site.xml // mapreduce运行于yarn框架中&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 退回Hadoop根目录 12# cd /opt/modules/Hadoop-2.8.0 // 退回Hadoop根目录# mkdir -p data/tmp // 创建core-site.xml中的tmp目录 启动HDFS 12345678910111213# bin/hdfs namenode -format // NameNode格式化扩展： * 指定Cluster ID为yarn-cluster # bin/hdfs namenode -format -clusterid yarn-cluster# sbin/hadoop-daemon.sh start namenode // 启动NameNode# sbin/hadoop-daemon.sh start datanode // 启动DataNode# sbin/hadoop-daemon.sh start secondarynamenode // 启动SecondaryNameNode# jps // 查看进程5751 DataNode11114 Jps5098 NameNode11051 SecondaryNameNode 创建File system 1234# bin/hdfs dfs -mkdir /data01# bin/hdfs dfs -ls / // 查看Found 1 itemsdrwxr-xr-x - root supergroup 0 2017-04-06 14:41 /data01 登录hadoop.o.cn:50070Utilities -&gt; Browser the file system 可看到data01 日志文件：$HADOOP_HOME/logs.log ：通过log4j记录的大部分应用程序的日志.out ：记录标准输出和标准错误日志，少量命名规则：框架名称 - 用户名 - 进程名 - 主机名 - 日志格式后缀","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"Parallels Desktop虚拟机Gnome分辨率","slug":"pd-gnome-display","date":"2017-04-27T00:45:21.000Z","updated":"2018-01-10T01:27:43.000Z","comments":true,"path":"posts/pd-gnome-display/","link":"","permalink":"http://tyrival.github.io/posts/pd-gnome-display/","excerpt":"怎样优化Gnome在高分辨率屏幕上的效果。","text":"怎样优化Gnome在高分辨率屏幕上的效果。 Linux虚拟机 - 配置 - 硬件 - 图形 - 分辨率：更懂控件 在终端执行下列代码 123# gsettings set org.gnome.desktop.interface scaling-factor 2# export GDK_SCALE=2# export GDK_DPI_SCALE=0.5 如果是CentOS 7，直接全局搜索tweak-tool，修改【字体】-【缩放比例】为1.5","categories":[{"name":"系统","slug":"系统","permalink":"http://tyrival.github.io/categories/系统/"}],"tags":[{"name":"mac","slug":"mac","permalink":"http://tyrival.github.io/tags/mac/"},{"name":"linux","slug":"linux","permalink":"http://tyrival.github.io/tags/linux/"}]},{"title":"Javascript模块化编程","slug":"js-module-programming","date":"2017-02-24T08:07:09.000Z","updated":"2017-06-19T06:15:53.000Z","comments":true,"path":"posts/js-module-programming/","link":"","permalink":"http://tyrival.github.io/posts/js-module-programming/","excerpt":"简介Javascript模块化编程的入门知识。","text":"简介Javascript模块化编程的入门知识。 最简单的实现 123456789101112var Calc = function () &#123; var eqAdd = 10; return &#123; add: function (x) &#123; return x + eqAdd; &#125; &#125;;&#125;;var cal = new Calc();console.log(cal.add(5)); // 15 问题是，每次都要new一个对象，占用内存。那我们干脆在全局定义一个实例，存储这个对象。 先看下闭包 123456789/* 方式1 */(function () &#123; // 内部代码&#125;());/* 方式2 */(function () &#123; // 内部代码&#125;)(); 引用一个全局变量 123(function ($, Yahoo) &#123; // 这里的代码就可以访问全局对象jQuery和Yahoo了&#125; (jQuery, Yahoo)); 这里只是访问了全局对象，我们经常需要声明全局变量。 声明全局变量 12345678910111213141516var myModule = (function () &#123; var me = &#123;&#125;, name = &quot;Tyrival&quot;; function privateAddTopic (topic) &#123; return name + &quot; &quot; + topic; &#125; me.addTopic = function (data) &#123; return privateAddTopic(data); &#125;; return me;&#125;)myModule.addTopic(&quot;has a new topic&quot;)console.log(myModule.name); // Tyrival has a new topic 看起来这个已经可以了，但是这种做法适用于独立开发一个模块的情况，无法协作开发同一个myModule，浏览器同时引入多个定义myModule对象的代码时，后引入的会覆盖先引入的，所以，就需要使myModule可扩展。 扩展 123456var myModule = (function (me) &#123; me.addPhoto = function () &#123; // do something &#125;; return me;&#125;(myModule)) 这样就对myModule扩展了addPhoto方法，并且原来的addTopic方法还在。但是又出现新的问题，必须先写第4步的声明myModule，如果直接执行第5步，将myModule传为参数，将报错： 1Uncaught TypeError: Cannot set property &apos;addPhoto&apos; of undefined // myModule is undefined 松耦合扩展 12345678910/** * 利用 var myModule = myModule || &#123;&#125;来实现Module模式的任意顺序加载 * 需要注意的是，此处必须加上var声明，否则其他文件读取不到这个myModule */var myModule = (function (me) &#123; me.addPhoto = function () &#123; // do something &#125;; return me;&#125;(myModule || &#123;&#125;)) 松耦合扩展也是有限制的，比如无法重写属性或函数，紧耦合扩展限制了加载顺序，同时提供了重载的功能。 紧耦合模式 123456789var myModule = (function (me) &#123; this.oldAddPhotoMethod = me.addPhoto; me.addPhoto = function () &#123; // do something &#125;; return me;&#125;(myModule)); 如果想使用重载前的方法，可以调用oldAddPhotoMethod方法。 克隆与继承 1234567891011121314151617var myModule = (function (old) &#123; var me = &#123;&#125;, key; for (key in old) &#123; if (old.hasOwnProperty (key) &#123; me[key] = old[key]; &#125;) &#125; var oldAddPhotoMethod = old.addPhoto; me.addPhoto = function () &#123; // do something &#125; returm me;&#125;(myModule)); 这种方式也会有个问题，就是新对象并没有复制老对象的属性和方法，而是引用。也就是说，如果老对象的属性或方法被修改后，新的对象也会同步变化。 1234567891011121314151617var blogModule = (function (me) &#123; var _private = me._private = me._private || &#123;&#125;, _seal = me._seal = me._seal || function () &#123; delete me._private; delete me._seal; delete me._unseal; &#125;, _unseal = me._unseal = me._unseal || function () &#123; me._private = _private; me._seal = _seal; me._unseal = _unseal; &#125;; return me;&#125;(blogModule || &#123;&#125;)); 任何文件都可以对他们的局部变量_private设属性，并且设置对其他的文件也立即生效。一旦这个模块加载结束，应用会调用 blogModule._seal()”上锁”，这会阻止外部接入内部的_private。如果这个模块需要再次增生，应用的生命周期内，任何文件都可以调用_unseal() ”开锁”，然后再加载新文件。加载后再次调用_seal()”上锁”。","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"Ubuntu+ownCloud搭建私有云教程","slug":"cloud-owncloud-build","date":"2016-12-25T02:55:12.000Z","updated":"2017-08-21T06:08:24.000Z","comments":true,"path":"posts/cloud-owncloud-build/","link":"","permalink":"http://tyrival.github.io/posts/cloud-owncloud-build/","excerpt":"本文简单介绍了Ubuntu环境下，搭建ownCloud私有云的详细过程。为什么选择ownCloud而不是Seafile呢，因为Seafile的所有数据文件在服务器上都是进行了切割和整合存储的，而ownCloud则是将文件原样保存在服务器上，也就是说，如果别人能访问你的主机，可以绕过ownCloud直接查看你私有云的文件。如果你对安全性的要求较高，就选择Seafile；而我比较在意的是，如果系统崩溃了，或者换服务器了，可以比较方便的将所有文件迁移或直接导出来，所以我选择ownCloud。","text":"本文简单介绍了Ubuntu环境下，搭建ownCloud私有云的详细过程。为什么选择ownCloud而不是Seafile呢，因为Seafile的所有数据文件在服务器上都是进行了切割和整合存储的，而ownCloud则是将文件原样保存在服务器上，也就是说，如果别人能访问你的主机，可以绕过ownCloud直接查看你私有云的文件。如果你对安全性的要求较高，就选择Seafile；而我比较在意的是，如果系统崩溃了，或者换服务器了，可以比较方便的将所有文件迁移或直接导出来，所以我选择ownCloud。 搭建内网云 首先，得有一个能装Ubuntu的电脑，但先不要选择和安装Ubuntu。 访问：ownCloud下载，在页面上选择Ubuntu（或其他系统），根据下面列出的系统版本选择Ubuntu的版本，到Ubuntu官网下载相应版本，并安装，安装是建议单独分一个较大的区挂在/home。另外，建议后续所有要输入密码的地方，都与Ubuntu的管理员密码保持一致。 安装ssh服务端（不装的话只是没法用ssh连接服务器进行远程而已，仍旧可以在服务器进行配置） 12sudo apt updatesudo apt install openssh-server 安装vim 1sudo apt install vim 安装并启动Apache2 1234567sudo apt updatesudo apt install apache2 -y// 启动Apache2sudo systemctl start apache2.servicesudo systemctl enable apache2.servicesudo systemctl status apache2.service // 用:q退出 如果你开启了 Ubuntu 的防火墙（ufw），那么你可以使用如下的命令来解除 web 服务器的端口（80和443）限制 12345sudo ufw status=&gt; Status: active // 状态为不活动时，无需继续执行后续指令sudo ufw allow in &apos;Apache Full&apos;=&gt; Rule added=&gt; Rule added (v6) 打开浏览器，输入 (http://服务器IP)，能访问到Apache2的默认页面，说明Apache2安装成功。 安装MySql 1sudo apt install mysql-server mysql-client 安装过程中会要求你设置mysql的root密码，设置完成后，可以执行下列命令查看MySql状态： 1sudo systemctl status mysql.service MariaDB Server安装 1sudo apt install mariadb-server 运行如下的命令来设置 MariaDB root 帐户的密码，中间会让你作几个选择，比如是否关闭远程登录功能。 1sudo mysql_secure_installation PHP 脚本语言的安装 1sudo apt install php7.0-mysql php7.0-curl php7.0-json php7.0-cgi php7.0 libapache2-mod-php7.0 安装phpMyAdmin 123sudo apt install php-mbstring php7.0-mbstring php-gettextsudo systemctl restart apache2.servicesudo apt install phpmyadmin 安装过程中，它会提示我们选择 phpMyAdmin 运行的目标服务器，选择 Apache2 并点击确定。还需要设置phpMyAdmin向数据库服务器注册时所用的密码。 然后可以开始尝试访问 phpMyAdmin，打开浏览器并输入：http://服务器IP/phpmyadmin ，使用我们安装时设置的 root 帐户和密码，可以访问phpMyAdmin。 至此，LAMP全部安装完成。 安装ownCloud 在刚才的ownCloud下载，一般会有两种标题以供选择，执行不带files字样命令 Ubuntu_16.04 owncloud-9.1.3-1.1 &lt;== 执行这个下面的命令 123456789wget -nv https://download.owncloud.org/download/repositories/stable/Ubuntu_16.04/Release.key -O Release.keysudo apt-key add - &lt; Release.keysudo sh -c &quot;echo &apos;deb http://download.owncloud.org/download/repositories/stable/Ubuntu_16.04/ /&apos; &gt; /etc/apt/sources.list.d/owncloud.list&quot;sudo apt-get updatesudo apt-get install owncloud Ubuntu_16.04 owncloud-files-9.1.3-1.1 &lt;== 这个无视 1...... 配置MySql数据库 123456789101112131415161718192021// 登录mysqlsudo mysql -u root -p// 输入密码// 创建owncloud专用库CREATE DATABASE owncloud;// 创建一个单独的MySQL用户帐户owncloudGRANT ALL ON owncloud.* to &apos;owncloud&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;密码&apos;;/** * 如果上面脑抽直接复制语句执行了，导致owncloud的密码设置为&quot;密码&quot;，就用root登录mysql后，用下面的命令修改密码 * USE mysql * UPDATE user SET password = password(”新密码”) WHERE user = “owncloud”; * FLUSH PRIVILEGES; */ FLUSH PRIVILEGES;exit 初始化ownCloud，在浏览器输入 1http://服务器IP/owncloud 应当会跳出一个管理界面，在界面上输入： 12345678910用户名：按需设置密码：按需设置数据目录：/var/www/owncloud/data配置数据库：用户名：owncloud密码：******数据库名：owncloud地址：localhost 修改数据存储位置 停止apache2 1service apache2 stop // 需要输入密码 在/home/tyrival下创建owncloud用于存储数据，这就是第2步单独挂载/home的原因 12cd /home/tyrivalmkdir owncloud 编辑owncloud配置文件 1sudo vim /var/www/owncloud/config/config.php 修改配置文件 12345&apos;datadirectory&apos; =&gt; &apos;/var/www/owncloud/data&apos;改为&apos;datadirectory&apos; =&gt; &apos;/home/tyrival/owncloud&apos;// :wq 保存退出 查看原始文件夹/var/www/owncloud/data权限，所有者和组通常都为www-data，将其修改为系统用户 1sudo chown -R tyrival:tyrival /var/www/owncloud/data 进入此文件夹，将其中所有的文件复制到/home/tyrival/owncloud中，包括隐藏文件.htaccess和.ocdata，然后修改目标文件夹所有者和权限 12sudo chown -R www-data:www-data /home/tyrival/owncloudsudo chmod 770 /home/tyrival/owncloud // 修改后无法访问 启动apache2 1service apache2 start // 需要输入密码 至此，数据文件夹修改完成。 浏览器访问： http://服务器IP/owncloud，登录后，点击右上角的用户名，选择“管理”，然后选择左侧菜单“文件处理”，可以修改上传文件的最大限制，通常我设置为10240 MB。 内网云搭建完成。 搭建外网云由于使用的是ADSL，ip是动态的，所以希望能动态获取ip并进行解析，国内最有名的花生壳又不是很稳定，现在阿里云开放了API，有人已经写了个动态域名解析工具出来，而且是跨平台的，直接配置下就能用。步骤如下： 首先得有一个带端口转发功能的路由器，否则外网访问你的ip只能访问到路由器，无法穿透到内网中访问到云服务器，除非你直接把云服务器接在电信的modem上拨号。 先到阿里云注册账号，申请域名，现在域名一年的费用是60，新注册还能便宜点。 进入阿里云的管理界面，选择左侧的“域名与网站”—“云解析DNS”，勾选注册的域名，选择“添加解析”： 记录类型：A 主机记录：www或者其他子域名，如cloud 记录值：随便写一个 解析线路和TTL默认不改 点击“添加”，完成。 回到刚才的云解析DNS界面，右上方有个AccessKeys，进入后选择”创建Access Key“，然后根据手机验证创建一个Key，将Access Key ID和Access Key Secret记录下来，一会要用到。 安装git 1sudo apt install git 安装和配置阿里云ddns客户端 123456789cd /optsudo git clone https://github.com/rfancn/aliyun-ddns-client.git// 拷贝配置文件到指定位置cd aliyun-ddns-client/sudo cp ddns.conf.example /etc/ddns.conf//编辑配置文件sudo vim /etc/ddns.conf 123456789101112[DEFAULT]access_id = ABC******XYZ // 第3步的Access Key IDaccess_key = aaabbb*********YYYZZZ // 第3步的Access Key Secretinterval = 600 // 默认debug = true // 默认 [DomainRecord1]domain = tyrival.com // 第2步注册的域名sub_domain = www // 第2步填写的www等子域名type = A // 第2步的记录类型id = // 空着value = // 空着 按ESC，然后:wq保存退出。 由于ddns客户端需要用到python，可能要安装如下依赖包： 1234567// 安装pip——python包管理工具&lt;可选择&gt;sudo apt-get install python-pip python-dev build-essentialsudo pip install --upgrade pip sudo pip install --upgrade virtualenv // 安装requests依赖包pip install requests 执行ddns客户端同步 1234sudo python /opt/aliyun-ddns-client/ddns.py// 第一次运行可能会报错[ERROR] You must specify domain record id.如果报这个错，再执行一次试试看。****[INFO] Successfully sync done for record:DomainRecord1 执行完后，到云DNS解析那里看看，刚才随便写的ip应该被修改成了你的真实ip。 利用Ubuntu的任务管理来实现域名动态解析 1sudo crontab -e 我们在文件内容末尾追加一行，输入： 1*/1 * * * * cd /opt/aliyun-ddns-client &amp;&amp; /usr/bin/python ddns.py 表示每隔1分钟进行一次刚才的刷新，至此，动态域名解析完成。 通常，我们使用的ADSL是带路由器的，外网访问你的ip，也只能到路由器，无法具体找到内网中的电脑，所以需要在路由器上设置一个端口转发规则： 123456协议：TCP或者全部IP：云服务器的内网IP外部端口：8090或者其他内部端口：80 &lt;== 这个取决于你的Apache2服务监听的端口，如果没改过就是80// 另外可以顺便建立外部映射到云服务器，外网端口和内网端口都为22的ssh映射，方便在外网连接云服务器 这里需要注意的是外部端口，因为未备案的网站的80端口是被国家全部封掉的，443和8080可能也是封掉的，所以这三个端口就不要用于外部端口了，自定义一个8090这种可用的端口。 至此，外网云搭建完成，等上一会儿，最多估计10分钟左右，就可以通过域名访问你的云服务了。 1http://www(第3步中的子域名).你的域名.com:8090(第10步中的外部端口)/owncloud 可选步骤：如果第10步中，你希望指向一个非80端口，那就需要修改Apache的端口，记得和第10步的内网端口一致 123sudo vim /etc/apache2/sites-available/000-default.conf// &lt;VirtualHost *:80&gt;改成&lt;VirtualHost *:你想要的端口&gt;，然后保存退出。 123sudo vim /etc/apache2/ports.conf// Listen 80改成Listen 你想要的端口，然后保存退出。 1service apache2 restart // 重启apache服务 可选步骤：使用HTTPS加密，这个需要 安装签名工具 1234567cd /home/tyrival git clone https://github.com/Neilpang/acme.sh.gitcd ./acme.shsudo ./acme.sh --install 生成证书 1234567sudo ./acme.sh --issue --dns -d 你的域名.com==&gt; Registering account==&gt; *********==&gt; Domain: &apos;_acme-challenge.你的域名.com&apos;==&gt; TXT value: &apos;_AAABBB*********YYYZZZ&apos;==&gt; ********* 记住Domain和TXT Value到刚才的阿里云DNS解析那里，新增一个解析 123记录类型：TXT主机记录：&apos;_acme-challenge.你的域名.com&apos;记录值：&apos;_AAABBB*********YYYZZZ&apos; 申请证书 12345678910111213141516171819202122sudo ./acme.sh --renew -d 你的域名.com// 成功的话会有如下提示*** Renew: &apos;你的域名.com&apos;*** Single domain=&apos;你的域名.com&apos;*** Getting domain auth token for each domain*** Verifying:你的域名.com*** Success*** Verify finished, start to sign.*** Cert success.-----BEGIN CERTIFICATE-----MIIE+jCCA+KgAwIBAgISA1yIkeGmdcR3mWQ1mDRuGpYwMA0GCSqGSIb3DQEBCwUAMEoxCzAJBgNVBAYTAlVTMRYwFAYDVQQKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQD************0tofB/V66BhMtw+BzwUNk/brmy2iuA6mdoiGOaS5rxlv/rsRlFgba5mKLwOhuLvobNVG4y1lNAQ1m17QYdfPMtUFpfiO6e+xyuiownBoJWcWs1TnCx7k6J36ICLyljuBxjeDoZFiVBewn4iapjQB98E6J77wfMEttlunqslS-----END CERTIFICATE-----*** Your cert is in /home/***/.acme.sh/***.com/***.com.cer *** Your cert key is in /home/***/.acme.sh/***.com/***.com.key *** The intermediate CA cert is in /home/***/.acme.sh/***.com/ca.cer *** And the full chain certs is there: /home/***/.acme.sh/***.com/fullchain.cer 记录倒数第3、4行中，in后面的信息。 安装证书，首先要看存放证书的位置，然后把证书复制过去 12345sudo vim /etc/apache2/sites-available/default-ssl.conf// 找到下面两行SSLCertificateFile /etc/ssl/certs/ssl-cert-snakeoil.pemSSLCertificateKeyFile /etc/ssl/private/ssl-cert-snakeoil.key :q退出，然后把证书和私钥复制进去，证书为钢材倒数第4行，私钥为倒数第3行 12sudo cp /home/***/.acme.sh/***.com/***.com.cer /etc/ssl/certs/ssl-cert-snakeoil.pemsudo cp /home/***/.acme.sh/***.com/***.com.key /etc/ssl/private/ssl-cert-snakeoil.key 安装openssl 1234apt install openssl// 开启ssl模块sudo a2enmod ssl 修改https默认路径 1234sudo vim /etc/apache2/sites-available/default-ssl.conf // 改成下面值的DocumentRoot /var/www/owncloud 启用https：上文安装完后，会在 /etc/apache2/sites-available/ 目录下生成一个缺省的 default-ssl 文件。缺省的网页目录仍然是 /var/www/ 。我们可以创建一个链接到 site-enabled 目录。 1sudo ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/default-ssl.conf 重启apache服务 1service apache2 restart 然后到路由器配置下映射到云服务器的443端口，https加密完成。","categories":[{"name":"服务器","slug":"服务器","permalink":"http://tyrival.github.io/categories/服务器/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"cloud","slug":"cloud","permalink":"http://tyrival.github.io/tags/cloud/"}]},{"title":"Javascript作用域","slug":"js-scope","date":"2016-12-14T06:12:44.000Z","updated":"2017-06-19T06:15:57.000Z","comments":true,"path":"posts/js-scope/","link":"","permalink":"http://tyrival.github.io/posts/js-scope/","excerpt":"通过一个案例简述js中变量及函数的作用域的原理。","text":"通过一个案例简述js中变量及函数的作用域的原理。 1234567891011121314151617alert(x); // function ①var x = 10;alert(x); // 10 ②x = 20;function x() &#123;&#125;alert(x); // 20 ③if (true) &#123; var a = 1;&#125; else &#123; var b = 1;&#125;alert(a); // 1 ④alert(b); // undefined ⑤ 由于js中，所有的var声明会被提前到顶部，并且，变量的作用域是没有块级作用域，所以a和b的作用域实际上是全局的。这段代码实际的执行顺序大致如下： 123456789101112131415161718var x;function x() &#123;&#125;var a;var b;alert(x); // function ①x = 10;alert(x); // 10 ②x = 20;alert(x); // 20 ③if (true) &#123; a = 1;&#125; else &#123; b = 1;&#125;alert(a); // 1 ④alert(b); // undefined ⑤ ① var x 被 function x() {} 覆盖； ⑤ b被声明，但未赋值，所以是undefined，而不是报未声明的错误。","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"Intellij IDEA远程调试tomcat","slug":"tomcat-remote-debug","date":"2016-12-01T04:58:28.000Z","updated":"2017-08-21T06:18:49.000Z","comments":true,"path":"posts/tomcat-remote-debug/","link":"","permalink":"http://tyrival.github.io/posts/tomcat-remote-debug/","excerpt":"本文介绍怎样使用Intellij IDEA远程调试tomcat","text":"本文介绍怎样使用Intellij IDEA远程调试tomcat 如果服务器是Windows NT，就在%CATALINA_HOME%/bin下建立一个debug.bat文件，内容如下： 1234set JPDA_ADDRESS=9075 set JPDA_TRANSPORT=dt_socket et CATALINA_OPTS=-server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=9075 startup 其中的两处9075是要启用的远程端口，可以使用任何未被使用的端口。连接方式有两种，为dt_shmem和dt_socket，分别表示本机调试和远程调试。 如果远程服务器是Linux/Unix环境，就编辑%CATALINE_HOME%/bin/startup.sh文件，找到其中最后一行： 1exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; start &quot;$@&quot; 改为 1exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; jpda start &quot;$@&quot; 默认的远程调试端口是8000，如果被占用，编辑%CATALINA_HOME%/bin/catalina.sh文件： 1JPDA_ADDRESS=&quot;8000&quot; 改为 1JPDA_ADDRESS=&quot;9075&quot; 在Windows下运行debug.bat，在Linux下运行 startup.sh启动Tomcat。如果在启动日志中出现以下内容，则说明远程调试端口监听成功。 1Listening for transport dt_socket at address: 9075 进入Intellij IDEA - Edit Configuration，新建Remote，配置Host为服务器IP，Port为上面配置的9075端口，然后点击Debug开始调试，如果控制台出现如下信息，则说明远程调试配置正确。 1Connected to the target VM, address: &apos;192.168.2.252:9075&apos;, transport: &apos;socket&apos;","categories":[{"name":"服务器","slug":"服务器","permalink":"http://tyrival.github.io/categories/服务器/"}],"tags":[{"name":"server","slug":"server","permalink":"http://tyrival.github.io/tags/server/"},{"name":"tomcat","slug":"tomcat","permalink":"http://tyrival.github.io/tags/tomcat/"}]},{"title":"Hadoop（一）环境搭建","slug":"hadoop-configuration","date":"2016-11-28T03:47:44.000Z","updated":"2017-08-21T06:15:04.000Z","comments":true,"path":"posts/hadoop-configuration/","link":"","permalink":"http://tyrival.github.io/posts/hadoop-configuration/","excerpt":"本文阐述了在Ubuntu16环境下安装和配置Hadoop-2.7.3的全过程。","text":"本文阐述了在Ubuntu16环境下安装和配置Hadoop-2.7.3的全过程。 安装Ubuntu 安装ssh并启用 12sudo apt-get install openssh-serversudo /etc/init.d/ssh start 安装vim 1sudo apt install vim 下载并安装JDK到/usr/java目录 1sudo tar zxvf jdk-8u111-linux-x64.tar.gz -C /usr/lib/jvm 配置JDK环境变量，并使环境变量生效（vim用法自行Google） 1sudo vim /etc/profile 1234export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_111export JAVA_BIN=$JAVA_HOME/binexport JAVA_LIB=$JAVA_HOME/libexport CLASSPATH=.:$JAVA_LIB/tools.jar:$JAVA_LIB/dt.jar 1sudo vim /etc/environment 123 PATH=&quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/jvm/jdk1.8.0_111/bin&quot;CLASSPATH=&quot;/usr/lib/jvm/jdk1.8.0_111/lib&quot;JAVA_HOME=&quot;/usr/lib/jvm/jdk1.8.0_111&quot; 1source ~/.bashrc 告诉ubuntu系统，我们使用的sun的JDK，而非OpenJDK 123sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/jdk1.8.0_111/bin/java 300sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/jdk1.8.0_111/bin/javac 300sudo update-alternatives --config java 如果没有显示有多个jdk，则结束配置，如果有显示如下： 1234567sudo update-alternatives --config java有 2 个候选项可用于替换 java (提供 /usr/bin/java)。选择 路径 优先级 状态-------------------------------* 0 /usr/lib/jvm/java-6-openjdk/jre/bin/java 1061 自动模式1 /usr/lib/jvm/java-6-openjdk/jre/bin/java 1061 手动模式 2 /usr/lib/jvm/jdk1.8.0_05/bin/java 300 手动模式要维持当前值[*]请按回车键，或者键入选择的编号：？ 想用哪个输哪个号码，如上所示，这样就设置好了要使用的jdk了。 12345/* 验证jdk是否生效 */tyrival@ubuntu:/usr/java$ java -versionjava version &quot;1.8.0_111&quot;Java(TM) SE Runtime Environment (build 1.8.0_111-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode) 下载Hadoop并解压缩至/usr/local/hadoop 12sudo tar zxvf hadoop-2.7.3.tar.gz -C /usr/localsudo mv /usr/local/hadoop-2.7.3 /usr/local/hadoop 给/usr/local/hadoop设置访问权限（如果启动时报没有权限的错误，很大可能是因为这一步没完成） 1sudo chmod 777 /usr/local/hadoop 配置.bashrc文件 1sudo vim ~/.bashrc 在文件末尾追加下面内容： 123456789101112#HADOOP VARIABLES STARTexport JAVA_HOME=/usr/lib/jvm/jdk1.8.0_111export HADOOP_INSTALL=/usr/local/hadoopexport PATH=$PATH:$HADOOP_INSTALL/binexport PATH=$PATH:$HADOOP_INSTALL/sbinexport HADOOP_MAPRED_HOME=$HADOOP_INSTALLexport HADOOP_COMMON_HOME=$HADOOP_INSTALLexport HADOOP_HDFS_HOME=$HADOOP_INSTALLexport YARN_HOME=$HADOOP_INSTALLexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/nativeexport HADOOP_OPTS=&quot;-Djava.library.path=$HADOOP_INSTALL/lib&quot;#HADOOP VARIABLES END 使添加的环境变量生效 1source ~/.bashrc 配置Hadoop 1sudo vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh 1234# The java implementation to use.export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_111export HADOOP=/usr/local/hadoopexport PATH=$PATH:/usr/local/hadoop/bin 1sudo vim /usr/local/hadoop/etc/hadoop/yarn-env.sh 12# export JAVA_HOME=/home/y/libexec/jdk1.6.0/export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_111 在home目录地下创建 /home/tyrival/hadoop_tmp目录 1sudo mkdir /home/tyrival/hadoop_tmp 1sudo vim /usr/local/hadoop/etc/hadoop/core-site.sh 123456789101112&lt;configuration&gt; &lt;!-- 指定HDFS老大（namenode）的通信地址 --&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/tyrival/hadoop_tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 1sudo vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml 1234567&lt;configuration&gt; &lt;!-- 指定HDFS副本的数量 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 1sudo vim /usr/local/hadoop/etc/hadoop/yarn-site.xml 12345678910111213141516171819202122&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;127.0.0.1:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;127.0.0.1:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;127.0.0.1:8031&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 格式化 1hdfs namenode -format 12345678/* 出现下列消息表示成功 */...... INFO common.Storage: Storage directory /home/windghoul/tmp/dfs/name has been successfully formatted......./************************************************************SHUTDOWN_MSG: Shutting down NameNode at ubuntu/127.0.1.1************************************************************/ 启动，中间可能要输入几次密码 12start-all.sh​ 查看jps 12jps​ 123456/* 显示下列信息说明运行正常 */5760 Jps3058 DataNode3286 SecondaryNameNode2879 NameNode​ 访问 http://localhost:50070 和 http://localhost:8088，可以访问则说明成功。 ​","categories":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/categories/hadoop/"}],"tags":[{"name":"hadoop","slug":"hadoop","permalink":"http://tyrival.github.io/tags/hadoop/"}]},{"title":"IE扩展Function.prototype.bind()方法","slug":"ie-function-bind","date":"2016-11-24T06:54:32.000Z","updated":"2017-06-19T06:15:38.000Z","comments":true,"path":"posts/ie-function-bind/","link":"","permalink":"http://tyrival.github.io/posts/ie-function-bind/","excerpt":"IE6~IE8不支持Function原型的bind()方法，所以对其进行扩展。","text":"IE6~IE8不支持Function原型的bind()方法，所以对其进行扩展。1234567891011121314151617181920212223242526var Iflat = Iflat || &#123;&#125;;Iflat.Browser = &#123; extend: = &#123; ieFuncBind: function() &#123; if(!Function.prototype.bind) &#123; Function.prototype.bind = function(oThis) &#123; if(typeof this !== &apos;function&apos;) &#123; // closest thing possible to the ECMAScipt 5 // internal IsCallable function throw new TypeError(&apos;What is trying to be bound is not callable&apos;); &#125; var aArgs = Array.prototype.slice.call(arguments, 1); var fToBind = this; var fNOP = function()&#123;&#125;; var fBound = function() &#123; return fToBind.apply(this instanceof fNOP ? this : oThis, aArgs.contac(Array.prototype.slice.call(arguments))); &#125; fNOP.prototype = this.prototype; fBound.prototype = new fNOP(); eturn fBound; &#125;; &#125; &#125; &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"},{"name":"f**k ie","slug":"f-k-ie","permalink":"http://tyrival.github.io/tags/f-k-ie/"}]},{"title":"IE上的startsWith和endWith方法","slug":"ie-startswith-endwith","date":"2016-11-23T08:48:04.000Z","updated":"2017-06-19T06:15:48.000Z","comments":true,"path":"posts/ie-startswith-endwith/","link":"","permalink":"http://tyrival.github.io/posts/ie-startswith-endwith/","excerpt":"IE居然不支持这两个方法，好辣鸡！依赖包：Javascript浏览器相关方法","text":"IE居然不支持这两个方法，好辣鸡！依赖包：Javascript浏览器相关方法 12345678910111213141516171819202122// 扩展IE浏览器的String原型方法var Iflat = Iflat || &#123;&#125;;Iflat.Browser = &#123; extend: &#123; ieStringExtend: function () &#123; var browser = Iflat.Browser.info(); if (browser.name === &apos;ie&apos;) &#123; if (typeof String.prototype.startsWith != &apos;function&apos;) &#123; String.prototype.startsWith = function (prefix) &#123; return this.slice(0, prefix.length) === prefix; &#125;; &#125; if (typeof String.prototype.endsWith != &apos;function&apos;) &#123; String.prototype.endsWith = function (suffix) &#123; return this.indexOf(suffix, this.length - suffix.length) !== -1; &#125;; &#125; &#125; return browser; &#125; &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"},{"name":"f**k ie","slug":"f-k-ie","permalink":"http://tyrival.github.io/tags/f-k-ie/"}]},{"title":"IE上的new Date()","slug":"ie-new-date","date":"2016-11-23T08:47:48.000Z","updated":"2017-06-19T06:15:43.000Z","comments":true,"path":"posts/ie-new-date/","link":"","permalink":"http://tyrival.github.io/posts/ie-new-date/","excerpt":"IE下new Date(“yyyy-MM-dd hh:mm:ss”)是不支持的，只支持new Date(“yyyy-MM-dd”)，所以就对传入其中的string.substring(0, 10)，而IE6～7貌似连带参数的new Date(var1)都不支持。","text":"IE下new Date(“yyyy-MM-dd hh:mm:ss”)是不支持的，只支持new Date(“yyyy-MM-dd”)，所以就对传入其中的string.substring(0, 10)，而IE6～7貌似连带参数的new Date(var1)都不支持。此处提供一个方法: 1234567891011121314var Iflat = Iflat || &#123;&#125;;Iflat.Date = &#123; newDate: function(str) &#123; if(Iflat.Browser.isIE()) &#123; str = str.split(&apos;-&apos;); var date = new Date(); date.setUTCFullYear(str[0], str[1] - 1, str[2]); date.setUTCHours(0, 0, 0, 0); return date; &#125; else &#123; return new Date(str); &#125; &#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"},{"name":"f**k ie","slug":"f-k-ie","permalink":"http://tyrival.github.io/tags/f-k-ie/"}]},{"title":"网页mp3播放","slug":"media","date":"2016-11-23T08:16:19.000Z","updated":"2017-06-19T06:16:02.000Z","comments":true,"path":"posts/media/","link":"","permalink":"http://tyrival.github.io/posts/media/","excerpt":"封装了一个Web页面上播放mp3的功能，将mp3播放封装为一个小圆按钮。但对于不支持HTML5的IE6～8，通过html5media插件的flash功能对mp3进行播放，暂未对其封装为小圆按钮。依赖脚本：DOM操作常用方法Javascript浏览器相关方法IE上的startsWith和endWith方法外部依赖：html5media - 使html5的audio标签兼容各版本浏览器Font Aswsome","text":"封装了一个Web页面上播放mp3的功能，将mp3播放封装为一个小圆按钮。但对于不支持HTML5的IE6～8，通过html5media插件的flash功能对mp3进行播放，暂未对其封装为小圆按钮。依赖脚本：DOM操作常用方法Javascript浏览器相关方法IE上的startsWith和endWith方法外部依赖：html5media - 使html5的audio标签兼容各版本浏览器Font Aswsome 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697var Iflat = Iflat || &#123;&#125;;/** * Iflat.Audio用于在指定的标签内创建一个音频播放器，播放mp3； * 页面加载或修改完成后，调用Iflat.Audio.init()，装载音频播放器； * 插件为原生Javascript，不依赖jQuery * @param selector 标签选择器，默认&apos;.iflat-audio&apos;， * 支持 id(#id), className(.className), tagName(tagName)选择，不支持div[name=abc]这种复杂指定， * 建议在div或span中加载此插件，否则在ie6-8中无法正常使用； * 在页面增加selector指向的标签后，需调用Iflat.Audio.init()重新部署，最好是直接针对增加的标签部署，否则插件会检索全页面，效率较低； * @param attr 从指定标签的哪个属性获取音频文件路径，默认&apos;scr&apos;，修改mp3路径后，无需重新部署，监听器会自动关联路径信息 */Iflat.Audio = &#123; className: &apos;.iflat-audio&apos;, attrName: &apos;src&apos;, init: function (selector, attr) &#123; // 如果是ie浏览器，扩展其String原型方法，使其标！准！化！ var browser = Iflat.Browser.ieBullshitting(); // 根据选择器查询到所有满足条件的标签 var sel = selector || this.className; var eles = []; if (sel.startsWith(&quot;#&quot;)) &#123; var id = sel.substring(1, sel.length); eles[0] = document.getElementById(id); &#125; else if (sel.startsWith(&quot;.&quot;)) &#123; var clsName = sel.substring(1, sel.length); var all = document.getElementsByTagName(&quot;*&quot;); for (var o = 0; o &lt; all.length; o++) &#123; var eleCls = all[o].className if (eleCls.indexOf(&apos; &apos; + clsName) &gt;= 0 || eleCls.indexOf(clsName + &apos; &apos;) &gt;= 0 || eleCls === clsName) &#123; eles[eles.length] = all[o]; &#125; &#125; &#125; else &#123; eles = document.getElementsByTagName(sel); &#125; var attr = attr || this.attrName if (eles &amp;&amp; eles.length &gt; 0) &#123; for (var i = 0; i &lt; eles.length; i++) &#123; // 获取标签的src属性，即mp3资源 var src = eles[i].getAttribute(attr); // 将播放所需html代码置入标签内部 var cmpHtml = &apos;&apos;; if (browser.name === &apos;ie&apos; &amp;&amp; browser.version &lt; 9) &#123; cmpHtml = &apos;&lt;audio src=&quot;&apos; + src + &apos;&quot; controls&gt;&lt;/audio&gt;&apos;; &#125; else &#123; cmpHtml = &apos;&lt;a href=&quot;javascript:void(0);&quot; onclick=&quot;Iflat.Audio.clickPlayButton(this)&quot;&gt;&lt;i style=&quot;color:#1f6cf8&quot; class=&quot;fa fa-play-circle fa-lg&quot;&gt;&lt;/i&gt;&lt;/a&gt;&lt;audio src=&quot;&apos; + src + &apos;&quot; onended=&quot;Iflat.Audio.end(this)&quot;&gt;&lt;/audio&gt;&apos;; &#125; eles[i].innerHTML = cmpHtml; // 定义监听器的callback函数，使容器内的audio的src保持同步 var bindSrc = function (e) &#123; var audio = Iflat.DOM.lastChild(e); if (!audio.paused) &#123; audio.pause(); &#125; var icon = Iflat.DOM.firstChild(Iflat.DOM.previousSibling(audio)); icon.className = &quot;fa fa-play-circle fa-lg&quot;; audio.setAttribute(&apos;src&apos;, e.getAttribute(attr)) &#125; // 增加监听器 Iflat.DOM.addAttributeListener(eles[i], attr, bindSrc); &#125; &#125; &#125;, clickPlayButton: function (ele) &#123; var media = Iflat.DOM.nextSibling(ele); if (!media) &#123; console.error(&quot;未找到可播放的音频。&quot;); return; &#125; var icon = Iflat.DOM.firstChild(ele); if (media.paused) &#123; media.play(); icon.className = &quot;fa fa-pause-circle fa-lg&quot;; &#125; else &#123; media.pause(); icon.className = &quot;fa fa-play-circle fa-lg&quot;; &#125; &#125;, end: function (ele) &#123; var icon = Iflat.DOM.firstChild(Iflat.DOM.previousSibling(ele)); icon.className = &quot;fa fa-play-circle fa-lg&quot;; &#125;, play: function (audio) &#123; if (audio.paused) &#123; audio.play(); &#125; &#125;, pause: function (audio) &#123; if (!audio.paused) &#123; audio.pause(); &#125; &#125;,&#125;;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"Javascript浏览器相关方法","slug":"browser","date":"2016-11-23T08:16:11.000Z","updated":"2017-08-21T05:59:08.000Z","comments":true,"path":"posts/browser/","link":"","permalink":"http://tyrival.github.io/posts/browser/","excerpt":"用于判断浏览器的类型的js脚本。","text":"用于判断浏览器的类型的js脚本。12345678910111213141516171819202122232425262728293031323334353637383940var Iflat = Iflat || &#123;&#125;;Iflat.Browser = &#123; /* 获取浏览器信息，包括名称和版本 *／ info: function () &#123; var ua = navigator.userAgent.toLowerCase(); var browser = &#123; name: null, version: null &#125; var s; (s = ua.match(/rv:([\\d.]+)\\) like gecko/)) ? browser.name = &apos;ie&apos;: (s = ua.match(/msie ([\\d.]+)/)) ? browser.name = &apos;ie&apos;: (s = ua.match(/firefox\\/([\\d.]+)/)) ? browser.name = &apos;firefox&apos;: (s = ua.match(/chrome\\/([\\d.]+)/)) ? browser.name = &apos;chrome&apos;: (s = ua.match(/opera.([\\d.]+)/)) ? browser.name = &apos;opera&apos;: (s = ua.match(/version\\/([\\d.]+).*safari/)) ? browser.name = &apos;safari&apos; : 0; browser.version = s[1]; return browser; &#125;, ／* 是否为IE *／ isIE: function () &#123; return this.info().name === &apos;ie&apos;; &#125;, ／* 是否为chrome *／ isChrome: function () &#123; return this.info().name === &apos;chrome&apos;; &#125;, ／* 是否为opera *／ isOpera: function () &#123; return this.info().name === &apos;opera&apos;; &#125;, ／* 是否为safari *／ isSafari: function () &#123; return this.info().name === &apos;safari&apos;; &#125;, ／* 是否为firefox *／ isFirefox: function () &#123; return this.info().name === &apos;firefox&apos;; &#125;,&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"DOM操作常用方法","slug":"dom","date":"2016-11-23T08:14:43.000Z","updated":"2017-06-19T06:15:30.000Z","comments":true,"path":"posts/dom/","link":"","permalink":"http://tyrival.github.io/posts/dom/","excerpt":"基于原生js对DOM对象进行操作的部分方法，如查找兄弟元素或子元素等，以及对DOM元素的所有属性或特定属性进行监听的方法。","text":"基于原生js对DOM对象进行操作的部分方法，如查找兄弟元素或子元素等，以及对DOM元素的所有属性或特定属性进行监听的方法。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798var Iflat = Iflat || &#123;&#125;;Iflat.DOM = &#123; /** * 附加监听器，监听DOM元素的属性变化 * @param ele 附加监听器的DOM元素 * @param attr 监听的属性，!attr == true 时，监听所有属性 * @param callback 属性变化后执行函数，参数：ele - 监听的DOM元素对象 */ addAttributeListener: function (ele, attr, callback) &#123; // 判断浏览器是否支持MutationObserver var MutationObserver = window.MutationObserver || window.WebKitMutationObserver || window.MozMutationObserver; var observeMutationSupport = !!MutationObserver; if (observeMutationSupport) &#123; // 创建观察者对象 var observer = new MutationObserver(function (mutations) &#123; mutations.forEach(function (mutation) &#123; // 定义回调函数时，如果监控属性参数为非，或修改的属性与需要监控的属性相等时，调用回调函数 if (callback) &#123; if (!attr || (attr &amp;&amp; mutation.attributeName == attr)) &#123; callback(mutation.target); &#125; &#125; &#125;); &#125;); // 配置观察选项: var config = &#123;attributes: true&#125; // 传入目标节点和观察选项 observer.observe(ele, config); &#125; else &#123; // 回调函数 var onChange = function (event) &#123; // 定义回调函数时，如果监控属性参数为非，或修改的属性与需要监控的属性相等时，调用回调函数 if (callback) &#123; if (!attr || (attr &amp;&amp; event.attrName == attr)) &#123; callback(event.target); &#125; &#125; &#125;; if (ele.addEventListener) &#123; // Firefox, Opera and Safari ele.addEventListener(&apos;DOMAttrModified&apos;, onChange, false); &#125; else if (ele.attachEvent) &#123; // 旧版Internet Explorer ele.attachEvent(&apos;onpropertychange&apos;, onChange); &#125; &#125; &#125;, /* 参数DOM元素的前一个元素 *／ previousSibling: function (ele) &#123; while ((ele = ele.previousSibling)) &#123; if (!this.isIgnorable(ele)) return ele; &#125; return null; &#125;, /* 参数DOM元素的后一个元素 *／ nextSibling: function (ele) &#123; while ((ele = ele.nextSibling)) &#123; if (!this.isIgnorable(ele)) return ele; &#125; return null; &#125;, /* 参数DOM元素的第一个子元素 *／ firstChild: function (ele) &#123; while ((ele = ele.firstChild)) &#123; if (!this.isIgnorable(ele)) return ele; &#125; return null; &#125;, /* 参数DOM元素的最后一个子元素 *／ lastChild: function (ele) &#123; while ((ele = ele.lastChild)) &#123; if (!this.isIgnorable(ele)) return ele; &#125; return null; &#125;, /* 判断是否是无意义的节点 *／ isIgnorable: function (node) &#123; return (node.nodeType == 8) || ( (node.nodeType == 3) &amp;&amp; this.isBlankNode(node)); &#125;, /* 是否是空白节点，例如回车，空字符串 *／ isBlankNode: function (node) &#123; return !(/[^\\t\\n\\r ]/.test(node.data)); &#125;&#125;; demo：123456789var ele = document.getElementById(&apos;test&apos;);var attr = &apos;src&apos;;// 定义监听器的callback函数，使容器内的audio的src保持同步var callback = function (element) &#123; // doSomething...&#125;// 增加监听器Iflat.DOM.addAttributeListener(eles, attr, callback);","categories":[{"name":"前端","slug":"前端","permalink":"http://tyrival.github.io/categories/前端/"}],"tags":[{"name":"javascript","slug":"javascript","permalink":"http://tyrival.github.io/tags/javascript/"}]},{"title":"Git基本命令集","slug":"git-base","date":"2016-11-23T06:06:36.000Z","updated":"2017-12-08T09:21:03.000Z","comments":true,"path":"posts/git-base/","link":"","permalink":"http://tyrival.github.io/posts/git-base/","excerpt":"本文介绍运用git将代码同步到github上的基本方法。","text":"本文介绍运用git将代码同步到github上的基本方法。 检验电脑上是否存在 ssh keys. 1$ cd ~/.ssh 创建新的ssh keys 1$ ssh-keygen -t rsa -C &quot;tyrival@qq.com” 输入两次密码 tyrival1019（与Github一致） 进入C:\\User\\用户名.ssh，打开 id_rsa.pub，将其作为一个SSH key新建到Github中的个人信息中 配置用户名、邮箱（与github保持一致） 12$ git config --global user.name&quot;tyrival”$ git config --global user.email&quot;tyrival@qq.com” 在Github上新建项目，并复制其ssh地址 进入项目文件夹，初始化仓库. 1$ git init 添加所有文件到仓库. 12$ cd D:/workspace/iflat/iflat$ git add \\* 提交. 1$ git commit -m &quot;commit by Tyrival” 远程同步到服务器 1$ git remote add origin git@github.com:tyrival/iFlat.git 第5步如果报“fatal: remote origin already exists.” 12$ git remote rm origin$ git remote add origin git@github.com:tyrival/iFlat.git 推送到服务器 1$ git push -u origin master","categories":[{"name":"工具","slug":"工具","permalink":"http://tyrival.github.io/categories/工具/"}],"tags":[{"name":"git","slug":"git","permalink":"http://tyrival.github.io/tags/git/"}]}]}